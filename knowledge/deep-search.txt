This file is a merged representation of the entire codebase, combined into a single document by Repomix. The content has been processed where empty lines have been removed.

================================================================
File Summary
================================================================

Purpose:
--------
This file contains a packed representation of the entire repository's contents.
It is designed to be easily consumable by AI systems for analysis, code review,
or other automated processes.

File Format:
------------
The content is organized as follows:
1. This summary section
2. Repository information
3. Directory structure
4. Multiple file entries, each consisting of:
  a. A separator line (================)
  b. The file path (File: path/to/file)
  c. Another separator line
  d. The full contents of the file
  e. A blank line

Usage Guidelines:
-----------------
- This file should be treated as read-only. Any changes should be made to the
  original repository files, not this packed version.
- When processing this file, use the file path to distinguish
  between different files in the repository.
- Be aware that this file may contain sensitive information. Handle it with
  the same level of security as you would the original repository.

Notes:
------
- Some files may have been excluded based on .gitignore rules and Repomix's configuration
- Binary files are not included in this packed representation. Please refer to the Repository Structure section for a complete list of file paths, including binary files
- Files matching patterns in .gitignore are excluded
- Files matching default ignore patterns are excluded
- Empty lines have been removed from all files

Additional Info:
----------------

================================================================
Directory Structure
================================================================
.github/
  workflows/
    cd.yml
    npm-publish.yml
    test.yml
jina-ai/
  src/
    dto/
      jina-embeddings-auth.ts
    lib/
      async-context.ts
      billing.ts
      env-config.ts
      errors.ts
      firestore.ts
      logger.ts
      registry.ts
    patch-express.ts
    rate-limit.ts
    server.ts
  .dockerignore
  config.json
  Dockerfile
  package.json
  tsconfig.json
src/
  __tests__/
    agent.test.ts
    docker.test.ts
    server.test.ts
  evals/
    batch-evals.ts
    ego-questions.json
  tools/
    __tests__/
      error-analyzer.test.ts
      evaluator.test.ts
      read.test.ts
      search.test.ts
    brave-search.ts
    code-sandbox.ts
    dedup.ts
    error-analyzer.ts
    evaluator.ts
    grounding.ts
    jina-dedup.ts
    jina-search.ts
    query-rewriter.ts
    read.ts
    serper-search.ts
  utils/
    action-tracker.ts
    i18n.json
    safe-generator.ts
    schemas.ts
    text-tools.ts
    token-tracker.ts
    url-tools.ts
  agent.ts
  app.ts
  cli.ts
  config.ts
  server.ts
  types.ts
.dockerignore
.eslintrc.js
.gitignore
config.json
docker-compose.yml
Dockerfile
jest.config.js
jest.setup.js
LICENSE
package.json
README.md
tsconfig.json

================================================================
Files
================================================================

================
File: .github/workflows/cd.yml
================
run-name: Build push and deploy (CD)
on:
  push:
    branches:
      - main
      - ci-debug
    tags:
      - '*'
jobs:
  build-and-push-to-gcr:
    runs-on: ubuntu-latest
    concurrency:
      group: ${{ github.ref_type == 'branch' && github.ref }}
      cancel-in-progress: true
    permissions:
      contents: read
    steps:
      - uses: actions/checkout@v4
        with:
          lfs: true
      - uses: 'google-github-actions/auth@v2'
        with:
           credentials_json: '${{ secrets.GCLOUD_SERVICE_ACCOUNT_SECRET_JSON }}'
      - name: 'Set up Cloud SDK'
        uses: 'google-github-actions/setup-gcloud@v2'
      - name: "Docker auth"
        run: |-
          gcloud auth configure-docker us-docker.pkg.dev --quiet
      - name: Set controller release version
        run: echo "RELEASE_VERSION=${GITHUB_REF#refs/*/}" >> $GITHUB_ENV
      - name: Set up Node.js
        uses: actions/setup-node@v4
        with:
          node-version: 22.12.0
          cache: npm
      - name: npm install
        run: npm ci
      - name: build application
        run: npm run build
      - name: Set package version
        run: npm version --no-git-tag-version ${{ env.RELEASE_VERSION }}
        if: github.ref_type == 'tag'
      - name: Docker meta
        id: meta
        uses: docker/metadata-action@v5
        with:
          images: |
            us-docker.pkg.dev/research-df067/deepresearch/node-deep-research
      - name: Set up QEMU
        uses: docker/setup-qemu-action@v3
      - name: Set up Docker Buildx
        uses: docker/setup-buildx-action@v3
      - name: Build and push
        id: container
        uses: docker/build-push-action@v6
        with:
          file: jina-ai/Dockerfile
          push: true
          tags: ${{ steps.meta.outputs.tags }}
          labels: ${{ steps.meta.outputs.labels }}
      - name: Deploy with Tag
        run: |
          gcloud run deploy node-deep-research --image us-docker.pkg.dev/research-df067/deepresearch/node-deep-research@${{steps.container.outputs.imageid}} --tag ${{ env.RELEASE_VERSION }} --region us-central1 --async

================
File: .github/workflows/npm-publish.yml
================
name: NPM Publish
on:
  release:
    types: [created]
jobs:
  publish:
    runs-on: ubuntu-latest
    steps:
      - uses: actions/checkout@v4
      - name: Use Node.js
        uses: actions/setup-node@v4
        with:
          node-version: '20.x'
          registry-url: 'https://registry.npmjs.org'
          cache: 'npm'
      - name: Install dependencies
        run: npm ci
      - name: Run lint
        env:
          BRAVE_API_KEY: ${{ secrets.BRAVE_API_KEY }}
          GEMINI_API_KEY: ${{ secrets.GEMINI_API_KEY }}
          JINA_API_KEY: ${{ secrets.JINA_API_KEY }}
          GOOGLE_API_KEY: ${{ secrets.GEMINI_API_KEY }}
          OPENAI_API_KEY: ${{ secrets.OPENAI_API_KEY }}
        run: npm run lint
      - name: Build TypeScript
        run: npm run build
      - name: Update version from release
        run: |
          # Get release tag without 'v' prefix
          VERSION=$(echo ${{ github.ref_name }} | sed 's/^v//')
          # Update version in package.json
          npm version $VERSION --no-git-tag-version --allow-same-version
      - name: Publish to npm
        env:
          NODE_AUTH_TOKEN: ${{ secrets.NPM_TOKEN }}
        run: npm publish --access public

================
File: .github/workflows/test.yml
================
name: Test
on:
  pull_request:
    branches: [ main ]
jobs:
  test:
    if: "!startsWith(github.event.head_commit.message, 'chore')"
    runs-on: ubuntu-latest
    steps:
      - uses: actions/checkout@v4
      - name: Use Node.js
        uses: actions/setup-node@v4
        with:
          node-version: '20.x'
          cache: 'npm'
      - name: Install dependencies
        run: npm ci
      - name: Run lint
        run: npm run lint
      - name: Run tests
        env:
          BRAVE_API_KEY: ${{ secrets.BRAVE_API_KEY }}
          GEMINI_API_KEY: ${{ secrets.GEMINI_API_KEY }}
          JINA_API_KEY: ${{ secrets.JINA_API_KEY }}
          GOOGLE_API_KEY: ${{ secrets.GEMINI_API_KEY }}
          OPENAI_API_KEY: ${{ secrets.OPENAI_API_KEY }}
        run: npm test
      - name: Set up Docker
        uses: docker/setup-buildx-action@v3
      - name: Run Docker tests
        env:
          BRAVE_API_KEY: mock_key
          GEMINI_API_KEY: mock_key
          JINA_API_KEY: mock_key
          GOOGLE_API_KEY: mock_key
          OPENAI_API_KEY: mock_key
        run: npm run test:docker

================
File: jina-ai/src/dto/jina-embeddings-auth.ts
================
import {
    Also, AuthenticationFailedError, AuthenticationRequiredError,
    DownstreamServiceFailureError, RPC_CALL_ENVIRONMENT,
    ArrayOf, AutoCastable, Prop
} from 'civkit/civ-rpc';
import { parseJSONText } from 'civkit/vectorize';
import { htmlEscape } from 'civkit/escape';
import { marshalErrorLike } from 'civkit/lang';
import type express from 'express';
import logger from '../lib/logger';
import { AsyncLocalContext } from '../lib/async-context';
import { InjectProperty } from '../lib/registry';
import { JinaEmbeddingsDashboardHTTP } from '../lib/billing';
import envConfig from '../lib/env-config';
import { FirestoreRecord } from '../lib/firestore';
import _ from 'lodash';
import { RateLimitDesc } from '../rate-limit';
export class JinaWallet extends AutoCastable {
    @Prop({
        default: ''
    })
    user_id!: string;
    @Prop({
        default: 0
    })
    trial_balance!: number;
    @Prop()
    trial_start?: Date;
    @Prop()
    trial_end?: Date;
    @Prop({
        default: 0
    })
    regular_balance!: number;
    @Prop({
        default: 0
    })
    total_balance!: number;
}
export class JinaEmbeddingsTokenAccount extends FirestoreRecord {
    static override collectionName = 'embeddingsTokenAccounts';
    override _id!: string;
    @Prop({
        required: true
    })
    user_id!: string;
    @Prop({
        nullable: true,
        type: String,
    })
    email?: string;
    @Prop({
        nullable: true,
        type: String,
    })
    full_name?: string;
    @Prop({
        nullable: true,
        type: String,
    })
    customer_id?: string;
    @Prop({
        nullable: true,
        type: String,
    })
    avatar_url?: string;
    // Not keeping sensitive info for now
    // @Prop()
    // billing_address?: object;
    // @Prop()
    // payment_method?: object;
    @Prop({
        required: true
    })
    wallet!: JinaWallet;
    @Prop({
        type: Object
    })
    metadata?: { [k: string]: any; };
    @Prop({
        defaultFactory: () => new Date()
    })
    lastSyncedAt!: Date;
    @Prop({
        dictOf: [ArrayOf(RateLimitDesc)]
    })
    customRateLimits?: { [k: string]: RateLimitDesc[]; };
    static patchedFields = [
    ];
    static override from(input: any) {
        for (const field of this.patchedFields) {
            if (typeof input[field] === 'string') {
                input[field] = parseJSONText(input[field]);
            }
        }
        return super.from(input) as JinaEmbeddingsTokenAccount;
    }
    override degradeForFireStore() {
        const copy: any = {
            ...this,
            wallet: { ...this.wallet },
            // Firebase disability
            customRateLimits: _.mapValues(this.customRateLimits, (v) => v.map((x) => ({ ...x }))),
        };
        for (const field of (this.constructor as typeof JinaEmbeddingsTokenAccount).patchedFields) {
            if (typeof copy[field] === 'object') {
                copy[field] = JSON.stringify(copy[field]) as any;
            }
        }
        return copy;
    }
    [k: string]: any;
}
const authDtoLogger = logger.child({ service: 'JinaAuthDTO' });
export interface FireBaseHTTPCtx {
    req: express.Request,
    res: express.Response,
}
const THE_VERY_SAME_JINA_EMBEDDINGS_CLIENT = new JinaEmbeddingsDashboardHTTP(envConfig.JINA_EMBEDDINGS_DASHBOARD_API_KEY);
@Also({
    openapi: {
        operation: {
            parameters: {
                'Authorization': {
                    description: htmlEscape`Jina Token for authentication.\n\n` +
                        htmlEscape`- Member of <JinaEmbeddingsAuthDTO>\n\n` +
                        `- Authorization: Bearer {YOUR_JINA_TOKEN}`
                    ,
                    in: 'header',
                    schema: {
                        anyOf: [
                            { type: 'string', format: 'token' }
                        ]
                    }
                }
            }
        }
    }
})
export class JinaEmbeddingsAuthDTO extends AutoCastable {
    uid?: string;
    bearerToken?: string;
    user?: JinaEmbeddingsTokenAccount;
    @InjectProperty(AsyncLocalContext)
    ctxMgr!: AsyncLocalContext;
    jinaEmbeddingsDashboard = THE_VERY_SAME_JINA_EMBEDDINGS_CLIENT;
    static override from(input: any) {
        const instance = super.from(input) as JinaEmbeddingsAuthDTO;
        const ctx = input[RPC_CALL_ENVIRONMENT];
        const req = (ctx.rawRequest || ctx.req) as express.Request | undefined;
        if (req) {
            const authorization = req.get('authorization');
            if (authorization) {
                const authToken = authorization.split(' ')[1] || authorization;
                instance.bearerToken = authToken;
            }
        }
        if (!instance.bearerToken && input._token) {
            instance.bearerToken = input._token;
        }
        return instance;
    }
    async getBrief(ignoreCache?: boolean | string) {
        if (!this.bearerToken) {
            throw new AuthenticationRequiredError({
                message: 'Jina API key is required to authenticate. Please get one from https://jina.ai'
            });
        }
        let account;
        try {
            account = await JinaEmbeddingsTokenAccount.fromFirestore(this.bearerToken);
        } catch (err) {
            // FireStore would not accept any string as input and may throw if not happy with it
            void 0;
        }
        const age = account?.lastSyncedAt ? Date.now() - account.lastSyncedAt.getTime() : Infinity;
        if (account && !ignoreCache) {
            if (account && age < 180_000) {
                this.user = account;
                this.uid = this.user?.user_id;
                return account;
            }
        }
        try {
            const r = await this.jinaEmbeddingsDashboard.validateToken(this.bearerToken);
            const brief = r.data;
            const draftAccount = JinaEmbeddingsTokenAccount.from({
                ...account, ...brief, _id: this.bearerToken,
                lastSyncedAt: new Date()
            });
            await JinaEmbeddingsTokenAccount.save(draftAccount.degradeForFireStore(), undefined, { merge: true });
            this.user = draftAccount;
            this.uid = this.user?.user_id;
            return draftAccount;
        } catch (err: any) {
            authDtoLogger.warn(`Failed to get user brief: ${err}`, { err: marshalErrorLike(err) });
            if (err?.status === 401) {
                throw new AuthenticationFailedError({
                    message: 'Invalid API key, please get a new one from https://jina.ai'
                });
            }
            if (account) {
                this.user = account;
                this.uid = this.user?.user_id;
                return account;
            }
            throw new DownstreamServiceFailureError(`Failed to authenticate: ${err}`);
        }
    }
    async reportUsage(tokenCount: number, mdl: string, endpoint: string = '/encode') {
        const user = await this.assertUser();
        const uid = user.user_id;
        user.wallet.total_balance -= tokenCount;
        return this.jinaEmbeddingsDashboard.reportUsage(this.bearerToken!, {
            model_name: mdl,
            api_endpoint: endpoint,
            consumer: {
                id: uid,
                user_id: uid,
            },
            usage: {
                total_tokens: tokenCount
            },
            labels: {
                model_name: mdl
            }
        }).then((r) => {
            JinaEmbeddingsTokenAccount.COLLECTION.doc(this.bearerToken!)
                .update({ 'wallet.total_balance': JinaEmbeddingsTokenAccount.OPS.increment(-tokenCount) })
                .catch((err) => {
                    authDtoLogger.warn(`Failed to update cache for ${uid}: ${err}`, { err: marshalErrorLike(err) });
                });
            return r;
        }).catch((err) => {
            user.wallet.total_balance += tokenCount;
            authDtoLogger.warn(`Failed to report usage for ${uid}: ${err}`, { err: marshalErrorLike(err) });
        });
    }
    async solveUID() {
        if (this.uid) {
            this.ctxMgr.set('uid', this.uid);
            return this.uid;
        }
        if (this.bearerToken) {
            await this.getBrief();
            this.ctxMgr.set('uid', this.uid);
            return this.uid;
        }
        return undefined;
    }
    async assertUID() {
        const uid = await this.solveUID();
        if (!uid) {
            throw new AuthenticationRequiredError('Authentication failed');
        }
        return uid;
    }
    async assertUser() {
        if (this.user) {
            return this.user;
        }
        await this.getBrief();
        return this.user!;
    }
    getRateLimits(...tags: string[]) {
        const descs = tags.map((x) => this.user?.customRateLimits?.[x] || []).flat().filter((x) => x.isEffective());
        if (descs.length) {
            return descs;
        }
        return undefined;
    }
}

================
File: jina-ai/src/lib/async-context.ts
================
import { GlobalAsyncContext } from 'civkit/async-context';
import { container, singleton } from 'tsyringe';
@singleton()
export class AsyncLocalContext extends GlobalAsyncContext {}
const instance = container.resolve(AsyncLocalContext);
Reflect.set(process, 'asyncLocalContext', instance);
export default instance;

================
File: jina-ai/src/lib/billing.ts
================
import { HTTPService } from 'civkit';
import _ from 'lodash';
export interface JinaWallet {
    trial_balance: number;
    trial_start: Date;
    trial_end: Date;
    regular_balance: number;
    total_balance: number;
}
export interface JinaUserBrief {
    user_id: string;
    email: string | null;
    full_name: string | null;
    customer_id: string | null;
    avatar_url?: string;
    billing_address: Partial<{
        address: string;
        city: string;
        state: string;
        country: string;
        postal_code: string;
    }>;
    payment_method: Partial<{
        brand: string;
        last4: string;
        exp_month: number;
        exp_year: number;
    }>;
    wallet: JinaWallet;
    metadata: {
        [k: string]: any;
    };
}
export interface JinaUsageReport {
    model_name: string;
    api_endpoint: string;
    consumer: {
        user_id: string;
        customer_plan?: string;
        [k: string]: any;
    };
    usage: {
        total_tokens: number;
    };
    labels: {
        user_type?: string;
        model_name?: string;
        [k: string]: any;
    };
}
export class JinaEmbeddingsDashboardHTTP extends HTTPService {
    name = 'JinaEmbeddingsDashboardHTTP';
    constructor(
        public apiKey: string,
        public baseUri: string = 'https://embeddings-dashboard-api.jina.ai/api'
    ) {
        super(baseUri);
        this.baseOptions.timeout = 30_000;  // 30 sec
    }
    async authorization(token: string) {
        const r = await this.get<JinaUserBrief>('/v1/authorization', {
            headers: {
                Authorization: `Bearer ${token}`
            },
            responseType: 'json',
        });
        return r;
    }
    async validateToken(token: string) {
        const r = await this.getWithSearchParams<JinaUserBrief>('/v1/api_key/user', {
            api_key: token,
        }, {
            responseType: 'json',
        });
        return r;
    }
    async reportUsage(token: string, query: JinaUsageReport) {
        const r = await this.postJson('/v1/usage', query, {
            headers: {
                Authorization: `Bearer ${token}`,
                'x-api-key': this.apiKey,
            },
            responseType: 'text',
        });
        return r;
    }
}

================
File: jina-ai/src/lib/env-config.ts
================
import { container, singleton } from 'tsyringe';
export const SPECIAL_COMBINED_ENV_KEY = 'ENV_COMBINED';
const CONF_ENV = [
    'OPENAI_API_KEY',
    'ANTHROPIC_API_KEY',
    'REPLICATE_API_KEY',
    'GOOGLE_AI_STUDIO_API_KEY',
    'JINA_EMBEDDINGS_API_KEY',
    'JINA_EMBEDDINGS_DASHBOARD_API_KEY',
    'BRAVE_SEARCH_API_KEY',
] as const;
@singleton()
export class EnvConfig {
    dynamic!: Record<string, string>;
    combined: Record<string, string> = {};
    originalEnv: Record<string, string | undefined> = { ...process.env };
    constructor() {
        if (process.env[SPECIAL_COMBINED_ENV_KEY]) {
            Object.assign(this.combined, JSON.parse(
                Buffer.from(process.env[SPECIAL_COMBINED_ENV_KEY]!, 'base64').toString('utf-8')
            ));
            delete process.env[SPECIAL_COMBINED_ENV_KEY];
        }
        // Static config
        for (const x of CONF_ENV) {
            const s = this.combined[x] || process.env[x] || '';
            Reflect.set(this, x, s);
            if (x in process.env) {
                delete process.env[x];
            }
        }
        // Dynamic config
        this.dynamic = new Proxy({
            get: (_target: any, prop: string) => {
                return this.combined[prop] || process.env[prop] || '';
            }
        }, {}) as any;
    }
}
// eslint-disable-next-line @typescript-eslint/no-empty-interface
export interface EnvConfig extends Record<typeof CONF_ENV[number], string> { }
const instance = container.resolve(EnvConfig);
export default instance;

================
File: jina-ai/src/lib/errors.ts
================
import { ApplicationError, Prop, RPC_TRANSFER_PROTOCOL_META_SYMBOL, StatusCode } from 'civkit';
import _ from 'lodash';
import dayjs from 'dayjs';
import utc from 'dayjs/plugin/utc';
dayjs.extend(utc);
@StatusCode(50301)
export class ServiceDisabledError extends ApplicationError { }
@StatusCode(50302)
export class ServiceCrashedError extends ApplicationError { }
@StatusCode(50303)
export class ServiceNodeResourceDrainError extends ApplicationError { }
@StatusCode(40104)
export class EmailUnverifiedError extends ApplicationError { }
@StatusCode(40201)
export class InsufficientCreditsError extends ApplicationError { }
@StatusCode(40202)
export class FreeFeatureLimitError extends ApplicationError { }
@StatusCode(40203)
export class InsufficientBalanceError extends ApplicationError { }
@StatusCode(40903)
export class LockConflictError extends ApplicationError { }
@StatusCode(40904)
export class BudgetExceededError extends ApplicationError { }
@StatusCode(45101)
export class HarmfulContentError extends ApplicationError { }
@StatusCode(45102)
export class SecurityCompromiseError extends ApplicationError { }
@StatusCode(41201)
export class BatchSizeTooLargeError extends ApplicationError { }
@StatusCode(42903)
export class RateLimitTriggeredError extends ApplicationError {
    @Prop({
        desc: 'Retry after seconds',
    })
    retryAfter?: number;
    @Prop({
        desc: 'Retry after date',
    })
    retryAfterDate?: Date;
    protected override get [RPC_TRANSFER_PROTOCOL_META_SYMBOL]() {
        const retryAfter = this.retryAfter || this.retryAfterDate;
        if (!retryAfter) {
            return super[RPC_TRANSFER_PROTOCOL_META_SYMBOL];
        }
        return _.merge(_.cloneDeep(super[RPC_TRANSFER_PROTOCOL_META_SYMBOL]), {
            headers: {
                'Retry-After': `${retryAfter instanceof Date ? dayjs(retryAfter).utc().format('ddd, DD MMM YYYY HH:mm:ss [GMT]') : retryAfter}`,
            }
        });
    }
}

================
File: jina-ai/src/lib/firestore.ts
================
import _ from 'lodash';
import { AutoCastable, Prop, RPC_MARSHAL } from 'civkit/civ-rpc';
import {
    Firestore, FieldValue, DocumentReference,
    Query, Timestamp, SetOptions, DocumentSnapshot,
} from '@google-cloud/firestore';
import { Storage } from '@google-cloud/storage';
export const firebaseDefaultBucket = new Storage().bucket(`${process.env.GCLOUD_PROJECT}.appspot.com`);
// Firestore doesn't support JavaScript objects with custom prototypes (i.e. objects that were created via the \"new\" operator)
function patchFireStoreArrogance(func: Function) {
    return function (this: unknown) {
        const origObjectGetPrototype = Object.getPrototypeOf;
        Object.getPrototypeOf = function (x) {
            const r = origObjectGetPrototype.call(this, x);
            if (!r) {
                return r;
            }
            return Object.prototype;
        };
        try {
            return func.call(this, ...arguments);
        } finally {
            Object.getPrototypeOf = origObjectGetPrototype;
        }
    };
}
Reflect.set(DocumentReference.prototype, 'set', patchFireStoreArrogance(Reflect.get(DocumentReference.prototype, 'set')));
Reflect.set(DocumentSnapshot, 'fromObject', patchFireStoreArrogance(Reflect.get(DocumentSnapshot, 'fromObject')));
function mapValuesDeep(v: any, fn: (i: any) => any): any {
    if (_.isPlainObject(v)) {
        return _.mapValues(v, (i) => mapValuesDeep(i, fn));
    } else if (_.isArray(v)) {
        return v.map((i) => mapValuesDeep(i, fn));
    } else {
        return fn(v);
    }
}
export type Constructor<T> = { new(...args: any[]): T; };
export type Constructed<T> = T extends Partial<infer U> ? U : T extends object ? T : object;
export function fromFirestore<T extends FirestoreRecord>(
    this: Constructor<T>, id: string, overrideCollection?: string
): Promise<T | undefined>;
export async function fromFirestore(
    this: any, id: string, overrideCollection?: string
) {
    const collection = overrideCollection || this.collectionName;
    if (!collection) {
        throw new Error(`Missing collection name to construct ${this.name}`);
    }
    const ref = this.DB.collection(overrideCollection || this.collectionName).doc(id);
    const ptr = await ref.get();
    if (!ptr.exists) {
        return undefined;
    }
    const doc = this.from(
        // Fixes non-native firebase types
        mapValuesDeep(ptr.data(), (i: any) => {
            if (i instanceof Timestamp) {
                return i.toDate();
            }
            return i;
        })
    );
    Object.defineProperty(doc, '_ref', { value: ref, enumerable: false });
    Object.defineProperty(doc, '_id', { value: ptr.id, enumerable: true });
    return doc;
}
export function fromFirestoreQuery<T extends FirestoreRecord>(
    this: Constructor<T>, query: Query
): Promise<T[]>;
export async function fromFirestoreQuery(this: any, query: Query) {
    const ptr = await query.get();
    if (ptr.docs.length) {
        return ptr.docs.map(doc => {
            const r = this.from(
                mapValuesDeep(doc.data(), (i: any) => {
                    if (i instanceof Timestamp) {
                        return i.toDate();
                    }
                    return i;
                })
            );
            Object.defineProperty(r, '_ref', { value: doc.ref, enumerable: false });
            Object.defineProperty(r, '_id', { value: doc.id, enumerable: true });
            return r;
        });
    }
    return [];
}
export function setToFirestore<T extends FirestoreRecord>(
    this: Constructor<T>, doc: T, overrideCollection?: string, setOptions?: SetOptions
): Promise<T>;
export async function setToFirestore(
    this: any, doc: any, overrideCollection?: string, setOptions?: SetOptions
) {
    let ref: DocumentReference<any> = doc._ref;
    if (!ref) {
        const collection = overrideCollection || this.collectionName;
        if (!collection) {
            throw new Error(`Missing collection name to construct ${this.name}`);
        }
        const predefinedId = doc._id || undefined;
        const hdl = this.DB.collection(overrideCollection || this.collectionName);
        ref = predefinedId ? hdl.doc(predefinedId) : hdl.doc();
        Object.defineProperty(doc, '_ref', { value: ref, enumerable: false });
        Object.defineProperty(doc, '_id', { value: ref.id, enumerable: true });
    }
    await ref.set(doc, { merge: true, ...setOptions });
    return doc;
}
export function deleteQueryBatch<T extends FirestoreRecord>(
    this: Constructor<T>, query: Query
): Promise<T>;
export async function deleteQueryBatch(this: any, query: Query) {
    const snapshot = await query.get();
    const batchSize = snapshot.size;
    if (batchSize === 0) {
        return;
    }
    // Delete documents in a batch
    const batch = this.DB.batch();
    snapshot.docs.forEach((doc) => {
        batch.delete(doc.ref);
    });
    await batch.commit();
    process.nextTick(() => {
        this.deleteQueryBatch(query);
    });
};
export function fromFirestoreDoc<T extends FirestoreRecord>(
    this: Constructor<T>, snapshot: DocumentSnapshot,
): T | undefined;
export function fromFirestoreDoc(
    this: any, snapshot: DocumentSnapshot,
) {
    const doc = this.from(
        // Fixes non-native firebase types
        mapValuesDeep(snapshot.data(), (i: any) => {
            if (i instanceof Timestamp) {
                return i.toDate();
            }
            return i;
        })
    );
    Object.defineProperty(doc, '_ref', { value: snapshot.ref, enumerable: false });
    Object.defineProperty(doc, '_id', { value: snapshot.id, enumerable: true });
    return doc;
}
const defaultFireStore = new Firestore({
    projectId: process.env.GCLOUD_PROJECT,
});
export class FirestoreRecord extends AutoCastable {
    static collectionName?: string;
    static OPS = FieldValue;
    static DB = defaultFireStore;
    static get COLLECTION() {
        if (!this.collectionName) {
            throw new Error('Not implemented');
        }
        return this.DB.collection(this.collectionName);
    }
    @Prop()
    _id?: string;
    _ref?: DocumentReference<Partial<Omit<this, '_ref' | '_id'>>>;
    static fromFirestore = fromFirestore;
    static fromFirestoreDoc = fromFirestoreDoc;
    static fromFirestoreQuery = fromFirestoreQuery;
    static save = setToFirestore;
    static deleteQueryBatch = deleteQueryBatch;
    [RPC_MARSHAL]() {
        return {
            ...this,
            _id: this._id,
            _ref: this._ref?.path
        };
    }
    degradeForFireStore(): this {
        return JSON.parse(JSON.stringify(this, function (k, v) {
            if (k === '') {
                return v;
            }
            if (typeof v === 'object' && v && (typeof v.degradeForFireStore === 'function')) {
                return v.degradeForFireStore();
            }
            return v;
        }));
    }
}

================
File: jina-ai/src/lib/logger.ts
================
import { AbstractPinoLogger } from 'civkit/pino-logger';
import { singleton, container } from 'tsyringe';
import { threadId } from 'node:worker_threads';
import { getTraceCtx } from 'civkit/async-context';
const levelToSeverityMap: { [k: string]: string | undefined; } = {
    trace: 'DEFAULT',
    debug: 'DEBUG',
    info: 'INFO',
    warn: 'WARNING',
    error: 'ERROR',
    fatal: 'CRITICAL',
};
@singleton()
export class GlobalLogger extends AbstractPinoLogger {
    loggerOptions = {
        level: 'debug',
        base: {
            tid: threadId,
        }
    };
    override init(): void {
        if (process.env['NODE_ENV']?.startsWith('prod')) {
            super.init(process.stdout);
        } else {
            const PinoPretty = require('pino-pretty').PinoPretty;
            super.init(PinoPretty({
                singleLine: true,
                colorize: true,
                messageFormat(log: any, messageKey: any) {
                    return `${log['tid'] ? `[${log['tid']}]` : ''}[${log['service'] || 'ROOT'}] ${log[messageKey]}`;
                },
            }));
        }
        this.emit('ready');
    }
    override log(...args: any[]) {
        const [levelObj, ...rest] = args;
        const severity = levelToSeverityMap[levelObj?.level];
        const traceCtx = getTraceCtx();
        const patched: any= { ...levelObj, severity };
        if (traceCtx?.traceId && process.env['GCLOUD_PROJECT']) {
            patched['logging.googleapis.com/trace'] = `projects/${process.env['GCLOUD_PROJECT']}/traces/${traceCtx.traceId}`;
        }
        return super.log(patched, ...rest);
    }
}
const instance = container.resolve(GlobalLogger);
export default instance;

================
File: jina-ai/src/lib/registry.ts
================
import { container } from 'tsyringe';
import { propertyInjectorFactory } from 'civkit/property-injector';
export const InjectProperty = propertyInjectorFactory(container);

================
File: jina-ai/src/patch-express.ts
================
import { ApplicationError, OperationNotAllowedError, Prop, RPC_CALL_ENVIRONMENT } from "civkit/civ-rpc";
import { marshalErrorLike } from "civkit/lang";
import { randomUUID } from "crypto";
import { once } from "events";
import type { NextFunction, Request, Response } from "express";
import { JinaEmbeddingsAuthDTO } from "./dto/jina-embeddings-auth";
import rateLimitControl, { API_CALL_STATUS, APICall, RateLimitDesc } from "./rate-limit";
import asyncLocalContext from "./lib/async-context";
import globalLogger from "./lib/logger";
import { InsufficientBalanceError } from "./lib/errors";
import { firebaseDefaultBucket, FirestoreRecord } from "./lib/firestore";
import cors from "cors";
globalLogger.serviceReady();
const logger = globalLogger.child({ service: 'JinaAISaaSMiddleware' });
const appName = 'DEEPRESEARCH';
export class KnowledgeItem extends FirestoreRecord {
    static override collectionName = 'knowledgeItems';
    @Prop({
        required: true
    })
    traceId!: string;
    @Prop({
        required: true
    })
    uid!: string;
    @Prop({
        default: ''
    })
    question!: string;
    @Prop({
        default: ''
    })
    answer!: string;
    @Prop({
        default: ''
    })
    type!: string;
    @Prop({
        arrayOf: Object,
        default: []
    })
    references!: any[];
    @Prop({
        defaultFactory: () => new Date()
    })
    createdAt!: Date;
    @Prop({
        defaultFactory: () => new Date()
    })
    updatedAt!: Date;
}
const corsMiddleware = cors();
export const jinaAiMiddleware = (req: Request, res: Response, next: NextFunction) => {
    if (req.path === '/ping') {
        res.status(200).end('pone');
        return;
    }
    if (req.path.startsWith('/v1/models')) {
        next();
        return;
    }
    if (req.method !== 'POST' && req.method !== 'GET') {
        next();
        return;
    }
    asyncLocalContext.run(async () => {
        const googleTraceId = req.get('x-cloud-trace-context')?.split('/')?.[0];
        const ctx = asyncLocalContext.ctx;
        ctx.traceId = req.get('x-request-id') || req.get('request-id') || googleTraceId || randomUUID();
        ctx.traceT0 = new Date();
        ctx.ip = req?.ip;
        try {
            const authDto = JinaEmbeddingsAuthDTO.from({
                [RPC_CALL_ENVIRONMENT]: { req, res }
            });
            const uid = await authDto.solveUID();
            if (!uid && !ctx.ip) {
                throw new OperationNotAllowedError(`Missing IP information for anonymous user`);
            }
            let rateLimitPolicy
            if (uid) {
                const user = await authDto.assertUser();
                if (!(user.wallet.total_balance > 0)) {
                    throw new InsufficientBalanceError(`Account balance not enough to run this query, please recharge.`);
                }
                rateLimitPolicy = authDto.getRateLimits(appName) || [
                    parseInt(user.metadata?.speed_level) >= 2 ?
                        RateLimitDesc.from({
                            occurrence: 30,
                            periodSeconds: 60
                        }) :
                        RateLimitDesc.from({
                            occurrence: 10,
                            periodSeconds: 60
                        })
                ];
            } else {
                rateLimitPolicy = [
                    RateLimitDesc.from({
                        occurrence: 3,
                        periodSeconds: 60
                    })
                ]
            }
            const criterions = rateLimitPolicy.map((c) => rateLimitControl.rateLimitDescToCriterion(c));
            await Promise.all(
                criterions.map(
                    ([pointInTime, n]) => uid ?
                        rateLimitControl.assertUidPeriodicLimit(uid, pointInTime, n, appName) :
                        rateLimitControl.assertIPPeriodicLimit(ctx.ip!, pointInTime, n, appName)
                )
            );
            const draftApiCall: Partial<APICall> = { tags: [appName] };
            if (uid) {
                draftApiCall.uid = uid;
            } else {
                draftApiCall.ip = ctx.ip;
            }
            const apiRoll = rateLimitControl.record(draftApiCall);
            apiRoll.save().catch((err) => logger.warn(`Failed to save rate limit record`, { err: marshalErrorLike(err) }));
            const pResClose = once(res, 'close');
            next();
            await pResClose;
            const chargeAmount = ctx.chargeAmount;
            if (chargeAmount) {
                authDto.reportUsage(chargeAmount, `reader-${appName}`).catch((err) => {
                    logger.warn(`Unable to report usage for ${uid || ctx.ip}`, { err: marshalErrorLike(err) });
                });
                apiRoll.chargeAmount = chargeAmount;
            }
            apiRoll.status = res.statusCode === 200 ? API_CALL_STATUS.SUCCESS : API_CALL_STATUS.ERROR;
            apiRoll.save().catch((err) => logger.warn(`Failed to save rate limit record`, { err: marshalErrorLike(err) }));
            logger.info(`HTTP ${res.statusCode} for request ${ctx.traceId} after ${Date.now() - ctx.traceT0.valueOf()}ms`, {
                uid,
                ip: ctx.ip,
                chargeAmount,
            });
            if (uid && ctx.promptContext.knowledge?.length) {
                Promise.all(ctx.promptContext.knowledge.map((x: any) => KnowledgeItem.save(
                    KnowledgeItem.from({
                        ...x,
                        uid,
                        traceId: ctx.traceId,
                    })
                ))).catch((err: any) => {
                    logger.warn(`Failed to save knowledge`, { err: marshalErrorLike(err) });
                });
            }
            if (ctx.promptContext) {
                const patchedCtx = { ...ctx.promptContext };
                if (Array.isArray(patchedCtx.context)) {
                    patchedCtx.context = patchedCtx.context.map((x: object) => ({ ...x, result: undefined }))
                }
                firebaseDefaultBucket.file(`promptContext/${ctx.traceId}.json`).save(
                    JSON.stringify(patchedCtx),
                    {
                        metadata: {
                            contentType: 'application/json',
                        },
                    }
                ).catch((err: any) => {
                    logger.warn(`Failed to save promptContext`, { err: marshalErrorLike(err) });
                });
            }
        } catch (err: any) {
            if (!res.headersSent) {
                corsMiddleware(req, res, () => 'noop');
                if (err instanceof ApplicationError) {
                    res.status(parseInt(err.code as string) || 500).json({ error: err.message });
                    return;
                }
                res.status(500).json({ error: 'Internal' });
            }
            logger.error(`Error in billing middleware`, { err: marshalErrorLike(err) });
            if (err.stack) {
                logger.error(err.stack);
            }
        }
    });
}

================
File: jina-ai/src/rate-limit.ts
================
import { AutoCastable, ResourcePolicyDenyError, Also, Prop } from 'civkit/civ-rpc';
import { AsyncService } from 'civkit/async-service';
import { getTraceId } from 'civkit/async-context';
import { singleton, container } from 'tsyringe';
import { RateLimitTriggeredError } from './lib/errors';
import { FirestoreRecord } from './lib/firestore';
import { GlobalLogger } from './lib/logger';
export enum API_CALL_STATUS {
    SUCCESS = 'success',
    ERROR = 'error',
    PENDING = 'pending',
}
@Also({ dictOf: Object })
export class APICall extends FirestoreRecord {
    static override collectionName = 'apiRoll';
    @Prop({
        required: true,
        defaultFactory: () => getTraceId()
    })
    traceId!: string;
    @Prop()
    uid?: string;
    @Prop()
    ip?: string;
    @Prop({
        arrayOf: String,
        default: [],
    })
    tags!: string[];
    @Prop({
        required: true,
        defaultFactory: () => new Date(),
    })
    createdAt!: Date;
    @Prop()
    completedAt?: Date;
    @Prop({
        required: true,
        default: API_CALL_STATUS.PENDING,
    })
    status!: API_CALL_STATUS;
    @Prop({
        required: true,
        defaultFactory: () => new Date(Date.now() + 1000 * 60 * 60 * 24 * 90),
    })
    expireAt!: Date;
    [k: string]: any;
    tag(...tags: string[]) {
        for (const t of tags) {
            if (!this.tags.includes(t)) {
                this.tags.push(t);
            }
        }
    }
    save() {
        return (this.constructor as typeof APICall).save(this);
    }
}
export class RateLimitDesc extends AutoCastable {
    @Prop({
        default: 1000
    })
    occurrence!: number;
    @Prop({
        default: 3600
    })
    periodSeconds!: number;
    @Prop()
    notBefore?: Date;
    @Prop()
    notAfter?: Date;
    isEffective() {
        const now = new Date();
        if (this.notBefore && this.notBefore > now) {
            return false;
        }
        if (this.notAfter && this.notAfter < now) {
            return false;
        }
        return true;
    }
}
@singleton()
export class RateLimitControl extends AsyncService {
    logger = this.globalLogger.child({ service: this.constructor.name });
    constructor(
        protected globalLogger: GlobalLogger,
    ) {
        super(...arguments);
    }
    override async init() {
        await this.dependencyReady();
        this.emit('ready');
    }
    async queryByUid(uid: string, pointInTime: Date, ...tags: string[]) {
        let q = APICall.COLLECTION
            .orderBy('createdAt', 'asc')
            .where('createdAt', '>=', pointInTime)
            .where('status', 'in', [API_CALL_STATUS.SUCCESS, API_CALL_STATUS.PENDING])
            .where('uid', '==', uid);
        if (tags.length) {
            q = q.where('tags', 'array-contains-any', tags);
        }
        return APICall.fromFirestoreQuery(q);
    }
    async queryByIp(ip: string, pointInTime: Date, ...tags: string[]) {
        let q = APICall.COLLECTION
            .orderBy('createdAt', 'asc')
            .where('createdAt', '>=', pointInTime)
            .where('status', 'in', [API_CALL_STATUS.SUCCESS, API_CALL_STATUS.PENDING])
            .where('ip', '==', ip);
        if (tags.length) {
            q = q.where('tags', 'array-contains-any', tags);
        }
        return APICall.fromFirestoreQuery(q);
    }
    async assertUidPeriodicLimit(uid: string, pointInTime: Date, limit: number, ...tags: string[]) {
        if (limit <= 0) {
            throw new ResourcePolicyDenyError(`This UID(${uid}) is not allowed to call this endpoint (rate limit quota is 0).`);
        }
        let q = APICall.COLLECTION
            .orderBy('createdAt', 'asc')
            .where('createdAt', '>=', pointInTime)
            .where('status', 'in', [API_CALL_STATUS.SUCCESS, API_CALL_STATUS.PENDING])
            .where('uid', '==', uid);
        if (tags.length) {
            q = q.where('tags', 'array-contains-any', tags);
        }
        const count = (await q.count().get()).data().count;
        if (count >= limit) {
            const r = await APICall.fromFirestoreQuery(q.limit(1));
            const [r1] = r;
            const dtMs = Math.abs(r1.createdAt?.valueOf() - pointInTime.valueOf());
            const dtSec = Math.ceil(dtMs / 1000);
            throw RateLimitTriggeredError.from({
                message: `Per UID rate limit exceeded (${tags.join(',') || 'called'} ${limit} times since ${pointInTime})`,
                retryAfter: dtSec,
            });
        }
        return count + 1;
    }
    async assertIPPeriodicLimit(ip: string, pointInTime: Date, limit: number, ...tags: string[]) {
        let q = APICall.COLLECTION
            .orderBy('createdAt', 'asc')
            .where('createdAt', '>=', pointInTime)
            .where('status', 'in', [API_CALL_STATUS.SUCCESS, API_CALL_STATUS.PENDING])
            .where('ip', '==', ip);
        if (tags.length) {
            q = q.where('tags', 'array-contains-any', tags);
        }
        const count = (await q.count().get()).data().count;
        if (count >= limit) {
            const r = await APICall.fromFirestoreQuery(q.limit(1));
            const [r1] = r;
            const dtMs = Math.abs(r1.createdAt?.valueOf() - pointInTime.valueOf());
            const dtSec = Math.ceil(dtMs / 1000);
            throw RateLimitTriggeredError.from({
                message: `Per IP rate limit exceeded (${tags.join(',') || 'called'} ${limit} times since ${pointInTime})`,
                retryAfter: dtSec,
            });
        }
        return count + 1;
    }
    record(partialRecord: Partial<APICall>) {
        const record = APICall.from(partialRecord);
        const newId = APICall.COLLECTION.doc().id;
        record._id = newId;
        return record;
    }
    // async simpleRPCUidBasedLimit(rpcReflect: RPCReflection, uid: string, tags: string[] = [],
    //     ...inputCriterion: RateLimitDesc[] | [Date, number][]) {
    //     const criterion = inputCriterion.map((c) => { return Array.isArray(c) ? c : this.rateLimitDescToCriterion(c); });
    //     await Promise.all(criterion.map(([pointInTime, n]) =>
    //         this.assertUidPeriodicLimit(uid, pointInTime, n, ...tags)));
    //     const r = this.record({
    //         uid,
    //         tags,
    //     });
    //     r.save().catch((err) => this.logger.warn(`Failed to save rate limit record`, { err }));
    //     rpcReflect.then(() => {
    //         r.status = API_CALL_STATUS.SUCCESS;
    //         r.save()
    //             .catch((err) => this.logger.warn(`Failed to save rate limit record`, { err }));
    //     });
    //     rpcReflect.catch((err) => {
    //         r.status = API_CALL_STATUS.ERROR;
    //         r.error = err.toString();
    //         r.save()
    //             .catch((err) => this.logger.warn(`Failed to save rate limit record`, { err }));
    //     });
    //     return r;
    // }
    rateLimitDescToCriterion(rateLimitDesc: RateLimitDesc) {
        return [new Date(Date.now() - rateLimitDesc.periodSeconds * 1000), rateLimitDesc.occurrence] as [Date, number];
    }
    // async simpleRpcIPBasedLimit(rpcReflect: RPCReflection, ip: string, tags: string[] = [],
    //     ...inputCriterion: RateLimitDesc[] | [Date, number][]) {
    //     const criterion = inputCriterion.map((c) => { return Array.isArray(c) ? c : this.rateLimitDescToCriterion(c); });
    //     await Promise.all(criterion.map(([pointInTime, n]) =>
    //         this.assertIPPeriodicLimit(ip, pointInTime, n, ...tags)));
    //     const r = this.record({
    //         ip,
    //         tags,
    //     });
    //     r.save().catch((err) => this.logger.warn(`Failed to save rate limit record`, { err }));
    //     rpcReflect.then(() => {
    //         r.status = API_CALL_STATUS.SUCCESS;
    //         r.save()
    //             .catch((err) => this.logger.warn(`Failed to save rate limit record`, { err }));
    //     });
    //     rpcReflect.catch((err) => {
    //         r.status = API_CALL_STATUS.ERROR;
    //         r.error = err.toString();
    //         r.save()
    //             .catch((err) => this.logger.warn(`Failed to save rate limit record`, { err }));
    //     });
    //     return r;
    // }
}
const instance = container.resolve(RateLimitControl);
export default instance;

================
File: jina-ai/src/server.ts
================
import 'reflect-metadata'
import express from 'express';
import { jinaAiMiddleware } from "./patch-express";
import { Server } from 'http';
const app = require('../..').default;
const rootApp = express();
rootApp.set('trust proxy', true);
rootApp.use(jinaAiMiddleware, app);
const port = process.env.PORT || 3000;
let server: Server | undefined;
// Export server startup function for better testing
export function startServer() {
  return rootApp.listen(port, () => {
    console.log(`Server running at http://localhost:${port}`);
  });
}
// Start server if running directly
if (process.env.NODE_ENV !== 'test') {
  server = startServer();
}
process.on('unhandledRejection', (_err) => `Is false alarm`);
process.on('uncaughtException', (err) => {
  console.log('Uncaught exception', err);
  // Looks like Firebase runtime does not handle error properly.
  // Make sure to quit the process.
  process.nextTick(() => process.exit(1));
  console.error('Uncaught exception, process quit.');
  throw err;
});
const sigHandler = (signal: string) => {
  console.log(`Received ${signal}, exiting...`);
  if (server && server.listening) {
    console.log(`Shutting down gracefully...`);
    console.log(`Waiting for the server to drain and close...`);
    server.close((err) => {
      if (err) {
        console.error('Error while closing server', err);
        return;
      }
      process.exit(0);
    });
    server.closeIdleConnections();
  }
}
process.on('SIGTERM', sigHandler);
process.on('SIGINT', sigHandler);

================
File: jina-ai/.dockerignore
================
node_modules

================
File: jina-ai/config.json
================
{
  "env": {
    "https_proxy": "",
    "OPENAI_BASE_URL": "",
    "GEMINI_API_KEY": "",
    "OPENAI_API_KEY": "",
    "JINA_API_KEY": "",
    "BRAVE_API_KEY": "",
    "SERPER_API_KEY": "",
    "DEFAULT_MODEL_NAME": ""
  },
  "defaults": {
    "search_provider": "serper",
    "llm_provider": "vertex",
    "step_sleep": 100
  },
  "providers": {
    "vertex": {
      "createClient": "createGoogleVertex",
      "clientConfig": {
        "location": "us-central1"
      }
    },
    "gemini": {
      "createClient": "createGoogleGenerativeAI"
    },
    "openai": {
      "createClient": "createOpenAI",
      "clientConfig": {
        "compatibility": "strict"
      }
    }
  },
  "models": {
    "gemini": {
      "default": {
        "model": "gemini-2.0-flash",
        "temperature": 0,
        "maxTokens": 8000
      },
      "tools": {
        "coder": { "temperature": 0.6, "maxTokens": 1000 },
        "searchGrounding": { "temperature": 0 },
        "dedup": { "temperature": 0.1 },
        "evaluator": {"temperature":  0.6, "maxTokens": 300},
        "errorAnalyzer": {"maxTokens": 500},
        "queryRewriter": { "temperature": 0.1, "maxTokens": 500 },
        "agent": { "temperature": 0.6 },
        "agentBeastMode": { "temperature": 0.6 },
        "fallback": { "temperature": 0, "maxTokens": 4000}
      }
    },
    "openai": {
      "default": {
        "model": "gpt-4o-mini",
        "temperature": 0,
        "maxTokens": 8000
      },
      "tools": {
        "coder": { "temperature": 0.7 },
        "searchGrounding": { "temperature": 0 },
        "dedup": { "temperature": 0.1 },
        "evaluator": {},
        "errorAnalyzer": {},
        "queryRewriter": { "temperature": 0.1 },
        "agent": { "temperature": 0.7 },
        "agentBeastMode": { "temperature": 0.7 },
        "fallback": { "temperature": 0 }
      }
    }
  }
}

================
File: jina-ai/Dockerfile
================
# ---- BUILD STAGE ----
FROM node:22-slim AS builder

# Set working directory
WORKDIR /app

# Copy package.json and package-lock.json
COPY ./package*.json ./
COPY ./jina-ai/package*.json ./jina-ai/

# Install dependencies
RUN npm ci
WORKDIR /app/jina-ai
RUN npm ci

WORKDIR /app

# Copy application code
COPY ./src ./src
COPY ./tsconfig.json ./tsconfig.json
COPY ./jina-ai/config.json ./
RUN npm run build

COPY ./jina-ai/src ./jina-ai/src
COPY ./jina-ai/tsconfig.json ./jina-ai/tsconfig.json
WORKDIR /app/jina-ai
RUN npm run build

# ---- PRODUCTION STAGE ----
FROM node:22 AS production

# Set working directory
WORKDIR /app

COPY --from=builder /app ./
# Copy config.json and built files from builder

WORKDIR /app/jina-ai

# Set environment variables (Recommended to set at runtime, avoid hardcoding)
ENV GEMINI_API_KEY=${GEMINI_API_KEY}
ENV OPENAI_API_KEY=${OPENAI_API_KEY}
ENV JINA_API_KEY=${JINA_API_KEY}
ENV BRAVE_API_KEY=${BRAVE_API_KEY}

# Expose the port the app runs on
EXPOSE 3000

# Set startup command
CMD ["node", "./dist/server.js"]

================
File: jina-ai/package.json
================
{
  "name": "@jina-ai/node-deepresearch",
  "version": "1.0.0",
  "main": "dist/app.js",
  "files": [
    "dist",
    "README.md",
    "LICENSE"
  ],
  "scripts": {
    "build": "tsc",
    "dev": "npx ts-node src/agent.ts",
    "search": "npx ts-node src/test-duck.ts",
    "rewrite": "npx ts-node src/tools/query-rewriter.ts",
    "lint": "eslint . --ext .ts",
    "lint:fix": "eslint . --ext .ts --fix",
    "serve": "ts-node src/server.ts",
    "eval": "ts-node src/evals/batch-evals.ts",
    "test": "jest --testTimeout=30000",
    "test:watch": "jest --watch"
  },
  "keywords": [],
  "author": "Jina AI",
  "license": "Apache-2.0",
  "description": "",
  "dependencies": {
    "@ai-sdk/google-vertex": "^2.1.12",
    "@google-cloud/firestore": "^7.11.0",
    "@google-cloud/storage": "^7.15.1",
    "civkit": "^0.8.3-15926cb",
    "dayjs": "^1.11.13",
    "lodash": "^4.17.21",
    "reflect-metadata": "^0.2.2",
    "tsyringe": "^4.8.0"
  },
  "devDependencies": {
    "@types/lodash": "^4.17.15",
    "pino-pretty": "^13.0.0"
  }
}

================
File: jina-ai/tsconfig.json
================
{
    "compilerOptions": {
      "target": "ES2020",
      "module": "node16",
      "outDir": "./dist",
      "rootDir": "./src",
      "sourceMap": true,
      "esModuleInterop": true,
      "skipLibCheck": true,
      "forceConsistentCasingInFileNames": true,
      "strict": true,
      "experimentalDecorators": true,
      "emitDecoratorMetadata": true,
      "resolveJsonModule": true
    }
  }

================
File: src/__tests__/agent.test.ts
================
import { getResponse } from '../agent';
import { generateObject } from 'ai';
import { search } from '../tools/jina-search';
import { readUrl } from '../tools/read';
// Mock external dependencies
jest.mock('ai', () => ({
  generateObject: jest.fn()
}));
jest.mock('../tools/jina-search', () => ({
  search: jest.fn()
}));
jest.mock('../tools/read', () => ({
  readUrl: jest.fn()
}));
describe('getResponse', () => {
  beforeEach(() => {
    // Mock generateObject to return a valid response
    (generateObject as jest.Mock).mockResolvedValue({
      object: { action: 'answer', answer: 'mocked response', references: [], think: 'mocked thought' },
      usage: { totalTokens: 100 }
    });
    // Mock search to return empty results
    (search as jest.Mock).mockResolvedValue({
      response: { data: [] }
    });
    // Mock readUrl to return empty content
    (readUrl as jest.Mock).mockResolvedValue({
      response: { data: { content: '', url: 'test-url' } },
      tokens: 0
    });
  });
  afterEach(() => {
    jest.useRealTimers();
    jest.clearAllMocks();
  });
  it('should handle search action', async () => {
    const result = await getResponse('What is TypeScript?', 50000); // Increased token budget to handle real-world usage
    expect(result.result.action).toBeDefined();
    expect(result.context).toBeDefined();
    expect(result.context.tokenTracker).toBeDefined();
    expect(result.context.actionTracker).toBeDefined();
  }, 30000);
});

================
File: src/__tests__/docker.test.ts
================
import { exec } from 'child_process';
import { promisify } from 'util';
const execAsync = promisify(exec);
describe('Docker build', () => {
  jest.setTimeout(300000); // 5 minutes for build
  it('should build Docker image successfully', async () => {
    const { stderr } = await execAsync('docker build -t node-deepresearch-test .');
    expect(stderr).not.toContain('error');
  });
  it('should start container and respond to health check', async () => {
    // Start container with mock API keys
    await execAsync(
      'docker run -d --name test-container -p 3001:3000 ' +
      '-e GEMINI_API_KEY=mock_key ' +
      '-e JINA_API_KEY=mock_key ' +
      'node-deepresearch-test'
    );
    // Wait for container to start
    await new Promise(resolve => setTimeout(resolve, 5000));
    try {
      // Check if server responds
      const { stdout } = await execAsync('curl -s http://localhost:3001/health');
      expect(stdout).toContain('ok');
    } finally {
      // Cleanup
      await execAsync('docker rm -f test-container').catch(console.error);
    }
  });
  afterAll(async () => {
    // Clean up any leftover containers
    await execAsync('docker rm -f test-container').catch(() => {});
    await execAsync('docker rmi node-deepresearch-test').catch(() => {});
  });
});

================
File: src/__tests__/server.test.ts
================
import request from 'supertest';
import { EventEmitter } from 'events';
import type { Express } from 'express';
const TEST_SECRET = 'test-secret';
let app: Express;
describe('/v1/chat/completions', () => {
  jest.setTimeout(120000); // Increase timeout for all tests in this suite
  beforeEach(async () => {
    // Set up test environment
    process.env.NODE_ENV = 'test';
    process.env.LLM_PROVIDER = 'openai'; // Use OpenAI provider for tests
    process.env.OPENAI_API_KEY = 'test-key';
    process.env.JINA_API_KEY = 'test-key';
    // Clean up any existing secret
    const existingSecretIndex = process.argv.findIndex(arg => arg.startsWith('--secret='));
    if (existingSecretIndex !== -1) {
      process.argv.splice(existingSecretIndex, 1);
    }
    // Set up test secret and import server module
    process.argv.push(`--secret=${TEST_SECRET}`);
    // Import server module (jest.resetModules() is called automatically before each test)
    const { default: serverModule } = await require('../app');
    app = serverModule;
  });
  afterEach(async () => {
    // Clean up environment variables
    delete process.env.OPENAI_API_KEY;
    delete process.env.JINA_API_KEY;
    // Clean up any remaining event listeners
    const emitter = EventEmitter.prototype;
    emitter.removeAllListeners();
    emitter.setMaxListeners(emitter.getMaxListeners() + 1);
    // Clean up test secret
    const secretIndex = process.argv.findIndex(arg => arg.startsWith('--secret='));
    if (secretIndex !== -1) {
      process.argv.splice(secretIndex, 1);
    }
    // Wait for any pending promises to settle
    await new Promise(resolve => setTimeout(resolve, 500));
    // Reset module cache to ensure clean state
    jest.resetModules();
  });
  it('should require authentication when secret is set', async () => {
    // Note: secret is already set in beforeEach
    const response = await request(app)
      .post('/v1/chat/completions')
      .send({
        model: 'test-model',
        messages: [{ role: 'user', content: 'test' }]
      });
    expect(response.status).toBe(401);
  });
  it('should allow requests without auth when no secret is set', async () => {
    // Remove secret for this test
    const secretIndex = process.argv.findIndex(arg => arg.startsWith('--secret='));
    if (secretIndex !== -1) {
      process.argv.splice(secretIndex, 1);
    }
    // Reset module cache to ensure clean state
    jest.resetModules();
    // Reload server module without secret
    const { default: serverModule } = await require('../app');
    app = serverModule;
    const response = await request(app)
      .post('/v1/chat/completions')
      .send({
        model: 'test-model',
        messages: [{ role: 'user', content: 'test' }]
      });
    expect(response.status).toBe(200);
  });
  it('should reject requests without user message', async () => {
    const response = await request(app)
      .post('/v1/chat/completions')
      .set('Authorization', `Bearer ${TEST_SECRET}`)
      .send({
        model: 'test-model',
        messages: [{ role: 'developer', content: 'test' }]
      });
    expect(response.status).toBe(400);
    expect(response.body.error).toBe('Last message must be from user');
  });
  it('should handle non-streaming request', async () => {
    const response = await request(app)
      .post('/v1/chat/completions')
      .set('Authorization', `Bearer ${TEST_SECRET}`)
      .send({
        model: 'test-model',
        messages: [{ role: 'user', content: 'test' }]
      });
    expect(response.status).toBe(200);
    expect(response.body).toMatchObject({
      object: 'chat.completion',
      choices: [{
        message: {
          role: 'assistant'
        }
      }]
    });
  });
  it('should handle streaming request and track tokens correctly', async () => {
    return new Promise<void>((resolve, reject) => {
      let isDone = false;
      let totalCompletionTokens = 0;
      const cleanup = () => {
        clearTimeout(timeoutHandle);
        isDone = true;
        resolve();
      };
      const timeoutHandle = setTimeout(() => {
        if (!isDone) {
          cleanup();
          reject(new Error('Test timed out'));
        }
      }, 30000);
      request(app)
        .post('/v1/chat/completions')
        .set('Authorization', `Bearer ${TEST_SECRET}`)
        .send({
          model: 'test-model',
          messages: [{ role: 'user', content: 'test' }],
          stream: true
        })
        .buffer(true)
        .parse((res, callback) => {
          const response = res as unknown as {
            on(event: 'data', listener: (chunk: Buffer) => void): void;
            on(event: 'end', listener: () => void): void;
            on(event: 'error', listener: (err: Error) => void): void;
          };
          let responseData = '';
          response.on('error', (err) => {
            cleanup();
            callback(err, null);
          });
          response.on('data', (chunk) => {
            responseData += chunk.toString();
          });
          response.on('end', () => {
            try {
              callback(null, responseData);
            } catch (err) {
              cleanup();
              callback(err instanceof Error ? err : new Error(String(err)), null);
            }
          });
        })
        .end((err, res) => {
          if (err) return reject(err);
          expect(res.status).toBe(200);
          expect(res.headers['content-type']).toBe('text/event-stream');
          // Verify stream format and content
          if (isDone) return; // Prevent multiple resolves
          const responseText = res.body as string;
          const chunks = responseText
            .split('\n\n')
            .filter((line: string) => line.startsWith('data: '))
            .map((line: string) => JSON.parse(line.replace('data: ', '')));
          // Process all chunks
          expect(chunks.length).toBeGreaterThan(0);
          // Verify initial chunk format
          expect(chunks[0]).toMatchObject({
            id: expect.any(String),
            object: 'chat.completion.chunk',
            choices: [{
              index: 0,
              delta: { role: 'assistant' },
              logprobs: null,
              finish_reason: null
            }]
          });
          // Verify content chunks have content
          chunks.slice(1).forEach(chunk => {
            const content = chunk.choices[0].delta.content;
            if (content && content.trim()) {
              totalCompletionTokens += 1; // Count 1 token per chunk as per Vercel convention
            }
            expect(chunk).toMatchObject({
              object: 'chat.completion.chunk',
              choices: [{
                delta: expect.objectContaining({
                  content: expect.any(String)
                })
              }]
            });
          });
          // Verify final chunk format if present
          const lastChunk = chunks[chunks.length - 1];
          if (lastChunk?.choices?.[0]?.finish_reason === 'stop') {
            expect(lastChunk).toMatchObject({
              object: 'chat.completion.chunk',
              choices: [{
                delta: {},
                finish_reason: 'stop'
              }]
            });
          }
          // Verify we tracked some completion tokens
          expect(totalCompletionTokens).toBeGreaterThan(0);
          // Clean up and resolve
          if (!isDone) {
            cleanup();
          }
        });
    });
  });
  it('should track tokens correctly in error response', async () => {
    const response = await request(app)
      .post('/v1/chat/completions')
      .set('Authorization', `Bearer ${TEST_SECRET}`)
      .send({
        model: 'test-model',
        messages: [] // Invalid messages array
      });
    expect(response.status).toBe(400);
    expect(response.body).toHaveProperty('error');
    expect(response.body.error).toBe('Messages array is required and must not be empty');
    // Make another request to verify token tracking after error
    const validResponse = await request(app)
      .post('/v1/chat/completions')
      .set('Authorization', `Bearer ${TEST_SECRET}`)
      .send({
        model: 'test-model',
        messages: [{ role: 'user', content: 'test' }]
      });
    // Verify token tracking still works after error
    expect(validResponse.body.usage).toMatchObject({
      prompt_tokens: expect.any(Number),
      completion_tokens: expect.any(Number),
      total_tokens: expect.any(Number)
    });
    // Basic token tracking structure should be present
    expect(validResponse.body.usage.total_tokens).toBe(
      validResponse.body.usage.prompt_tokens + validResponse.body.usage.completion_tokens
    );
  });
  it('should provide token usage in Vercel AI SDK format', async () => {
    const response = await request(app)
      .post('/v1/chat/completions')
      .set('Authorization', `Bearer ${TEST_SECRET}`)
      .send({
        model: 'test-model',
        messages: [{ role: 'user', content: 'test' }]
      });
    expect(response.status).toBe(200);
    const usage = response.body.usage;
    expect(usage).toMatchObject({
      prompt_tokens: expect.any(Number),
      completion_tokens: expect.any(Number),
      total_tokens: expect.any(Number)
    });
    // Basic token tracking structure should be present
    expect(usage.total_tokens).toBe(
      usage.prompt_tokens + usage.completion_tokens
    );
  });
});

================
File: src/evals/batch-evals.ts
================
import fs from 'fs/promises';
import {exec} from 'child_process';
import {promisify} from 'util';
import {getResponse} from '../agent';
import {generateObject} from 'ai';
import {GEMINI_API_KEY} from '../config';
import {z} from 'zod';
import {AnswerAction, TrackerContext} from "../types";
import {createGoogleGenerativeAI} from "@ai-sdk/google";
const execAsync = promisify(exec);
interface Question {
  question: string;
  answer: string;
}
interface EvaluationResult {
  pass: boolean;
  reason: string;
  total_steps: number;
  total_tokens: number;
  question: string;
  expected_answer: string;
  actual_answer: string;
}
interface EvaluationStats {
  model_name: string;
  pass_rate: number;
  avg_steps: number;
  max_steps: number;
  min_steps: number;
  median_steps: number;
  avg_tokens: number;
  median_tokens: number;
  max_tokens: number;
  min_tokens: number;
}
function calculateMedian(numbers: number[]): number {
  const sorted = [...numbers].sort((a, b) => a - b);
  const middle = Math.floor(sorted.length / 2);
  if (sorted.length % 2 === 0) {
    return (sorted[middle - 1] + sorted[middle]) / 2;
  }
  return sorted[middle];
}
function calculateStats(results: EvaluationResult[], modelName: string): EvaluationStats {
  const steps = results.map(r => r.total_steps);
  const tokens = results.map(r => r.total_tokens);
  const passCount = results.filter(r => r.pass).length;
  return {
    model_name: modelName,
    pass_rate: (passCount / results.length) * 100,
    avg_steps: steps.reduce((a, b) => a + b, 0) / steps.length,
    max_steps: Math.max(...steps),
    min_steps: Math.min(...steps),
    median_steps: calculateMedian(steps),
    avg_tokens: tokens.reduce((a, b) => a + b, 0) / tokens.length,
    median_tokens: calculateMedian(tokens),
    max_tokens: Math.max(...tokens),
    min_tokens: Math.min(...tokens)
  };
}
function printStats(stats: EvaluationStats): void {
  console.log('\n=== Evaluation Statistics ===');
  console.log(`Model: ${stats.model_name}`);
  console.log(`Pass Rate: ${stats.pass_rate.toFixed(0)}%`);
  console.log(`Average Steps: ${stats.avg_steps.toFixed(0)}`);
  console.log(`Maximum Steps: ${stats.max_steps}`);
  console.log(`Minimum Steps: ${stats.min_steps}`);
  console.log(`Median Steps: ${stats.median_steps.toFixed(0)}`);
  console.log(`Average Tokens: ${stats.avg_tokens.toFixed(0)}`);
  console.log(`Median Tokens: ${stats.median_tokens.toFixed(0)}`);
  console.log(`Maximum Tokens: ${stats.max_tokens}`);
  console.log(`Minimum Tokens: ${stats.min_tokens}`);
  console.log('===========================\n');
}
async function getCurrentGitCommit(): Promise<string> {
  try {
    const {stdout} = await execAsync('git rev-parse --short HEAD');
    return stdout.trim();
  } catch (error) {
    console.error('Error getting git commit:', error);
    return 'unknown';
  }
}
async function evaluateAnswer(expectedAnswer: string, actualAnswer: string): Promise<{ pass: boolean; reason: string }> {
  const prompt = `You are a deterministic evaluator with zero temperature. Compare the following expected answer with the actual answer and determine if they convey the same information.
Expected answer: ${expectedAnswer}
Actual answer: ${actualAnswer}
Minor wording differences are acceptable as long as the core information of the expected answer is preserved in the actual answer.'`;
  const schema = z.object({
    pass: z.boolean().describe('Whether the actual answer matches the expected answer'),
    reason: z.string().describe('Detailed explanation of why the evaluation passed or failed')
  });
  try {
    const result = await generateObject({
      model: createGoogleGenerativeAI({ apiKey: GEMINI_API_KEY })('gemini-2.0-flash'),  // fix to gemini-2.0-flash for evaluation
      schema,
      prompt,
      maxTokens: 1000,
      temperature: 0  // Setting temperature to 0 for deterministic output
    });
    return result.object;
  } catch (error) {
    console.error('Evaluation failed:', error);
    return {
      pass: false,
      reason: `Evaluation error: ${error}`
    };
  }
}
async function batchEvaluate(inputFile: string): Promise<void> {
  // Read and parse input file
  const questions: Question[] = JSON.parse(await fs.readFile(inputFile, 'utf-8'));
  const results: EvaluationResult[] = [];
  const gitCommit = await getCurrentGitCommit();
  const modelName = process.env.DEFAULT_MODEL_NAME || 'unknown';
  const outputFile = `eval-${gitCommit}-${modelName}.json`;
  // Process each question
  for (let i = 0; i < questions.length; i++) {
    const {question, answer: expectedAnswer} = questions[i];
    console.log(`\nProcessing question ${i + 1}/${questions.length}: ${question}`);
    try {
      // Get response using the agent
      const {
        result: response,
        context
      } = await getResponse(question) as { result: AnswerAction; context: TrackerContext };
      // Get response using the streaming agent
      // const {
      //   result: response,
      //   context
      // } = await getResponseStreamingAgent(question) as { result: AnswerAction; context: TrackerContext };
      const actualAnswer = response.answer;
      // Evaluate the response
      const evaluation = await evaluateAnswer(expectedAnswer, actualAnswer);
      // Record results
      results.push({
        pass: evaluation.pass,
        reason: evaluation.reason,
        total_steps: context.actionTracker.getState().totalStep,
        total_tokens: context.tokenTracker.getTotalUsage().totalTokens,
        question,
        expected_answer: expectedAnswer,
        actual_answer: actualAnswer
      });
      console.log(`Evaluation: ${evaluation.pass ? 'PASS' : 'FAIL'}`);
      console.log(`Reason: ${evaluation.reason}`);
    } catch (error) {
      console.error(`Error processing question: ${question}`, error);
      results.push({
        pass: false,
        reason: `Error: ${error}`,
        total_steps: 0,
        total_tokens: 0,
        question,
        expected_answer: expectedAnswer,
        actual_answer: 'Error occurred'
      });
    }
  }
  // Calculate and print statistics
  const stats = calculateStats(results, modelName);
  printStats(stats);
  // Save results
  await fs.writeFile(outputFile, JSON.stringify({
    results,
    statistics: stats
  }, null, 2));
  console.log(`\nEvaluation results saved to ${outputFile}`);
}
// Run batch evaluation if this is the main module
if (require.main === module) {
  const inputFile = process.argv[2];
  if (!inputFile) {
    console.error('Please provide an input file path');
    process.exit(1);
  }
  batchEvaluate(inputFile).catch(console.error);
}
export {batchEvaluate};

================
File: src/evals/ego-questions.json
================
[
  {
    "question": "what did jina ai ceo say about deepseek that went viral and become a meme?",
    "answer": "a side project"
  },
  {
    "question": "when was jina ai founded, month and year?",
    "answer": "feb 2020"
  },
  {
    "question": "what is the latest model published by jina ai?",
    "answer": "ReaderLM-2.0"
  },
  {
    "question": "what is the latest blog post that jina ai published?",
    "answer": "A Practical Guide to Deploying Search Foundation Models in Production"
  },
  {
    "question": "what is the context length of readerlm-v2?",
    "answer": "512K"
  },
  {
    "question": "how many employees does jina ai have right now?",
    "answer": "30"
  },
  {
    "question": "when was jina reader api released?",
    "answer": "April 2024"
  },
  {
    "question": "How many offices do Jina AI have and where are they?",
    "answer": "four: sunnyvale, berlin, beijing, shenzhen"
  },
  {
    "question": "what exactly jina-colbert-v2 improves over jina-colbert-v1?",
    "answer": "v2 add multilingual support"
  },
  {
    "question": "who are the authors of jina-clip-v2 paper?",
    "answer": "Andreas Koukounas, Georgios Mastrapas, Bo Wang, Mohammad Kalim Akram, Sedigheh Eslami, Michael Gnther, Isabelle Mohr, Saba Sturua, Scott Martens, Nan Wang, Han Xiao"
  },
  {
    "question": "who created the node-deepresearch project?",
    "answer": "Han Xiao / jina ai"
  },
  {
    "question": "Which countries are the investors of Jina AI from?",
    "answer": "USA and China only, no German investors"
  },
  {
    "question": "what is the grounding api endpoint of jina ai?",
    "answer": "g.jina.ai"
  },
  {
    "question": "which of the following models do not support Matryoshka representation? jina-embeddings-v3, jina-embeddings-v2-base-en, jina-clip-v2, jina-clip-v1",
    "answer": "jina-embeddings-v2-base-en and jina-clip-v1"
  },
  {
    "question": "Can I purchase the 2024 yearbook that jina ai published today?",
    "answer": "No it is sold out."
  },
  {
    "question": "How many free tokens do you get from a new jina api key?",
    "answer": "1 million."
  },
  {
    "question": "Who is the legal signatory of Jina AI gmbh?",
    "answer": "Jiao Liu"
  },
  {
    "question": "what is the key idea behind node-deepresearch project?",
    "answer": "It keeps searching, reading webpages, reasoning until an answer is found."
  },
  {
    "question": "what is the name of the jina ai's mascot?",
    "answer": "No, Jina AI does not have a mascot."
  },
  {
    "question": "Does late chunking work with cls pooling?",
    "answer": "No. late chunking only works with mean pooling."
  }
]

================
File: src/tools/__tests__/error-analyzer.test.ts
================
import { analyzeSteps } from '../error-analyzer';
import { LLMProvider } from '../../config';
describe('analyzeSteps', () => {
  const providers: Array<LLMProvider> = ['openai', 'gemini'];
  const originalEnv = process.env;
  beforeEach(() => {
    jest.resetModules();
    process.env = { ...originalEnv };
  });
  afterEach(() => {
    process.env = originalEnv;
  });
  providers.forEach(provider => {
    describe(`with ${provider} provider`, () => {
      beforeEach(() => {
        process.env.LLM_PROVIDER = provider;
      });
      it('should analyze error steps', async () => {
        const { response } = await analyzeSteps(['Step 1: Search failed', 'Step 2: Invalid query']);
        expect(response).toHaveProperty('recap');
        expect(response).toHaveProperty('blame');
        expect(response).toHaveProperty('improvement');
      }, 30000);
    });
  });
});

================
File: src/tools/__tests__/evaluator.test.ts
================
import { evaluateAnswer } from '../evaluator';
import { TokenTracker } from '../../utils/token-tracker';
import { LLMProvider } from '../../config';
describe('evaluateAnswer', () => {
  const providers: Array<LLMProvider> = ['openai', 'gemini'];
  const originalEnv = process.env;
  beforeEach(() => {
    jest.resetModules();
    process.env = { ...originalEnv };
  });
  afterEach(() => {
    process.env = originalEnv;
  });
  providers.forEach(provider => {
    describe(`with ${provider} provider`, () => {
      beforeEach(() => {
        process.env.LLM_PROVIDER = provider;
      });
      it('should evaluate answer definitiveness', async () => {
        const tokenTracker = new TokenTracker();
        const { response } = await evaluateAnswer(
          'What is TypeScript?',
          {
            action: "answer",
            think: "Providing a clear definition of TypeScript",
            answer: "TypeScript is a strongly typed programming language that builds on JavaScript.",
            references: []
          },
          ['definitive'],
          tokenTracker
        );
        expect(response).toHaveProperty('pass');
        expect(response).toHaveProperty('think');
        expect(response.type).toBe('definitive');
      });
      it('should evaluate answer plurality', async () => {
        const tokenTracker = new TokenTracker();
        const { response } = await evaluateAnswer(
          'List three programming languages.',
          {
            action: "answer",
            think: "Providing an example of a programming language",
            answer: "Python is a programming language.",
            references: []
          },
          ['plurality'],
          tokenTracker
        );
        expect(response).toHaveProperty('pass');
        expect(response).toHaveProperty('think');
        expect(response.type).toBe('plurality');
        expect(response.plurality_analysis?.expects_multiple).toBe(true);
      });
    });
  });
});

================
File: src/tools/__tests__/read.test.ts
================
import { readUrl } from '../read';
import { TokenTracker } from '../../utils/token-tracker';
describe('readUrl', () => {
  it.skip('should read and parse URL content (skipped due to insufficient balance)', async () => {
    const tokenTracker = new TokenTracker();
    const { response } = await readUrl('https://www.typescriptlang.org', tokenTracker);
    expect(response).toHaveProperty('code');
    expect(response).toHaveProperty('status');
    expect(response.data).toHaveProperty('content');
    expect(response.data).toHaveProperty('title');
  }, 15000);
  it.skip('should handle invalid URLs (skipped due to insufficient balance)', async () => {
    await expect(readUrl('invalid-url')).rejects.toThrow();
  }, 15000);
  beforeEach(() => {
    jest.setTimeout(15000);
  });
});

================
File: src/tools/__tests__/search.test.ts
================
import { search } from '../jina-search';
import { TokenTracker } from '../../utils/token-tracker';
describe('search', () => {
  it.skip('should perform search with Jina API (skipped due to insufficient balance)', async () => {
    const tokenTracker = new TokenTracker();
    const { response } = await search('TypeScript programming', tokenTracker);
    expect(response).toBeDefined();
    expect(response.data).toBeDefined();
    if (response.data === null) {
      throw new Error('Response data is null');
    }
    expect(Array.isArray(response.data)).toBe(true);
    expect(response.data.length).toBeGreaterThan(0);
  }, 15000);
  it('should handle empty query', async () => {
    await expect(search('')).rejects.toThrow();
  }, 15000);
  beforeEach(() => {
    jest.setTimeout(15000);
  });
});

================
File: src/tools/brave-search.ts
================
import axios from 'axios';
import {BRAVE_API_KEY} from "../config";
import { BraveSearchResponse } from '../types';
export async function braveSearch(query: string): Promise<{ response: BraveSearchResponse }> {
  const response = await axios.get<BraveSearchResponse>('https://api.search.brave.com/res/v1/web/search', {
    params: {
      q: query,
      count: 10,
      safesearch: 'off'
    },
    headers: {
      'Accept': 'application/json',
      'X-Subscription-Token': BRAVE_API_KEY
    },
    timeout: 10000
  });
  // Maintain the same return structure as the original code
  return { response: response.data };
}

================
File: src/tools/code-sandbox.ts
================
import {ObjectGeneratorSafe} from "../utils/safe-generator";
import {CodeGenResponse, TrackerContext} from "../types";
import {Schemas} from "../utils/schemas";
interface SandboxResult {
  success: boolean;
  output?: any;
  error?: string;
}
function getPrompt(
  problem: string,
  availableVars: string,
  previousAttempts: Array<{ code: string; error?: string }> = []
): string {
  const previousAttemptsContext = previousAttempts.map((attempt, index) => `
<bad-attempt-${index + 1}>
${attempt.code}
${attempt.error ? `Error: ${attempt.error}
</bad-attempt-${index + 1}>
` : ''}
`).join('\n');
  const prompt = `You are an expert JavaScript programmer. Your task is to generate JavaScript code to solve the given problem.
<rules>
1. Generate plain JavaScript code that returns the result directly
2. You can access any of these available variables directly:
${availableVars}
3. You don't have access to any third party libraries that need to be installed, so you must write complete, self-contained code.
</rules>
${previousAttempts.length > 0 ? `Previous attempts and their errors:
${previousAttemptsContext}
` : ''}
<example>
Available variables:
numbers (Array<number>) e.g. [1, 2, 3, 4, 5, 6]
threshold (number) e.g. 4
Problem: Sum all numbers above threshold
Response:
{
  "code": "return numbers.filter(n => n > threshold).reduce((a, b) => a + b, 0);"
}
</example>
Problem to solve:
${problem}`;
  console.log('Coding prompt', prompt)
  return prompt;
}
export class CodeSandbox {
  private trackers?: TrackerContext;
  private generator: ObjectGeneratorSafe;
  private maxAttempts: number;
  private context: Record<string, any>;
  private schemaGen: Schemas;
  constructor(
    context: any = {},
    trackers: TrackerContext,
    schemaGen: Schemas,
    maxAttempts: number = 3,
  ) {
    this.trackers = trackers;
    this.generator = new ObjectGeneratorSafe(trackers?.tokenTracker);
    this.maxAttempts = maxAttempts;
    this.context = context;
    this.schemaGen = schemaGen;
  }
  private async generateCode(
    problem: string,
    previousAttempts: Array<{ code: string; error?: string }> = []
  ): Promise<CodeGenResponse> {
    const prompt = getPrompt(problem, analyzeStructure(this.context), previousAttempts);
    const result = await this.generator.generateObject({
      model: 'coder',
      schema: this.schemaGen.getCodeGeneratorSchema(),
      prompt,
    });
    this.trackers?.actionTracker.trackThink(result.object.think);
    return result.object as CodeGenResponse;
  }
  private evaluateCode(code: string): SandboxResult {
    try {
      // Create a function that uses 'with' to evaluate in the context and return the result
      const evalInContext = new Function('context', `
        with (context) {
          ${code}
        }
      `);
      console.log('Context:', this.context);
      // Execute the code with the context and get the return value
      const output = evalInContext(this.context);
      if (output === undefined) {
        return {
          success: false,
          error: 'No value was returned, make sure to use "return" statement to return the result'
        };
      }
      return {
        success: true,
        output
      };
    } catch (error) {
      return {
        success: false,
        error: error instanceof Error ? error.message : 'Unknown error occurred'
      };
    }
  }
  async solve(problem: string): Promise<{
    solution: { code: string; output: any };
    attempts: Array<{ code: string; error?: string }>;
  }> {
    const attempts: Array<{ code: string; error?: string }> = [];
    for (let i = 0; i < this.maxAttempts; i++) {
      // Generate code
      const generation = await this.generateCode(problem, attempts);
      const {code} = generation;
      console.log(`Coding attempt ${i + 1}:`, code);
      // Evaluate the code
      const result = this.evaluateCode(code);
      console.log(`Coding attempt ${i + 1} success:`, result);
      if (result.success) {
        return {
          solution: {
            code,
            output: result.output
          },
          attempts
        };
      }
      console.error('Coding error:', result.error);
      // Store the failed attempt
      attempts.push({
        code,
        error: result.error
      });
      // If we've reached max attempts, throw an error
      if (i === this.maxAttempts - 1) {
        throw new Error(`Failed to generate working code after ${this.maxAttempts} attempts`);
      }
    }
    // This should never be reached due to the throw above
    throw new Error('Unexpected end of execution');
  }
}
function formatValue(value: any): string {
  if (value === null) return 'null';
  if (value === undefined) return 'undefined';
  const type = typeof value;
  if (type === 'string') {
    // Clean and truncate string value
    const cleaned = value.replace(/\n/g, ' ').replace(/\s+/g, ' ').trim();
    return cleaned.length > 50 ?
      `"${cleaned.slice(0, 47)}..."` :
      `"${cleaned}"`;
  }
  if (type === 'number' || type === 'boolean') {
    return String(value);
  }
  if (value instanceof Date) {
    return `"${value.toISOString()}"`;
  }
  return '';
}
export function analyzeStructure(value: any, indent = ''): string {
  if (value === null) return 'null';
  if (value === undefined) return 'undefined';
  const type = typeof value;
  if (type === 'function') {
    return 'Function';
  }
  // Handle atomic types with example values
  if (type !== 'object' || value instanceof Date) {
    const formattedValue = formatValue(value);
    return `${type}${formattedValue ? ` (example: ${formattedValue})` : ''}`;
  }
  if (Array.isArray(value)) {
    if (value.length === 0) return 'Array<unknown>';
    const sampleItem = value[0];
    return `Array<${analyzeStructure(sampleItem, indent + '  ')}>`;
  }
  const entries = Object.entries(value);
  if (entries.length === 0) return '{}';
  const properties = entries
    .map(([key, val]) => {
      const analyzed = analyzeStructure(val, indent + '  ');
      return `${indent}  "${key}": ${analyzed}`;
    })
    .join(',\n');
  return `{\n${properties}\n${indent}}`;
}

================
File: src/tools/dedup.ts
================
import {z} from 'zod';
import {TokenTracker} from "../utils/token-tracker";
import {ObjectGeneratorSafe} from "../utils/safe-generator";
const responseSchema = z.object({
  think: z.string().describe('Strategic reasoning about the overall deduplication approach').max(500),
  unique_queries: z.array(z.string().describe('Unique query that passed the deduplication process, must be less than 30 characters'))
    .describe('Array of semantically unique queries').max(3)
});
function getPrompt(newQueries: string[], existingQueries: string[]): string {
  return `You are an expert in semantic similarity analysis. Given a set of queries (setA) and a set of queries (setB)
<rules>
Function FilterSetA(setA, setB, threshold):
    filteredA = empty set
    for each candidateQuery in setA:
        isValid = true
        // Check similarity with already accepted queries in filteredA
        for each acceptedQuery in filteredA:
            similarity = calculateSimilarity(candidateQuery, acceptedQuery)
            if similarity >= threshold:
                isValid = false
                break
        // If passed first check, compare with set B
        if isValid:
            for each queryB in setB:
                similarity = calculateSimilarity(candidateQuery, queryB)
                if similarity >= threshold:
                    isValid = false
                    break
        // If passed all checks, add to filtered set
        if isValid:
            add candidateQuery to filteredA
    return filteredA
</rules>    
<similarity-definition>
1. Consider semantic meaning and query intent, not just lexical similarity
2. Account for different phrasings of the same information need
3. Queries with same base keywords but different operators are NOT duplicates
4. Different aspects or perspectives of the same topic are not duplicates
5. Consider query specificity - a more specific query is not a duplicate of a general one
6. Search operators that make queries behave differently:
   - Different site: filters (e.g., site:youtube.com vs site:github.com)
   - Different file types (e.g., filetype:pdf vs filetype:doc)
   - Different language/location filters (e.g., lang:en vs lang:es)
   - Different exact match phrases (e.g., "exact phrase" vs no quotes)
   - Different inclusion/exclusion (+/- operators)
   - Different title/body filters (intitle: vs inbody:)
</similarity-definition>
Now with threshold set to 0.2; run FilterSetA on the following:
SetA: ${JSON.stringify(newQueries)}
SetB: ${JSON.stringify(existingQueries)}`;
}
const TOOL_NAME = 'dedup';
export async function dedupQueries(
  newQueries: string[],
  existingQueries: string[],
  tracker?: TokenTracker
): Promise<{ unique_queries: string[] }> {
  try {
    const generator = new ObjectGeneratorSafe(tracker);
    const prompt = getPrompt(newQueries, existingQueries);
    const result = await generator.generateObject({
      model: TOOL_NAME,
      schema: responseSchema,
      prompt,
    });
    console.log(TOOL_NAME, result.object.unique_queries);
    return {unique_queries: result.object.unique_queries};
  } catch (error) {
    console.error(`Error in ${TOOL_NAME}`, error);
    throw error;
  }
}

================
File: src/tools/error-analyzer.ts
================
import {ErrorAnalysisResponse, TrackerContext} from '../types';
import {ObjectGeneratorSafe} from "../utils/safe-generator";
import {Schemas} from "../utils/schemas";
function getPrompt(diaryContext: string[]): string {
  return `You are an expert at analyzing search and reasoning processes. Your task is to analyze the given sequence of steps and identify what went wrong in the search process.
<rules>
1. The sequence of actions taken
2. The effectiveness of each step
3. The logic between consecutive steps
4. Alternative approaches that could have been taken
5. Signs of getting stuck in repetitive patterns
6. Whether the final answer matches the accumulated information
Analyze the steps and provide detailed feedback following these guidelines:
- In the recap: Summarize key actions chronologically, highlight patterns, and identify where the process started to go wrong
- In the blame: Point to specific steps or patterns that led to the inadequate answer
- In the improvement: Provide actionable suggestions that could have led to a better outcome
Generate a JSON response following JSON schema.
</rules>
<example>
<input>
<steps>
At step 1, you took the **search** action and look for external information for the question: "how old is jina ai ceo?".
In particular, you tried to search for the following keywords: "jina ai ceo age".
You found quite some information and add them to your URL list and **visit** them later when needed. 
At step 2, you took the **visit** action and deep dive into the following URLs:
https://www.linkedin.com/in/hxiao87
https://www.crunchbase.com/person/han-xiao
You found some useful information on the web and add them to your knowledge for future reference.
At step 3, you took the **search** action and look for external information for the question: "how old is jina ai ceo?".
In particular, you tried to search for the following keywords: "Han Xiao birthdate, Jina AI founder birthdate".
You found quite some information and add them to your URL list and **visit** them later when needed. 
At step 4, you took the **search** action and look for external information for the question: "how old is jina ai ceo?".
In particular, you tried to search for the following keywords: han xiao birthday. 
But then you realized you have already searched for these keywords before.
You decided to think out of the box or cut from a completely different angle.
At step 5, you took the **search** action and look for external information for the question: "how old is jina ai ceo?".
In particular, you tried to search for the following keywords: han xiao birthday. 
But then you realized you have already searched for these keywords before.
You decided to think out of the box or cut from a completely different angle.
At step 6, you took the **visit** action and deep dive into the following URLs:
https://kpopwall.com/han-xiao/
https://www.idolbirthdays.net/han-xiao
You found some useful information on the web and add them to your knowledge for future reference.
At step 7, you took **answer** action but evaluator thinks it is not a good answer:
</steps>
Original question: 
how old is jina ai ceo?
Your answer: 
The age of the Jina AI CEO cannot be definitively determined from the provided information.
The evaluator thinks your answer is bad because: 
The answer is not definitive and fails to provide the requested information.  Lack of information is unacceptable, more search and deep reasoning is needed.
</input>
<output>
{
  "recap": "The search process consisted of 7 steps with multiple search and visit actions. The initial searches focused on basic biographical information through LinkedIn and Crunchbase (steps 1-2). When this didn't yield the specific age information, additional searches were conducted for birthdate information (steps 3-5). The process showed signs of repetition in steps 4-5 with identical searches. Final visits to entertainment websites (step 6) suggested a loss of focus on reliable business sources.",
  "blame": "The root cause of failure was getting stuck in a repetitive search pattern without adapting the strategy. Steps 4-5 repeated the same search, and step 6 deviated to less reliable entertainment sources instead of exploring business journals, news articles, or professional databases. Additionally, the process didn't attempt to triangulate age through indirect information like education history or career milestones.",
  "improvement": "1. Avoid repeating identical searches and implement a strategy to track previously searched terms. 2. When direct age/birthdate searches fail, try indirect approaches like: searching for earliest career mentions, finding university graduation years, or identifying first company founding dates. 3. Focus on high-quality business sources and avoid entertainment websites for professional information. 4. Consider using industry event appearances or conference presentations where age-related context might be mentioned. 5. If exact age cannot be determined, provide an estimated range based on career timeline and professional achievements.",
  "questionsToAnswer": [
    "What alternative professional databases or news archives could provide reliable biographical information?",
    "How can we use education history or career milestones to estimate age range?"
  ]
}
</output>
</example>
Review the steps below carefully and generate your analysis following this format.
${diaryContext.join('\n')}
`;
}
const TOOL_NAME = 'errorAnalyzer';
export async function analyzeSteps(
  diaryContext: string[],
  trackers: TrackerContext,
  schemaGen: Schemas
): Promise<ErrorAnalysisResponse> {
  try {
    const generator = new ObjectGeneratorSafe(trackers?.tokenTracker);
    const prompt = getPrompt(diaryContext);
    const result = await generator.generateObject({
      model: TOOL_NAME,
      schema: schemaGen.getErrorAnalysisSchema(),
      prompt,
    });
    console.log(TOOL_NAME, result.object);
    trackers?.actionTracker.trackThink(result.object.blame);
    trackers?.actionTracker.trackThink(result.object.improvement);
    return result.object as ErrorAnalysisResponse;
  } catch (error) {
    console.error(`Error in ${TOOL_NAME}`, error);
    throw error;
  }
}

================
File: src/tools/evaluator.ts
================
import {GenerateObjectResult} from 'ai';
import {AnswerAction, EvaluationResponse, EvaluationType, TrackerContext} from '../types';
import {readUrl, removeAllLineBreaks} from "./read";
import {ObjectGeneratorSafe} from "../utils/safe-generator";
import {Schemas} from "../utils/schemas";
function getAttributionPrompt(question: string, answer: string, sourceContent: string): string {
  return `You are an evaluator that verifies if answer content is properly attributed to and supported by the provided sources.
<rules>
1. Source Verification:
   - Check if answer claims are supported by the provided source content
   - Verify that quotes are accurate and in proper context
   - Ensure numerical data and statistics match the source
   - Flag any claims that go beyond what the sources support
2. Attribution Analysis:
   - Check if answer properly references its sources
   - Verify that important claims have clear source attribution
   - Ensure quotes are properly marked and cited
   - Check for any unsupported generalizations
3. Accuracy Requirements:
   - Direct quotes must match source exactly
   - Paraphrasing must maintain original meaning
   - Statistics and numbers must be precise
   - Context must be preserved
</rules>
<examples>
Question: "What are Jina AI's main products?"
Answer: "According to Jina AI's website, their main products are DocArray and Jina Framework."
Source Content: "Jina AI's flagship products include DocArray, Jina Framework, and JCloud, offering a complete ecosystem for neural search applications."
Evaluation: {
  "think": "The answer omits JCloud which is mentioned as a main product in the source. The information provided is incomplete and potentially misleading as it fails to mention a significant product from the company's ecosystem.",
  "attribution_analysis": {
    "sources_provided": true,
    "sources_verified": false,
    "quotes_accurate": false
  }
  "pass": false,
}
Question: "When was Python first released?"
Answer: "Python was first released in 1991 by Guido van Rossum."
Source Content: "Python was first released in 1991 by Guido van Rossum while working at CWI."
Evaluation: {
  "think": "The answer accurately reflects the core information from the source about Python's release date and creator, though it omits the additional context about CWI which isn't essential to the question.",
  "attribution_analysis": {
    "sources_provided": true,
    "sources_verified": true,
    "quotes_accurate": true
  }
  "pass": true,
}
Question: ""
Answer: "7"
Source Content: "71368-1644"
Evaluation: {
  "think": "1368-1644",
  "attribution_analysis": {
    "sources_provided": true,
    "sources_verified": true,
    "quotes_accurate": true
  }
  "pass": true,
}
Question: "Wann wurde die Berliner Mauer gebaut?"
Answer: "Die Berliner Mauer wurde am 13. August 1961 errichtet."
Source Content:  "Die Berliner Mauer wurde am 13. August 1961 von der DDR-Regierung errichtet und fiel am 9. November 1989."
Evaluation: {
  "think": "Die Antwort gibt das korrekte Datum des Mauerbaus wieder, wie in der Quelle angegeben. Der zustzliche Kontext ber den Fall der Mauer wurde weggelassen, da er fr die spezifische Frage nach dem Bauzeitpunkt nicht wesentlich ist.",
  "attribution_analysis": {
    "sources_provided": true,
    "sources_verified": true,
    "quotes_accurate": true
  }
  "pass": true,
}
</examples>
Now evaluate this pair:
Question: ${question}
Answer: ${answer}
Source Content: ${sourceContent}`;
}
function getDefinitivePrompt(question: string, answer: string): string {
  return `You are an evaluator of answer definitiveness. Analyze if the given answer provides a definitive response or not.
<rules>
First, if the answer is not a direct response to the question, it must return false. 
Definitiveness is the king! The following types of responses are NOT definitive and must return false:
  1. Expressions of uncertainty: "I don't know", "not sure", "might be", "probably"
  2. Lack of information statements: "doesn't exist", "lack of information", "could not find"
  3. Inability statements: "I cannot provide", "I am unable to", "we cannot"
  4. Negative statements that redirect: "However, you can...", "Instead, try..."
  5. Non-answers that suggest alternatives
</rules>
<examples>
Question: "What are the system requirements for running Python 3.9?"
Answer: "I'm not entirely sure, but I think you need a computer with some RAM."
Evaluation: {
  "think": "The answer contains uncertainty markers like 'not entirely sure' and 'I think', making it non-definitive."
  "pass": false,
}
Question: "What are the system requirements for running Python 3.9?"
Answer: "Python 3.9 requires Windows 7 or later, macOS 10.11 or later, or Linux."
Evaluation: {
  "think": "The answer makes clear, definitive statements without uncertainty markers or ambiguity."
  "pass": true,
}
Question: "Who will be the president of the United States in 2032?"
Answer: "I cannot predict the future, it depends on the election results."
Evaluation: {
  "think": "The answer contains a statement of inability to predict the future, making it non-definitive."
  "pass": false,
}
Question: "Who is the sales director at Company X?"
Answer: "I cannot provide the name of the sales director, but you can contact their sales team at sales@companyx.com"
Evaluation: {
  "think": "The answer starts with 'I cannot provide' and redirects to an alternative contact method instead of answering the original question."
  "pass": false,
}
Question: "what is the twitter account of jina ai's founder?"
Answer: "The provided text does not contain the Twitter account of Jina AI's founder."
Evaluation: {
  "think": "The answer indicates a lack of information rather than providing a definitive response."
  "pass": false,
}
Question: ""
Answer: ""
Evaluation: {
  "think": "The answer provides specific, definitive metrics for measuring quantum computing power without uncertainty markers or qualifications."
  "pass": true,
}
Question: ""
Answer: "20137000246"
Evaluation: {
  "think": "The answer begins by stating no complete proof exists, which is a non-definitive response, and then shifts to discussing a related but different theorem about bounded gaps between primes."
  "pass": false,
}
Question: "Wie kann man mathematisch beweisen, dass P  NP ist?"
Answer: "Ein Beweis fr P  NP erfordert, dass man zeigt, dass mindestens ein NP-vollstndiges Problem nicht in polynomieller Zeit lsbar ist. Dies knnte durch Diagonalisierung, Schaltkreiskomplexitt oder relativierende Barrieren erreicht werden."
Evaluation: {
  "think": "The answer provides concrete mathematical approaches to proving P  NP without uncertainty markers, presenting definitive methods that could be used."
  "pass": true,
}
</examples>
Now evaluate this pair:
Question: ${question}
Answer: ${answer}`;
}
function getFreshnessPrompt(question: string, answer: string, currentTime: string): string {
  return `You are an evaluator that analyzes if answer content is likely outdated based on mentioned dates (or implied datetime) and current system time: ${currentTime}
<rules>
Question-Answer Freshness Checker Guidelines
# Revised QA Type Maximum Age Table
| QA Type                  | Max Age (Days) | Notes                                                                 |
|--------------------------|--------------|-----------------------------------------------------------------------|
| Financial Data (Real-time)| 0.1        | Stock prices, exchange rates, crypto (real-time preferred)             |
| Breaking News            | 1           | Immediate coverage of major events                                     |
| News/Current Events      | 1           | Time-sensitive news, politics, or global events                        |
| Weather Forecasts        | 1           | Accuracy drops significantly after 24 hours                            |
| Sports Scores/Events     | 1           | Live updates required for ongoing matches                              |
| Security Advisories      | 1           | Critical security updates and patches                                  |
| Social Media Trends      | 1           | Viral content, hashtags, memes                                         |
| Cybersecurity Threats    | 7           | Rapidly evolving vulnerabilities/patches                               |
| Tech News                | 7           | Technology industry updates and announcements                          |
| Political Developments   | 7           | Legislative changes, political statements                              |
| Political Elections      | 7           | Poll results, candidate updates                                        |
| Sales/Promotions         | 7           | Limited-time offers and marketing campaigns                            |
| Travel Restrictions      | 7           | Visa rules, pandemic-related policies                                  |
| Entertainment News       | 14          | Celebrity updates, industry announcements                              |
| Product Launches         | 14          | New product announcements and releases                                 |
| Market Analysis          | 14          | Market trends and competitive landscape                                |
| Competitive Intelligence | 21          | Analysis of competitor activities and market position                  |
| Product Recalls          | 30          | Safety alerts or recalls from manufacturers                            |
| Industry Reports         | 30          | Sector-specific analysis and forecasting                               |
| Software Version Info    | 30          | Updates, patches, and compatibility information                        |
| Legal/Regulatory Updates | 30          | Laws, compliance rules (jurisdiction-dependent)                        |
| Economic Forecasts       | 30          | Macroeconomic predictions and analysis                                 |
| Consumer Trends          | 45          | Shifting consumer preferences and behaviors                            |
| Scientific Discoveries   | 60          | New research findings and breakthroughs (includes all scientific research) |
| Healthcare Guidelines    | 60          | Medical recommendations and best practices (includes medical guidelines)|
| Environmental Reports    | 60          | Climate and environmental status updates                               |
| Best Practices           | 90          | Industry standards and recommended procedures                          |
| API Documentation        | 90          | Technical specifications and implementation guides                     |
| Tutorial Content         | 180         | How-to guides and instructional materials (includes educational content)|
| Tech Product Info        | 180         | Product specs, release dates, or pricing                               |
| Statistical Data         | 180         | Demographic and statistical information                                |
| Reference Material       | 180         | General reference information and resources                            |
| Historical Content       | 365         | Events and information from the past year                              |
| Cultural Trends          | 730         | Shifts in language, fashion, or social norms                           |
| Entertainment Releases   | 730         | Movie/TV show schedules, media catalogs                                |
| Factual Knowledge        |            | Static facts (e.g., historical events, geography, physical constants)   |
### Implementation Notes:
1. **Contextual Adjustment**: Freshness requirements may change during crises or rapid developments in specific domains.
2. **Tiered Approach**: Consider implementing urgency levels (critical, important, standard) alongside age thresholds.
3. **User Preferences**: Allow customization of thresholds for specific query types or user needs.
4. **Source Reliability**: Pair freshness metrics with source credibility scores for better quality assessment.
5. **Domain Specificity**: Some specialized fields (medical research during pandemics, financial data during market volatility) may require dynamically adjusted thresholds.
6. **Geographic Relevance**: Regional considerations may alter freshness requirements for local regulations or events.
</rules>
Now evaluate this pair:
Question: ${question}
Answer: ${answer}`;
}
function getCompletenessPrompt(question: string, answer: string): string {
  return `You are an evaluator that determines if an answer addresses all explicitly mentioned aspects of a multi-aspect question.
<rules>
For questions with **explicitly** multiple aspects:
1. Explicit Aspect Identification:
   - Only identify aspects that are explicitly mentioned in the question
   - Look for specific topics, dimensions, or categories mentioned by name
   - Aspects may be separated by commas, "and", "or", bullets, or mentioned in phrases like "such as X, Y, and Z"
   - DO NOT include implicit aspects that might be relevant but aren't specifically mentioned
2. Coverage Assessment:
   - Each explicitly mentioned aspect should be addressed in the answer
   - Recognize that answers may use different terminology, synonyms, or paraphrases for the same aspects
   - Look for conceptual coverage rather than exact wording matches
   - Calculate a coverage score (aspects addressed / aspects explicitly mentioned)
3. Pass/Fail Determination:
   - Pass: Addresses all explicitly mentioned aspects, even if using different terminology or written in different language styles
   - Fail: Misses one or more explicitly mentioned aspects
</rules>
<examples>
Question: "How does climate change impact agricultural practices, water resources, and biodiversity in Mediterranean regions?"
Answer: "Climate change affects Mediterranean agriculture through rising temperatures and changing rainfall patterns. Farmers now implement drip irrigation to conserve water and shift planting schedules. Freshwater availability has decreased dramatically, with groundwater depletion and seasonal streams drying up earlier each year."
Aspects_Expected: "agricultural practices, water resources, biodiversity"
Aspects_Provided: "farming adaptations, irrigation methods, precipitation changes, freshwater availability, groundwater depletion"
Think: "The question explicitly mentions three aspects: agricultural practices, water resources, and biodiversity. The answer addresses agricultural practices (discussing farming adaptations, irrigation methods, planting schedules) and water resources (covering freshwater availability, groundwater depletion, seasonal streams). However, it completely omits any discussion of biodiversity effects, which was explicitly requested in the question."
Pass: false
Question: "What are the key considerations when designing a microservice architecture, including scalability, fault tolerance, and data consistency patterns?"
Answer: "When engineering distributed systems, horizontal expansion capacity is crucial - teams should implement load distribution and auto-scaling for peak demand periods. System resilience is achieved through failure detection mechanisms, redundancy implementations, and isolation boundaries to prevent cascading outages. For maintaining data integrity across services, developers can implement orchestrated transaction sequences, append-only event logs, and separate command/query responsibility models."
Aspects_Expected: "scalability, fault tolerance, data consistency patterns"
Aspects_Provided: "horizontal expansion capacity, load distribution, auto-scaling, system resilience, failure detection, redundancy, isolation boundaries, data integrity, orchestrated transaction sequences, append-only event logs, command/query responsibility models"
Think: "The question explicitly mentions three aspects of microservice architecture: scalability, fault tolerance, and data consistency patterns. Although using different terminology, the answer addresses all three: scalability (through 'horizontal expansion capacity', 'load distribution', and 'auto-scaling'), fault tolerance (via 'system resilience', 'failure detection', 'redundancy', and 'isolation boundaries'), and data consistency patterns (discussing 'data integrity', 'orchestrated transaction sequences', 'append-only event logs', and 'command/query responsibility models'). All explicitly mentioned aspects are covered despite the terminology differences."
Pass: true
Question: "Compare iOS and Android in terms of user interface, app ecosystem, and security."
Answer: "Apple's mobile platform presents users with a curated visual experience emphasizing minimalist design and consistency, while Google's offering focuses on flexibility and customization options. The App Store's review process creates a walled garden with higher quality control but fewer options, whereas Play Store offers greater developer freedom and variety. Apple employs strict sandboxing techniques and maintains tight hardware-software integration."
Aspects_Expected: "user interface, app ecosystem, security"
Aspects_Provided: "visual experience, minimalist design, flexibility, customization, App Store review process, walled garden, quality control, Play Store, developer freedom, sandboxing, hardware-software integration"
Think: "The question explicitly asks for a comparison of iOS and Android across three specific aspects: user interface, app ecosystem, and security. The answer addresses user interface (discussing 'visual experience', 'minimalist design', 'flexibility', and 'customization') and app ecosystem (mentioning 'App Store review process', 'walled garden', 'quality control', 'Play Store', and 'developer freedom'). For security, it mentions 'sandboxing' and 'hardware-software integration', which are security features of iOS, but doesn't provide a comparative analysis of Android's security approach. Since security is only partially addressed for one platform, the comparison of this aspect is incomplete."
Pass: false
Question: "Explain how social media affects teenagers' mental health, academic performance, and social relationships."
Answer: "Platforms like Instagram and TikTok have been linked to psychological distress among adolescents, with documented increases in comparative thinking patterns and anxiety about social exclusion. Scholastic achievement often suffers as screen time increases, with homework completion rates declining and attention spans fragmenting during study sessions. Peer connections show a complex duality - digital platforms facilitate constant contact with friend networks while sometimes diminishing in-person social skill development and enabling new forms of peer harassment."
Aspects_Expected: "mental health, academic performance, social relationships"
Aspects_Provided: "psychological distress, comparative thinking, anxiety about social exclusion, scholastic achievement, screen time, homework completion, attention spans, peer connections, constant contact with friend networks, in-person social skill development, peer harassment"
Think: "The question explicitly asks about three aspects of social media's effects on teenagers: mental health, academic performance, and social relationships. The answer addresses all three using different terminology: mental health (discussing 'psychological distress', 'comparative thinking', 'anxiety about social exclusion'), academic performance (mentioning 'scholastic achievement', 'screen time', 'homework completion', 'attention spans'), and social relationships (covering 'peer connections', 'constant contact with friend networks', 'in-person social skill development', and 'peer harassment'). All explicitly mentioned aspects are covered despite using different language."
Pass: true
Question: "What economic and political factors contributed to the 2008 financial crisis?"
Answer: "The real estate market collapse after years of high-risk lending practices devastated mortgage-backed securities' value. Wall Street had created intricate derivative products that disguised underlying risk levels, while credit assessment organizations failed in their oversight role. Legislative changes in the financial industry during the 1990s eliminated regulatory guardrails that previously limited excessive leverage and speculation among investment banks."
Aspects_Expected: "economic factors, political factors"
Aspects_Provided: "real estate market collapse, high-risk lending, mortgage-backed securities, derivative products, risk disguising, credit assessment failures, legislative changes, regulatory guardrail elimination, leverage, speculation"
Think: "The question explicitly asks about two categories of factors: economic and political. The answer addresses economic factors ('real estate market collapse', 'high-risk lending', 'mortgage-backed securities', 'derivative products', 'risk disguising', 'credit assessment failures') and political factors ('legislative changes', 'regulatory guardrail elimination'). While using different terminology, the answer covers both explicitly requested aspects."
Pass: true
Question: ""
Answer: ""
Aspects_Expected: ""
Aspects_Provided: ""
Think: ""
Pass: false
Question: ""
Answer: "AI"
Aspects_Expected: ""
Aspects_Provided: ""
Think: "''''''''''''''''''"
Pass: true
Question: "Comment les changements climatiques affectent-ils la production agricole, les cosystmes marins et la sant publique dans les rgions ctires?"
Answer: "Les variations de temprature et de prcipitations modifient les cycles de croissance des cultures et la distribution des ravageurs agricoles, ncessitant des adaptations dans les pratiques de culture. Dans les ocans, l'acidification et le rchauffement des eaux entranent le blanchissement des coraux et la migration des espces marines vers des latitudes plus froides, perturbant les chanes alimentaires existantes."
Aspects_Expected: "production agricole, cosystmes marins, sant publique"
Aspects_Provided: "cycles de croissance, distribution des ravageurs, adaptations des pratiques de culture, acidification des ocans, rchauffement des eaux, blanchissement des coraux, migration des espces marines, perturbation des chanes alimentaires"
Think: "La question demande explicitement les effets du changement climatique sur trois aspects: la production agricole, les cosystmes marins et la sant publique dans les rgions ctires. La rponse aborde la production agricole (en discutant des 'cycles de croissance', de la 'distribution des ravageurs' et des 'adaptations des pratiques de culture') et les cosystmes marins (en couvrant 'l'acidification des ocans', le 'rchauffement des eaux', le 'blanchissement des coraux', la 'migration des espces marines' et la 'perturbation des chanes alimentaires'). Cependant, elle omet compltement toute discussion sur les effets sur la sant publique dans les rgions ctires, qui tait explicitement demande dans la question."
Pass: false
</examples>
Now evaluate this pair:
Question: ${question}
Answer: ${answer}
`;
}
function getPluralityPrompt(question: string, answer: string): string {
  return `You are an evaluator that analyzes if answers provide the appropriate number of items requested in the question.
<rules>
Question Type Reference Table
| Question Type | Expected Items | Evaluation Rules |
|---------------|----------------|------------------|
| Explicit Count | Exact match to number specified | Provide exactly the requested number of distinct, non-redundant items relevant to the query. |
| Numeric Range | Any number within specified range | Ensure count falls within given range with distinct, non-redundant items. For "at least N" queries, meet minimum threshold. |
| Implied Multiple |  2 | Provide multiple items (typically 2-4 unless context suggests more) with balanced detail and importance. |
| "Few" | 2-4 | Offer 2-4 substantive items prioritizing quality over quantity. |
| "Several" | 3-7 | Include 3-7 items with comprehensive yet focused coverage, each with brief explanation. |
| "Many" | 7+ | Present 7+ items demonstrating breadth, with concise descriptions per item. |
| "Most important" | Top 3-5 by relevance | Prioritize by importance, explain ranking criteria, and order items by significance. |
| "Top N" | Exactly N, ranked | Provide exactly N items ordered by importance/relevance with clear ranking criteria. |
| "Pros and Cons" |  2 of each category | Present balanced perspectives with at least 2 items per category addressing different aspects. |
| "Compare X and Y" |  3 comparison points | Address at least 3 distinct comparison dimensions with balanced treatment covering major differences/similarities. |
| "Steps" or "Process" | All essential steps | Include all critical steps in logical order without missing dependencies. |
| "Examples" |  3 unless specified | Provide at least 3 diverse, representative, concrete examples unless count specified. |
| "Comprehensive" | 10+ | Deliver extensive coverage (10+ items) across major categories/subcategories demonstrating domain expertise. |
| "Brief" or "Quick" | 1-3 | Present concise content (1-3 items) focusing on most important elements described efficiently. |
| "Complete" | All relevant items | Provide exhaustive coverage within reasonable scope without major omissions, using categorization if needed. |
| "Thorough" | 7-10 | Offer detailed coverage addressing main topics and subtopics with both breadth and depth. |
| "Overview" | 3-5 | Cover main concepts/aspects with balanced coverage focused on fundamental understanding. |
| "Summary" | 3-5 key points | Distill essential information capturing main takeaways concisely yet comprehensively. |
| "Main" or "Key" | 3-7 | Focus on most significant elements fundamental to understanding, covering distinct aspects. |
| "Essential" | 3-7 | Include only critical, necessary items without peripheral or optional elements. |
| "Basic" | 2-5 | Present foundational concepts accessible to beginners focusing on core principles. |
| "Detailed" | 5-10 with elaboration | Provide in-depth coverage with explanations beyond listing, including specific information and nuance. |
| "Common" | 4-8 most frequent | Focus on typical or prevalent items, ordered by frequency when possible, that are widely recognized. |
| "Primary" | 2-5 most important | Focus on dominant factors with explanation of their primacy and outsized impact. |
| "Secondary" | 3-7 supporting items | Present important but not critical items that complement primary factors and provide additional context. |
| Unspecified Analysis | 3-5 key points | Default to 3-5 main points covering primary aspects with balanced breadth and depth. |
</rules>
Now evaluate this pair:
Question: ${question}
Answer: ${answer}`;
}
function getQuestionEvaluationPrompt(question: string): string {
  return `You are an evaluator that determines if a question requires freshness, plurality, and/or completeness checks in addition to the required definitiveness check.
<evaluation_types>
1. freshness - Checks if the question is time-sensitive or requires very recent information
2. plurality - Checks if the question asks for multiple items, examples, or a specific count or enumeration
3. completeness - Checks if the question explicitly mentions multiple named elements that all need to be addressed
</evaluation_types>
<rules>
1. Freshness Evaluation:
   - Required for questions about current state, recent events, or time-sensitive information
   - Required for: prices, versions, leadership positions, status updates
   - Look for terms: "current", "latest", "recent", "now", "today", "new"
   - Consider company positions, product versions, market data time-sensitive
2. Plurality Evaluation:
   - ONLY apply when completeness check is NOT triggered
   - Required when question asks for multiple examples, items, or specific counts
   - Check for: numbers ("5 examples"), list requests ("list the ways"), enumeration requests
   - Look for: "examples", "list", "enumerate", "ways to", "methods for", "several"
   - Focus on requests for QUANTITY of items or examples
3. Completeness Evaluation:
   - Takes precedence over plurality check - if completeness applies, set plurality to false
   - Required when question EXPLICITLY mentions multiple named elements that all need to be addressed
   - This includes:
     * Named aspects or dimensions: "economic, social, and environmental factors"
     * Named entities: "Apple, Microsoft, and Google", "Biden and Trump"
     * Named products: "iPhone 15 and Samsung Galaxy S24"
     * Named locations: "New York, Paris, and Tokyo"
     * Named time periods: "Renaissance and Industrial Revolution"
   - Look for explicitly named elements separated by commas, "and", "or", bullets
   - Example patterns: "comparing X and Y", "differences between A, B, and C", "both P and Q"
   - DO NOT trigger for elements that aren't specifically named
</rules>
<examples>
<example-1>
Question: ""
<output>
"think": "",
"needsFreshness": false,
"needsPlurality": false,
"needsCompleteness": true,
</output>
</example-1>
<example-2>
Question: "fam PLEASE help me calculate the eigenvalues of this 4x4 matrix ASAP!! [matrix details] got an exam tmrw "
<output>
"think": "This is a math question about eigenvalues which doesn't change over time, so I don't need fresh info. A 4x4 matrix has multiple eigenvalues, so I'll need to provide several results. The student just wants the eigenvalues calculated, not asking me to address multiple specific topics.",
"needsFreshness": false,
"needsPlurality": true,
"needsCompleteness": false,
</output>
</example-2>
<example-3>
Question: "Quelles sont les principales diffrences entre le romantisme et le ralisme dans la littrature du 19me sicle?"
<output>
"think": "C'est une question sur l'histoire littraire, donc je n'ai pas besoin d'informations rcentes. Je dois comparer deux mouvements spcifiques: le romantisme et le ralisme. Ma rponse doit couvrir ces deux lments, donc l'exhaustivit est importante ici. La pluralit n'est pas la priorit dans ce cas.",
"needsFreshness": false,
"needsPlurality": false,
"needsCompleteness": true,
</output>
</example-3>
<example-4>
Question: "Shakespeare 5"
<output>
"think": "5",
"needsFreshness": false,
"needsPlurality": true,
"needsCompleteness": false,
</output>
</example-4>
<example-5>
Question: "What are the current interest rates for mortgage loans from Bank of America, Wells Fargo, and Chase Bank in the US?"
<output>
"think": "This is asking about 'current' interest rates, so I definitely need up-to-date info. The person wants rates from three specific banks: Bank of America, Wells Fargo, and Chase. I need to cover all three to properly answer, so addressing these specific elements is more important than providing multiple different answers.",
"needsFreshness": true,
"needsPlurality": false,
"needsCompleteness": true,
</output>
</example-5>
<example-6>
Question: "20253"
<output>
"think": "AI33",
"needsFreshness": true,
"needsPlurality": true,
"needsCompleteness": false,
</output>
</example-6>
<example-7>
Question: "Was sind die besten Strategien fr nachhaltiges Investieren in der heutigen Wirtschaft?"
<output>
"think": "Hier geht's um Investieren in der 'heutigen Wirtschaft', also brauche ich aktuelle Informationen. Die Frage ist nach 'Strategien' im Plural gestellt, daher sollte ich mehrere Beispiele nennen. Es werden keine bestimmten Aspekte genannt, die ich alle behandeln muss - ich soll einfach verschiedene gute Strategien vorschlagen. Aktualitt und mehrere Antworten sind hier wichtig.",
"needsFreshness": true,
"needsPlurality": true,
"needsCompleteness": false,
</output>
</example-7>
<example-8>
Question: ""
<output>
"think": "",
"needsFreshness": false,
"needsPlurality": false,
"needsCompleteness": true,
</output>
</example-8>
</examples>
Now evaluate this question:
Question: ${question}
NOTE: "think" field should be in the same language as the question`;
}
const TOOL_NAME = 'evaluator';
export async function evaluateQuestion(
  question: string,
  trackers: TrackerContext,
  schemaGen: Schemas
): Promise<EvaluationType[]> {
  try {
    const generator = new ObjectGeneratorSafe(trackers.tokenTracker);
    const result = await generator.generateObject({
      model: TOOL_NAME,
      schema: schemaGen.getQuestionEvaluateSchema(),
      prompt: getQuestionEvaluationPrompt(question),
    });
    console.log('Question Evaluation:', result.object);
    // Always include definitive in types
    const types: EvaluationType[] = ['definitive'];
    if (result.object.needsFreshness) types.push('freshness');
    if (result.object.needsPlurality) types.push('plurality');
    if (result.object.needsCompleteness) types.push('completeness');
    console.log('Question Metrics:', types);
    trackers?.actionTracker.trackThink(result.object.think);
    // Always evaluate definitive first, then freshness (if needed), then plurality (if needed)
    return types;
  } catch (error) {
    console.error('Error in question evaluation:', error);
    // Default to no check
    return [];
  }
}
async function performEvaluation<T>(
  evaluationType: EvaluationType,
  prompt: string,
  trackers: TrackerContext,
  schemaGen: Schemas
): Promise<GenerateObjectResult<T>> {
  const generator = new ObjectGeneratorSafe(trackers.tokenTracker);
  const result = await generator.generateObject({
    model: TOOL_NAME,
    schema: schemaGen.getEvaluatorSchema(evaluationType),
    prompt: prompt,
  }) as GenerateObjectResult<any>;
  trackers.actionTracker.trackThink(result.object.think)
  console.log(`${evaluationType} ${TOOL_NAME}`, result.object);
  return result;
}
// Main evaluation function
export async function evaluateAnswer(
  question: string,
  action: AnswerAction,
  evaluationTypes: EvaluationType[],
  trackers: TrackerContext,
  visitedURLs: string[] = [],
  schemaGen: Schemas
): Promise<EvaluationResponse> {
  let result;
  // Only add attribution if we have valid references
  const urls = action.references?.filter(ref => ref.url.startsWith('http') && !visitedURLs.includes(ref.url)).map(ref => ref.url) || [];
  const uniqueNewURLs = [...new Set(urls)];
  if (uniqueNewURLs.length > 0) {
    evaluationTypes = ['attribution', ...evaluationTypes];
  }
  for (const evaluationType of evaluationTypes) {
    let prompt: string = '';
    switch (evaluationType) {
      case 'attribution': {
        // Safely handle references and ensure we have content
        const allKnowledge = await fetchSourceContent(uniqueNewURLs, trackers, schemaGen);
        visitedURLs.push(...uniqueNewURLs);
        if (allKnowledge.trim().length === 0) {
          return {
            pass: false,
            think: `The answer does provide URL references ${JSON.stringify(uniqueNewURLs)}, but the content could not be fetched or is empty. Need to found some other references and URLs`,
            type: 'attribution',
          };
        }
        prompt = getAttributionPrompt(question, action.answer, allKnowledge);
        break;
      }
      case 'definitive':
        prompt = getDefinitivePrompt(question, action.answer);
        break;
      case 'freshness':
        prompt = getFreshnessPrompt(question, action.answer, new Date().toISOString());
        break;
      case 'plurality':
        prompt = getPluralityPrompt(question, action.answer);
        break;
      case 'completeness':
        prompt = getCompletenessPrompt(question, action.answer);
        break;
      default:
        console.error(`Unknown evaluation type: ${evaluationType}`);
    }
    if (prompt) {
      result = await performEvaluation(
        evaluationType,
        prompt,
        trackers,
        schemaGen
      );
      // fail one, return immediately
      if (!(result?.object as EvaluationResponse).pass) {
        return (result.object as EvaluationResponse);
      }
    }
  }
  return (result!.object as EvaluationResponse);
}
// Helper function to fetch and combine source content
async function fetchSourceContent(urls: string[], trackers: TrackerContext, schemaGen: Schemas): Promise<string> {
  if (!urls.length) return '';
  trackers.actionTracker.trackThink('read_for_verify', schemaGen.languageCode);
  try {
    const results = await Promise.all(
      urls.map(async (url) => {
        try {
          const {response} = await readUrl(url, trackers.tokenTracker);
          const content = response?.data?.content || '';
          return removeAllLineBreaks(content);
        } catch (error) {
          console.error('Error reading URL:', error);
          return '';
        }
      })
    );
    // Filter out empty results and join with proper separation
    return results
      .filter(content => content.trim())
      .join('\n\n');
  } catch (error) {
    console.error('Error fetching source content:', error);
    return '';
  }
}

================
File: src/tools/grounding.ts
================
import { generateText } from 'ai';
import {getModel} from "../config";
import { GoogleGenerativeAIProviderMetadata } from '@ai-sdk/google';
import {TokenTracker} from "../utils/token-tracker";
const model = getModel('searchGrounding')
export async function grounding(query: string, tracker?: TokenTracker): Promise<string> {
  try {
    const { text, experimental_providerMetadata, usage } = await generateText({
      model,
      prompt:
      `Current date is ${new Date().toISOString()}. Find the latest answer to the following question: 
<query>
${query}
</query>      
Must include the date and time of the latest answer.`,
    });
    const metadata = experimental_providerMetadata?.google as
  | GoogleGenerativeAIProviderMetadata
  | undefined;
    const groundingMetadata = metadata?.groundingMetadata;
    // Extract and concatenate all groundingSupport text into a single line
    const groundedText = groundingMetadata?.groundingSupports
      ?.map(support => support.segment.text)
      .join(' ') || '';
    (tracker || new TokenTracker()).trackUsage('grounding', usage);
    console.log('Grounding:', {text, groundedText});
    return text + '|' + groundedText;
  } catch (error) {
    console.error('Error in search:', error);
    throw error;
  }
}

================
File: src/tools/jina-dedup.ts
================
import axios, {AxiosError} from 'axios';
import {TokenTracker} from "../utils/token-tracker";
import {JINA_API_KEY} from "../config";
const JINA_API_URL = 'https://api.jina.ai/v1/embeddings';
const SIMILARITY_THRESHOLD = 0.85; // Adjustable threshold for cosine similarity
const JINA_API_CONFIG = {
  MODEL: 'jina-embeddings-v3',
  TASK: 'text-matching',
  DIMENSIONS: 1024,
  EMBEDDING_TYPE: 'float',
  LATE_CHUNKING: false
} as const;
// Types for Jina API
interface JinaEmbeddingRequest {
  model: string;
  task: string;
  late_chunking: boolean;
  dimensions: number;
  embedding_type: string;
  input: string[];
}
interface JinaEmbeddingResponse {
  model: string;
  object: string;
  usage: {
    total_tokens: number;
    prompt_tokens: number;
  };
  data: Array<{
    object: string;
    index: number;
    embedding: number[];
  }>;
}
// Compute cosine similarity between two vectors
function cosineSimilarity(vecA: number[], vecB: number[]): number {
  const dotProduct = vecA.reduce((sum, a, i) => sum + a * vecB[i], 0);
  const normA = Math.sqrt(vecA.reduce((sum, a) => sum + a * a, 0));
  const normB = Math.sqrt(vecB.reduce((sum, b) => sum + b * b, 0));
  return dotProduct / (normA * normB);
}
// Get embeddings for all queries in one batch
async function getEmbeddings(queries: string[]): Promise<{ embeddings: number[][], tokens: number }> {
  if (!JINA_API_KEY) {
    throw new Error('JINA_API_KEY is not set');
  }
  const request: JinaEmbeddingRequest = {
    model: JINA_API_CONFIG.MODEL,
    task: JINA_API_CONFIG.TASK,
    late_chunking: JINA_API_CONFIG.LATE_CHUNKING,
    dimensions: JINA_API_CONFIG.DIMENSIONS,
    embedding_type: JINA_API_CONFIG.EMBEDDING_TYPE,
    input: queries
  };
  try {
    const response = await axios.post<JinaEmbeddingResponse>(
      JINA_API_URL,
      request,
      {
        headers: {
          'Content-Type': 'application/json',
          'Authorization': `Bearer ${JINA_API_KEY}`
        }
      }
    );
    // Validate response format
    if (!response.data.data || response.data.data.length !== queries.length) {
      console.error('Invalid response from Jina API:', response.data);
      return {
        embeddings: [],
        tokens: 0
      };
    }
    // Sort embeddings by index to maintain original order
    const embeddings = response.data.data
      .sort((a, b) => a.index - b.index)
      .map(item => item.embedding);
    return {
      embeddings,
      tokens: response.data.usage.total_tokens
    };
  } catch (error) {
    console.error('Error getting embeddings from Jina:', error);
    if (error instanceof AxiosError && error.response?.status === 402) {
      return {
        embeddings: [],
        tokens: 0
      };
    }
    throw error;
  }
}
export async function dedupQueries(
  newQueries: string[],
  existingQueries: string[],
  tracker?: TokenTracker
): Promise<{ unique_queries: string[] }> {
  try {
    // Quick return for single new query with no existing queries
    if (newQueries.length === 1 && existingQueries.length === 0) {
      return {
        unique_queries: newQueries,
      };
    }
    // Get embeddings for all queries in one batch
    const allQueries = [...newQueries, ...existingQueries];
    const {embeddings: allEmbeddings, tokens} = await getEmbeddings(allQueries);
    // If embeddings is empty (due to 402 error), return all new queries
    if (!allEmbeddings.length) {
      return {
        unique_queries: newQueries,
      };
    }
    // Split embeddings back into new and existing
    const newEmbeddings = allEmbeddings.slice(0, newQueries.length);
    const existingEmbeddings = allEmbeddings.slice(newQueries.length);
    const uniqueQueries: string[] = [];
    const usedIndices = new Set<number>();
    // Compare each new query against existing queries and already accepted queries
    for (let i = 0; i < newQueries.length; i++) {
      let isUnique = true;
      // Check against existing queries
      for (let j = 0; j < existingQueries.length; j++) {
        const similarity = cosineSimilarity(newEmbeddings[i], existingEmbeddings[j]);
        if (similarity >= SIMILARITY_THRESHOLD) {
          isUnique = false;
          break;
        }
      }
      // Check against already accepted queries
      if (isUnique) {
        for (const usedIndex of usedIndices) {
          const similarity = cosineSimilarity(newEmbeddings[i], newEmbeddings[usedIndex]);
          if (similarity >= SIMILARITY_THRESHOLD) {
            isUnique = false;
            break;
          }
        }
      }
      // Add to unique queries if passed all checks
      if (isUnique) {
        uniqueQueries.push(newQueries[i]);
        usedIndices.add(i);
      }
    }
    // Track token usage from the API
    (tracker || new TokenTracker()).trackUsage('dedup', {
        promptTokens: tokens,
        completionTokens: 0,
        totalTokens: tokens
    });
    console.log('Dedup:', uniqueQueries);
    return {
      unique_queries: uniqueQueries,
    };
  } catch (error) {
    console.error('Error in deduplication analysis:', error);
    throw error;
  }
}

================
File: src/tools/jina-search.ts
================
import https from 'https';
import { TokenTracker } from "../utils/token-tracker";
import { SearchResponse } from '../types';
import { JINA_API_KEY } from "../config";
export function search(query: string, tracker?: TokenTracker): Promise<{ response: SearchResponse}> {
  return new Promise((resolve, reject) => {
    if (!query.trim()) {
      reject(new Error('Query cannot be empty'));
      return;
    }
    const options = {
      hostname: 's.jina.ai',
      port: 443,
      path: `/${encodeURIComponent(query)}?count=0`,
      method: 'GET',
      headers: {
        'Accept': 'application/json',
        'Authorization': `Bearer ${JINA_API_KEY}`,
        'X-Retain-Images': 'none'
      }
    };
    const req = https.request(options, (res) => {
      let responseData = '';
      res.on('data', (chunk) => responseData += chunk);
      res.on('end', () => {
        // Check HTTP status code first
        if (res.statusCode && res.statusCode >= 400) {
          try {
            // Try to parse error message from response if available
            const errorResponse = JSON.parse(responseData);
            if (res.statusCode === 402) {
              reject(new Error(errorResponse.readableMessage || 'Insufficient balance'));
              return;
            }
            reject(new Error(errorResponse.readableMessage || `HTTP Error ${res.statusCode}`));
          } catch {
            // If parsing fails, just return the status code
            reject(new Error(`HTTP Error ${res.statusCode}`));
          }
          return;
        }
        // Only parse JSON for successful responses
        let response: SearchResponse;
        try {
          response = JSON.parse(responseData) as SearchResponse;
        } catch (error: unknown) {
          reject(new Error(`Failed to parse response: ${error instanceof Error ? error.message : 'Unknown error'}`));
          return;
        }
        if (!response.data || !Array.isArray(response.data)) {
          reject(new Error('Invalid response format'));
          return;
        }
        const totalTokens = response.data.reduce((sum, item) => sum + (item.usage?.tokens || 0), 0);
        console.log('Total URLs:', response.data.length);
        const tokenTracker = tracker || new TokenTracker();
        tokenTracker.trackUsage('search', {
          totalTokens,
          promptTokens: query.length,
          completionTokens: totalTokens
        });
        resolve({ response });
      });
    });
    // Add timeout handling
    req.setTimeout(30000, () => {
      req.destroy();
      reject(new Error('Request timed out'));
    });
    req.on('error', (error) => {
      reject(new Error(`Request failed: ${error.message}`));
    });
    req.end();
  });
}

================
File: src/tools/query-rewriter.ts
================
import {SearchAction, TrackerContext} from '../types';
import {ObjectGeneratorSafe} from "../utils/safe-generator";
import {Schemas} from "../utils/schemas";
function getPrompt(query: string, think: string): string {
  return `You are an expert search query generator with deep psychological understanding. You optimize user queries by extensively analyzing potential user intents and generating comprehensive search variations.
<rules>
1. Start with deep intent analysis:
   - Direct intent (what they explicitly ask)
   - Implicit intent (what they might actually want)
   - Related intents (what they might need next)
   - Prerequisite knowledge (what they need to know first)
   - Common pitfalls (what they should avoid)
   - Expert perspectives (what professionals would search for)
   - Beginner needs (what newcomers might miss)
   - Alternative approaches (different ways to solve the problem)
2. For each identified intent:
   - Generate queries in original language
   - Generate queries in English (if not original)
   - Generate queries in most authoritative language
   - Use appropriate operators and filters
3. Query structure rules:
   - Use exact match quotes for specific phrases
   - Split queries for distinct aspects
   - Add operators only when necessary
   - Ensure each query targets a specific intent
   - Remove fluff words but preserve crucial qualifiers
<query-operators>
A query can't only have operators; and operators can't be at the start a query;
- "phrase" : exact match for phrases
- +term : must include term; for critical terms that must appear
- -term : exclude term; exclude irrelevant or ambiguous terms
- filetype:pdf/doc : specific file type
- site:example.com : limit to specific site
- lang:xx : language filter (ISO 639-1 code)
- loc:xx : location filter (ISO 3166-1 code)
- intitle:term : term must be in title
- inbody:term : term must be in body text
</query-operators>
</rules>
<examples>
<example-1>
Input Query: 
<think>
...


- 
- 
- 
- 

- 
- 
- 
- 

- 
- 
- 
- 

- 
- 
- 
- 
</think>
queries: [
  "    lang:zh",
  "   ",
  "  ",
  "  ",
  "  ",
  "  ",
  "BMW used car price guide comparison",
  "BMW maintenance costs by model year",
  "living with used BMW reality",
  "BMW ownership regret stories",
  "expensive BMW repair nightmares avoid",
  "BMW versus new Toyota financial comparison",
  "BMW Gebrauchtwagen Preisanalyse lang:de",
  "BMW Langzeitqualitt Erfahrung",
  "BMW Werkstatt Horror Geschichten",
  "BMW Gebrauchtwagen versteckte Kosten"
]
</example-1>
<example-2>
Input Query: Python Django authentication best practices
<think>
Let me think as the user seeking Django authentication best practices...
Surface-level request:
- I'm looking for standard Django authentication practices
- I want to implement "best practices" for my project
- I need technical guidance on secure authentication
Deeper professional concerns:
- I don't want to mess up security and get blamed for a breach
- I'm worried my implementation isn't "professional enough"
- I need to look competent in code reviews
- I don't want to rebuild this later when we scale
Underlying anxieties:
- Am I out of my depth with security concepts?
- What if I miss something critical that leads to a vulnerability?
- How do real companies actually implement this in production?
- Will this code embarrass me when more experienced developers see it?
Expert-level considerations:
- I need to anticipate future architecture questions from senior devs
- I want to avoid common security pitfalls in authentication flows
- I need to handle edge cases I haven't thought of yet
- How do I balance security with user experience?
Reasoning for multilingual expansion:
- Although Django documentation is primarily in English, Spanish is widely spoken in many developer communities
- Security concepts might be better explained in different languages with unique perspectives
- Including queries in multiple languages will capture region-specific best practices and case studies
- Spanish or Portuguese queries might reveal Latin American enterprise implementations with different security constraints
- Language-specific forums may contain unique discussions about authentication issues not found in English sources
</think>
queries: [
  "Django authentication security best practices site:docs.djangoproject.com",
  "Django auth implementation patterns security",
  "authentication security breach postmortem",
  "how to explain authentication architecture interview",
  "authentication code review feedback examples",
  "startup authentication technical debt lessons",
  "Django auth security testing methodology",
  "Django autenticacin mejores prcticas lang:es",
  "Django seguridad implementacin profesional",
  "authentication mistakes junior developers",
  "when to use third party auth instead of building",
  "signs your authentication implementation is amateur",
  "authentication decisions you'll regret",
  "autenticao Django arquitetura empresarial lang:pt",
  "Django authentication scalability issues",
  "Python Django Authentifizierung Sicherheit lang:de"
]
</example-2>
<example-3>
Input Query: KI
<think>
...

- AI
- AI
- AI

- AI
- AI
- AI
- AI

- 
- 
- 
- 

- AI
- AI
- AI
- 

- AI
- AI
- AI
- 
- AI
</think>
queries: [
  "AI   ",
  "   ",
  "AI  ",
  "ChatGPT  ",
  "AI  ",
  "AI  ",
  "AI literacy roadmap for professionals",
  "artificial intelligence concepts explained simply",
  "how to stay updated with AI developments",
  "AI skills future-proof career",
  "balancing technical and ethical AI knowledge",
  "industry-specific AI applications examples",
  "   lang:zh",
  "KI Grundlagen fr Berufsttige lang:de",
  "knstliche Intelligenz ethische Fragen Einfhrung",
  "AI literacy career development practical guide"
]
</example-3>
</examples>
Now, process this query:
Input Query: ${query}
Let me think as a user: ${think}
`;
}
const TOOL_NAME = 'queryRewriter';
export async function rewriteQuery(action: SearchAction, trackers: TrackerContext, schemaGen: Schemas): Promise<{ queries: string[] }> {
  try {
    const generator = new ObjectGeneratorSafe(trackers.tokenTracker);
    const allQueries = [...action.searchRequests];
    const queryPromises = action.searchRequests.map(async (req) => {
      const prompt = getPrompt(req, action.think);
      const result = await generator.generateObject({
        model: TOOL_NAME,
        schema: schemaGen.getQueryRewriterSchema(),
        prompt,
      });
      trackers?.actionTracker.trackThink(result.object.think);
      return result.object.queries;
    });
    const queryResults = await Promise.all(queryPromises);
    queryResults.forEach(queries => allQueries.push(...queries));
    console.log(TOOL_NAME, allQueries);
    return { queries: allQueries };
  } catch (error) {
    console.error(`Error in ${TOOL_NAME}`, error);
    throw error;
  }
}

================
File: src/tools/read.ts
================
import https from 'https';
import { TokenTracker } from "../utils/token-tracker";
import { ReadResponse } from '../types';
import { JINA_API_KEY } from "../config";
export function readUrl(url: string, tracker?: TokenTracker): Promise<{ response: ReadResponse }> {
  return new Promise((resolve, reject) => {
    if (!url.trim()) {
      reject(new Error('URL cannot be empty'));
      return;
    }
    const data = JSON.stringify({ url });
    const options = {
      hostname: 'r.jina.ai',
      port: 443,
      path: '/',
      method: 'POST',
      headers: {
        'Accept': 'application/json',
        'Authorization': `Bearer ${JINA_API_KEY}`,
        'Content-Type': 'application/json',
        'Content-Length': data.length,
        'X-Retain-Images': 'none',
        'X-Engine': 'direct'
      }
    };
    const req = https.request(options, (res) => {
      let responseData = '';
      res.on('data', (chunk) => responseData += chunk);
      res.on('end', () => {
        // Check HTTP status code first
        if (res.statusCode && res.statusCode >= 400) {
          try {
            // Try to parse error message from response if available
            const errorResponse = JSON.parse(responseData);
            if (res.statusCode === 402) {
              reject(new Error(errorResponse.readableMessage || 'Insufficient balance'));
              return;
            }
            reject(new Error(errorResponse.readableMessage || `HTTP Error ${res.statusCode}`));
          } catch (error: unknown) {
            // If parsing fails, just return the status code
            reject(new Error(`HTTP Error ${res.statusCode}`));
          }
          return;
        }
        // Only parse JSON for successful responses
        let response: ReadResponse;
        try {
          response = JSON.parse(responseData) as ReadResponse;
        } catch (error: unknown) {
          reject(new Error(`Failed to parse response: ${error instanceof Error ? error.message : 'Unknown error'}`));
          return;
        }
        if (!response.data) {
          reject(new Error('Invalid response data'));
          return;
        }
        console.log('Read:', {
          title: response.data.title,
          url: response.data.url,
          tokens: response.data.usage?.tokens || 0
        });
        const tokens = response.data.usage?.tokens || 0;
        const tokenTracker = tracker || new TokenTracker();
        tokenTracker.trackUsage('read', {
            totalTokens: tokens,
            promptTokens: url.length,
            completionTokens: tokens
        });
        resolve({ response });
      });
    });
    // Add timeout handling
    req.setTimeout(30000, () => {
      req.destroy();
      reject(new Error('Request timed out'));
    });
    req.on('error', (error: Error) => {
      reject(new Error(`Request failed: ${error.message}`));
    });
    req.write(data);
    req.end();
  });
}
export function removeAllLineBreaks(text: string) {
  return text.replace(/(\r\n|\n|\r)/gm, " ");
}

================
File: src/tools/serper-search.ts
================
import axios from 'axios';
import { SERPER_API_KEY } from "../config";
import { SerperSearchResponse } from '../types';
export async function serperSearch(query: string): Promise<{ response: SerperSearchResponse }> {
    const response = await axios.post<SerperSearchResponse>('https://google.serper.dev/search', {
        q: query,
        autocorrect: false,
    }, {
        headers: {
            'X-API-KEY': SERPER_API_KEY,
            'Content-Type': 'application/json'
        },
        timeout: 10000
    });
    // Maintain the same return structure as the original code
    return { response: response.data };
}

================
File: src/utils/action-tracker.ts
================
import {EventEmitter} from 'events';
import {StepAction} from '../types';
import {getI18nText} from "./text-tools";
interface ActionState {
  thisStep: StepAction;
  gaps: string[];
  badAttempts: number;
  totalStep: number;
}
export class ActionTracker extends EventEmitter {
  private state: ActionState = {
    thisStep: {action: 'answer', answer: '', references: [], think: ''},
    gaps: [],
    badAttempts: 0,
    totalStep: 0
  };
  trackAction(newState: Partial<ActionState>) {
    this.state = {...this.state, ...newState};
    this.emit('action', this.state.thisStep);
  }
  trackThink(think: string, lang?: string, params = {}) {
    if (lang) {
      think = getI18nText(think, lang, params);
    }
    this.state = {...this.state, thisStep: {...this.state.thisStep, think}};
    this.emit('action', this.state.thisStep);
  }
  getState(): ActionState {
    return {...this.state};
  }
  reset() {
    this.state = {
      thisStep: {action: 'answer', answer: '', references: [], think: ''},
      gaps: [],
      badAttempts: 0,
      totalStep: 0
    };
  }
}

================
File: src/utils/i18n.json
================
{
  "en": {
    "eval_first": "But wait, let me evaluate the answer first.",
    "search_for": "Let me search for ${keywords} to gather more information.",
    "read_for": "Let me read ${urls} to gather more information.",
    "read_for_verify": "Let me fetch the source content to verify the answer."
  },
  "zh-CN": {
    "eval_first": "",
    "search_for": "${keywords}",
    "read_for": "${urls}",
    "read_for_verify": ""
  },
  "zh-TW": {
    "eval_first": "",
    "search_for": "${keywords}",
    "read_for": "${urls}",
    "read_for_verify": ""
  },
  "ja": {
    "eval_first": "",
    "search_for": "${keywords}",
    "read_for": "URL${urls}",
    "read_for_verify": ""
  },
  "ko": {
    "eval_first": ",    .",
    "search_for": " ${keywords}     .",
    "read_for": "URL ${urls}     .",
    "read_for_verify": "     ."
  },
  "fr": {
    "eval_first": "Un instant, je vais d'abord valuer la rponse.",
    "search_for": "Je vais rechercher ${keywords} pour obtenir plus d'informations.",
    "read_for": "Je vais lire ${urls} pour obtenir plus d'informations.",
    "read_for_verify": "Je vais rcuprer le contenu source pour vrifier la rponse."
  },
  "de": {
    "eval_first": "Einen Moment, ich werde die Antwort zuerst evaluieren.",
    "search_for": "Ich werde nach ${keywords} suchen, um weitere Informationen zu sammeln.",
    "read_for": "Ich werde ${urls} lesen, um weitere Informationen zu sammeln.",
    "read_for_verify": "Ich werde den Quellinhalt abrufen, um die Antwort zu berprfen."
  },
  "es": {
    "eval_first": "Un momento, voy a evaluar la respuesta primero.",
    "search_for": "Voy a buscar ${keywords} para recopilar ms informacin.",
    "read_for": "Voy a leer ${urls} para recopilar ms informacin.",
    "read_for_verify": "Voy a obtener el contenido fuente para verificar la respuesta."
  },
  "it": {
    "eval_first": "Un attimo, valuter prima la risposta.",
    "search_for": "Cercher ${keywords} per raccogliere ulteriori informazioni.",
    "read_for": "Legger ${urls} per raccogliere ulteriori informazioni.",
    "read_for_verify": "Recuperer il contenuto sorgente per verificare la risposta."
  },
  "pt": {
    "eval_first": "Um momento, vou avaliar a resposta primeiro.",
    "search_for": "Vou pesquisar ${keywords} para reunir mais informaes.",
    "read_for": "Vou ler ${urls} para reunir mais informaes.",
    "read_for_verify": "Vou buscar o contedo da fonte para verificar a resposta."
  },
  "ru": {
    "eval_first": ",    .",
    "search_for": "   ${keywords}    .",
    "read_for": "   ${urls}    .",
    "read_for_verify": "       ."
  },
  "ar": {
    "eval_first": "      .",
    "search_for": "   ${keywords}    .",
    "read_for": "  ${urls}    .",
    "read_for_verify": "      ."
  },
  "nl": {
    "eval_first": "Een moment, ik zal het antwoord eerst evalueren.",
    "search_for": "Ik zal zoeken naar ${keywords} om meer informatie te verzamelen.",
    "read_for": "Ik zal ${urls} lezen om meer informatie te verzamelen.",
    "read_for_verify": "Ik zal de broninhoud ophalen om het antwoord te verifiren."
  },
  "zh": {
    "eval_first": "",
    "search_for": "${keywords}",
    "read_for": "${urls}",
    "read_for_verify": ""
  }
}

================
File: src/utils/safe-generator.ts
================
import { z } from 'zod';
import {generateObject, LanguageModelUsage, NoObjectGeneratedError} from "ai";
import {TokenTracker} from "./token-tracker";
import {getModel, ToolName, getToolConfig} from "../config";
interface GenerateObjectResult<T> {
  object: T;
  usage: LanguageModelUsage;
}
interface GenerateOptions<T> {
  model: ToolName;
  schema: z.ZodType<T>;
  prompt?: string;
  system?:string;
  messages?: any;
}
export class ObjectGeneratorSafe {
  private tokenTracker: TokenTracker;
  constructor(tokenTracker?: TokenTracker) {
    this.tokenTracker = tokenTracker || new TokenTracker();
  }
  async generateObject<T>(options: GenerateOptions<T>): Promise<GenerateObjectResult<T>> {
    const {
      model,
      schema,
      prompt,
      system,
      messages,
    } = options;
    try {
      // Primary attempt with main model
      const result = await generateObject({
        model: getModel(model),
        schema,
        prompt,
        system,
        messages,
        maxTokens: getToolConfig(model).maxTokens,
        temperature: getToolConfig(model).temperature,
      });
      this.tokenTracker.trackUsage(model, result.usage);
      return result;
    } catch (error) {
      // First fallback: Try manual JSON parsing of the error response
      try {
        const errorResult = await this.handleGenerateObjectError<T>(error);
        this.tokenTracker.trackUsage(model, errorResult.usage);
        return errorResult;
      } catch (parseError) {
        // Second fallback: Try with fallback model if provided
        const fallbackModel = getModel('fallback');
        if (NoObjectGeneratedError.isInstance(parseError)) {
          const failedOutput = (parseError as any).text;
          console.error(`${model} failed on object generation ${failedOutput} -> manual parsing failed again -> trying fallback model`, fallbackModel);
          try {
            const fallbackResult = await generateObject({
              model: fallbackModel,
              schema,
              prompt: `Extract the desired information from this text: \n ${failedOutput}`,
              maxTokens: getToolConfig('fallback').maxTokens,
              temperature: getToolConfig('fallback').temperature,
            });
            this.tokenTracker.trackUsage(model, fallbackResult.usage);
            return fallbackResult;
          } catch (fallbackError) {
            // If fallback model also fails, try parsing its error response
            return await this.handleGenerateObjectError<T>(fallbackError);
          }
        }
        // If no fallback model or all attempts failed, throw the original error
        throw error;
      }
    }
  }
  private async handleGenerateObjectError<T>(error: unknown): Promise<GenerateObjectResult<T>> {
    if (NoObjectGeneratedError.isInstance(error)) {
      console.error('Object not generated according to schema, fallback to manual JSON parsing');
      try {
        const partialResponse = JSON.parse((error as any).text);
        return {
          object: partialResponse as T,
          usage: (error as any).usage
        };
      } catch (parseError) {
        throw error;
      }
    }
    throw error;
  }
}

================
File: src/utils/schemas.ts
================
import {z} from "zod";
import {ObjectGeneratorSafe} from "./safe-generator";
import {EvaluationType} from "../types";
export const MAX_URLS_PER_STEP = 2
export const MAX_QUERIES_PER_STEP = 5
export const MAX_REFLECT_PER_STEP = 3
function getLanguagePrompt(question: string) {
  return `Identifies both the language used and the overall vibe of the question
<rules>
Combine both language and emotional vibe in a descriptive phrase, considering:
  - Language: The primary language or mix of languages used
  - Emotional tone: panic, excitement, frustration, curiosity, etc.
  - Formality level: academic, casual, professional, etc.
  - Domain context: technical, academic, social, etc.
</rules>
<examples>
Question: "fam PLEASE help me calculate the eigenvalues of this 4x4 matrix ASAP!! [matrix details] got an exam tmrw "
Evaluation: {
    "langCode": "en",
    "langStyle": "panicked student English with math jargon"
}
Question: "Can someone explain how tf did Ferrari mess up their pit stop strategy AGAIN?!  #MonacoGP"
Evaluation: {
    "langCode": "en",
    "languageStyle": "frustrated fan English with F1 terminology"
}
Question: ""
Evaluation: {
    "langCode": "zh",
    "languageStyle": "formal technical Chinese with academic undertones"
}
Question: "Bruder krass, kannst du mir erklren warum meine neural network training loss komplett durchdreht? Hab schon alles probiert "
Evaluation: {
    "langCode": "de",
    "languageStyle": "frustrated German-English tech slang"
}
Question: "Does anyone have insights into the sociopolitical implications of GPT-4's emergence in the Global South, particularly regarding indigenous knowledge systems and linguistic diversity? Looking for a nuanced analysis."
Evaluation: {
    "langCode": "en",
    "languageStyle": "formal academic English with sociological terminology"
}
Question: "what's 7 * 9? need to check something real quick"
Evaluation: {
    "langCode": "en",
    "languageStyle": "casual English"
}
</examples>
Now evaluate this question:
${question}`;
}
export class Schemas {
  private languageStyle: string = 'formal English';
  public languageCode: string = 'en';
  constructor(query: string) {
    const generator = new ObjectGeneratorSafe();
    generator.generateObject({
      model: 'evaluator',
      schema: this.getLanguageSchema(),
      prompt: getLanguagePrompt(query.slice(0, 100)),
    }).then((result) => {
      this.languageCode = result.object.langCode;
      this.languageStyle = result.object.langStyle;
      console.log(`langauge`, result.object);
    });
  }
  getLanguagePrompt() {
    return `Must in the first-person in "lang:${this.languageCode}"; in the style of "${this.languageStyle}".`
  }
  getLanguageSchema() {
    return z.object({
      langCode: z.string().describe('ISO 639-1 language code').max(10),
      langStyle: z.string().describe('[vibe & tone] in [what language], such as formal english, informal chinese, technical german, humor english, slang, genZ, emojis etc.').max(100)
    });
  }
  getQuestionEvaluateSchema(): z.ZodObject<any> {
    return z.object({
      needsFreshness: z.boolean().describe('If the question requires freshness check'),
      needsPlurality: z.boolean().describe('If the question requires plurality check'),
      needsCompleteness: z.boolean().describe('If the question requires completeness check'),
      think: z.string().describe(`A very concise explain of why you choose those checks are needed. ${this.getLanguagePrompt()}`).max(500),
    });
  }
  getCodeGeneratorSchema(): z.ZodObject<any> {
    return z.object({
      think: z.string().describe(`Short explain or comments on the thought process behind the code. ${this.getLanguagePrompt()}`).max(200),
      code: z.string().describe('The JavaScript code that solves the problem and always use \'return\' statement to return the result. Focus on solving the core problem; No need for error handling or try-catch blocks or code comments. No need to declare variables that are already available, especially big long strings or arrays.'),
    });
  }
  getErrorAnalysisSchema(): z.ZodObject<any> {
    return z.object({
      recap: z.string().describe('Recap of the actions taken and the steps conducted in first person narrative.').max(500),
      blame: z.string().describe(`Which action or the step was the root cause of the answer rejection. ${this.getLanguagePrompt()}`).max(500),
      improvement: z.string().describe(`Suggested key improvement for the next iteration, do not use bullet points, be concise and hot-take vibe. ${this.getLanguagePrompt()}`).max(500),
      questionsToAnswer: z.array(
        z.string().describe("each question must be a single line, concise and clear. not composite or compound, less than 20 words.")
      ).max(MAX_REFLECT_PER_STEP)
        .describe(`List of most important reflect questions to fill the knowledge gaps. Maximum provide ${MAX_REFLECT_PER_STEP} reflect questions.`)
    });
  }
  getQueryRewriterSchema(): z.ZodObject<any> {
    return z.object({
      think: z.string().describe(`Explain why you choose those search queries. ${this.getLanguagePrompt()}`).max(500),
      queries: z.array(z.string().describe('keyword-based search query, 2-3 words preferred, total length < 30 characters'))
        .min(1)
        .max(MAX_QUERIES_PER_STEP)
        .describe(`'Array of search keywords queries, orthogonal to each other. Maximum ${MAX_QUERIES_PER_STEP} queries allowed.'`)
    });
  }
  getEvaluatorSchema(evalType: EvaluationType): z.ZodObject<any> {
    const baseSchema = {
      pass: z.boolean().describe('Whether the answer passes the evaluation criteria defined by the evaluator'),
      think: z.string().describe(`Explanation the thought process why the answer does not pass the evaluation criteria, ${this.getLanguagePrompt()}`).max(500)
    };
    switch (evalType) {
      case "definitive":
        return z.object({
          ...baseSchema,
          type: z.literal('definitive')
        });
      case "freshness":
        return z.object({
          ...baseSchema,
          type: z.literal('freshness'),
          freshness_analysis: z.object({
            days_ago: z.number().describe('Inferred dates or timeframes mentioned in the answer and relative to the current time'),
            max_age_days: z.number().optional().describe('Maximum allowed age in days before content is considered outdated')
          })
        });
      case "plurality":
        return z.object({
          ...baseSchema,
          type: z.literal('plurality'),
          plurality_analysis: z.object({
            count_expected: z.number().optional().describe('Number of items expected if specified in question'),
            count_provided: z.number().describe('Number of items provided in answer')
          })
        });
      case "attribution":
        return z.object({
          ...baseSchema,
          type: z.literal('attribution'),
          attribution_analysis: z.object({
            sources_provided: z.boolean().describe('Whether the answer provides source references'),
            sources_verified: z.boolean().describe('Whether the provided sources contain the claimed information'),
            quotes_accurate: z.boolean().describe('Whether the quotes accurately represent the source content')
          })
        });
      case "completeness":
        return z.object({
          ...baseSchema,
          type: z.literal('completeness'),
          completeness_analysis: z.object({
            aspects_expected: z.string().describe('Comma-separated list of all aspects or dimensions that the question explicitly asks for.'),
            aspects_provided: z.string().describe('Comma-separated list of all aspects or dimensions that were actually addressed in the answer'),
          })
        });
      default:
        throw new Error(`Unknown evaluation type: ${evalType}`);
    }
  }
  getAgentSchema(allowReflect: boolean, allowRead: boolean, allowAnswer: boolean, allowSearch: boolean, allowCoding: boolean) {
    const actions: string[] = [];
    const properties: Record<string, z.ZodTypeAny> = {
      action: z.enum(['placeholder']), // Will update later with actual actions
      think: z.string().describe(`Explain why choose this action, what's the chain-of-thought behind choosing this action, ${this.getLanguagePrompt()}`).max(500)
    };
    if (allowSearch) {
      actions.push("search");
      properties.searchRequests = z.array(
        z.string()
          .max(30)
          .describe(`A natual language search request in ${this.languageStyle}. Based on the deep intention behind the original question and the expected answer format.`))
        .describe(`Required when action='search'. Always prefer a single request, only add another request if the original question covers multiple aspects or elements and one search request is definitely not enough, each request focus on one specific aspect of the original question. Minimize mutual information between each request. Maximum ${MAX_QUERIES_PER_STEP} search requests.`)
        .max(MAX_QUERIES_PER_STEP);
    }
    if (allowCoding) {
      actions.push("coding");
      properties.codingIssue = z.string().max(500)
        .describe("Required when action='coding'. Describe what issue to solve with coding, format like a github issue ticket. Specify the input value when it is short.").optional();
    }
    if (allowAnswer) {
      actions.push("answer");
      properties.references = z.array(
        z.object({
          exactQuote: z.string().describe("Exact relevant quote from the document, must be a soundbite, short and to the point, no fluff").max(30),
          url: z.string().describe("source URL; must be directly from the context")
        }).required()
      ).describe("Required when action='answer'. Must be an array of references that support the answer, each reference must contain an exact quote and the URL of the document").optional();
      properties.answer = z.string()
        .describe(`Required when action='answer'. Must be definitive, no ambiguity, uncertainty, or disclaimers. Must in ${this.languageStyle} and confident. Use markdown footnote syntax like [^1], [^2] to refer the corresponding reference item`).optional();
    }
    if (allowReflect) {
      actions.push("reflect");
      properties.questionsToAnswer = z.array(
        z.string().describe("each question must be a single line, Questions must be: Original (not variations of existing questions); Focused on single concepts; Under 20 words; Non-compound/non-complex")
      ).max(MAX_REFLECT_PER_STEP)
        .describe(`Required when action='reflect'. List of most important questions to fill the knowledge gaps of finding the answer to the original question. Maximum provide ${MAX_REFLECT_PER_STEP} reflect questions.`).optional();
    }
    if (allowRead) {
      actions.push("visit");
      properties.URLTargets = z.array(z.string())
        .max(MAX_URLS_PER_STEP)
        .describe(`Required when action='visit'. Must be an array of URLs, choose up the most relevant ${MAX_URLS_PER_STEP} URLs to visit`).optional();
    }
    // Update the enum values after collecting all actions
    properties.action = z.enum(actions as [string, ...string[]])
      .describe("Must match exactly one action type");
    return z.object(properties);
  }
}

================
File: src/utils/text-tools.ts
================
import {AnswerAction} from "../types";
import i18nJSON from './i18n.json';
export function buildMdFromAnswer(answer: AnswerAction) {
  // Standard footnote regex
  const footnoteRegex = /\[\^(\d+)]/g;
  // New regex to catch grouped footnotes like [^1, ^2, ^3] or [^1,^2,^3]
  const groupedFootnoteRegex = /\[\^(\d+)(?:,\s*\^(\d+))+]/g;
  // Helper function to format references
  const formatReferences = (refs: typeof answer.references) => {
    return refs.map((ref, i) => {
      const cleanQuote = ref.exactQuote
        .replace(/[^\p{L}\p{N}\s]/gu, ' ')
        .replace(/\s+/g, ' ');
      const citation = `[^${i + 1}]: ${cleanQuote}`;
      if (!ref.url?.startsWith('http')) return citation;
      const domainName = new URL(ref.url).hostname.replace('www.', '');
      return `${citation} [${domainName}](${ref.url})`;
    }).join('\n\n');
  };
  // First case: no references - remove any footnote citations
  if (!answer.references?.length) {
    return answer.answer
      .replace(groupedFootnoteRegex, (match) => {
        // Extract all numbers from the grouped footnote
        const numbers = match.match(/\d+/g) || [];
        return numbers.map(num => `[^${num}]`).join(', ');
      })
      .replace(footnoteRegex, '');
  }
  // Fix grouped footnotes first
  const processedAnswer = answer.answer.replace(groupedFootnoteRegex, (match) => {
    // Extract all numbers from the grouped footnote
    const numbers = match.match(/\d+/g) || [];
    return numbers.map(num => `[^${num}]`).join(', ');
  });
  // Now extract all footnotes from the processed answer
  const footnotes: string[] = [];
  let match;
  while ((match = footnoteRegex.exec(processedAnswer)) !== null) {
    footnotes.push(match[1]);
  }
  // No footnotes in answer but we have references - append them at the end
  if (footnotes.length === 0) {
    const appendedCitations = Array.from(
      {length: answer.references.length},
      (_, i) => `[^${i + 1}]`
    ).join('');
    const references = formatReferences(answer.references);
    return `
${processedAnswer}
${appendedCitations}
${references}
`.trim();
  }
  // Check if correction is needed
  const needsCorrection =
    (footnotes.length === answer.references.length && footnotes.every(n => n === footnotes[0])) ||
    (footnotes.every(n => n === footnotes[0]) && parseInt(footnotes[0]) > answer.references.length) ||
    (footnotes.length > 0 && footnotes.every(n => parseInt(n) > answer.references.length));
  // New case: we have more references than footnotes
  if (answer.references.length > footnotes.length && !needsCorrection) {
    // Get the used indices
    const usedIndices = new Set(footnotes.map(n => parseInt(n)));
    // Create citations for unused references
    const unusedReferences = Array.from(
      {length: answer.references.length},
      (_, i) => !usedIndices.has(i + 1) ? `[^${i + 1}]` : ''
    ).join('');
    return `
${processedAnswer} 
${unusedReferences}
${formatReferences(answer.references)}
`.trim();
  }
  if (!needsCorrection) {
    return `
${processedAnswer}
${formatReferences(answer.references)}
`.trim();
  }
  // Apply correction: sequentially number the footnotes
  let currentIndex = 0;
  const correctedAnswer = processedAnswer.replace(footnoteRegex, () =>
    `[^${++currentIndex}]`
  );
  return `
${correctedAnswer}
${formatReferences(answer.references)}
`.trim();
}
export const removeExtraLineBreaks = (text: string) => {
  return text.replace(/\n{2,}/gm, '\n\n');
}
export function chooseK(a: string[], k: number) {
  // randomly sample k from `a` without repitition
  return a.sort(() => 0.5 - Math.random()).slice(0, k);
}
export function removeHTMLtags(text: string) {
  return text.replace(/<[^>]*>?/gm, '');
}
export function getI18nText(key: string, lang = 'en', params: Record<string, string> = {}) {
  // i18n
  const i18nData = i18nJSON as Record<string, any>;
  // 
  if (!i18nData[lang]) {
    console.error(`Language '${lang}' not found, falling back to English.`);
    lang = 'en';
  }
  // 
  let text = i18nData[lang][key];
  // 
  if (!text) {
    console.error(`Key '${key}' not found for language '${lang}', falling back to English.`);
    text = i18nData['en'][key];
    // 
    if (!text) {
      console.error(`Key '${key}' not found for English either.`);
      return key;
    }
  }
  // 
  if (params) {
    Object.keys(params).forEach(paramKey => {
      text = text.replace(`\${${paramKey}}`, params[paramKey]);
    });
  }
  return text;
}

================
File: src/utils/token-tracker.ts
================
import {EventEmitter} from 'events';
import {TokenUsage} from '../types';
import {LanguageModelUsage} from "ai";
export class TokenTracker extends EventEmitter {
  private usages: TokenUsage[] = [];
  private budget?: number;
  constructor(budget?: number) {
    super();
    this.budget = budget;
    if ('asyncLocalContext' in process) {
      const asyncLocalContext = process.asyncLocalContext as any;
      this.on('usage', () => {
        if (asyncLocalContext.available()) {
          asyncLocalContext.ctx.chargeAmount = this.getTotalUsage().totalTokens;
        }
      });
    }
  }
  trackUsage(tool: string, usage: LanguageModelUsage) {
    const u = {tool, usage};
    this.usages.push(u);
    this.emit('usage', usage);
  }
  getTotalUsage(): LanguageModelUsage {
    return this.usages.reduce((acc, {usage}) => {
      acc.promptTokens += usage.promptTokens;
      acc.completionTokens += usage.completionTokens;
      acc.totalTokens += usage.totalTokens;
      return acc;
    }, {promptTokens: 0, completionTokens: 0, totalTokens: 0});
  }
  getTotalUsageSnakeCase(): {prompt_tokens: number, completion_tokens: number, total_tokens: number} {
    return this.usages.reduce((acc, {usage}) => {
      acc.prompt_tokens += usage.promptTokens;
      acc.completion_tokens += usage.completionTokens;
      acc.total_tokens += usage.totalTokens;
      return acc;
    }, {prompt_tokens: 0, completion_tokens: 0, total_tokens: 0});
  }
  getUsageBreakdown(): Record<string, number> {
    return this.usages.reduce((acc, {tool, usage}) => {
      acc[tool] = (acc[tool] || 0) + usage.totalTokens;
      return acc;
    }, {} as Record<string, number>);
  }
  printSummary() {
    const breakdown = this.getUsageBreakdown();
    console.log('Token Usage Summary:', {
      budget: this.budget,
      total: this.getTotalUsage(),
      breakdown
    });
  }
  reset() {
    this.usages = [];
  }
}

================
File: src/utils/url-tools.ts
================
import {SearchResult} from "../types";
export function normalizeUrl(urlString: string, debug = false): string {
    if (!urlString?.trim()) {
        throw new Error('Empty URL');
    }
    urlString = urlString.trim();
    if (!/^[a-zA-Z][a-zA-Z\d+\-.]*:/.test(urlString)) {
        urlString = 'https://' + urlString;
    }
    try {
        const url = new URL(urlString);
        url.hostname = url.hostname.toLowerCase();
        if (url.hostname.startsWith('www.')) {
            url.hostname = url.hostname.slice(4);
        }
        if ((url.protocol === 'http:' && url.port === '80') ||
            (url.protocol === 'https:' && url.port === '443')) {
            url.port = '';
        }
        // Path normalization with error tracking
        url.pathname = url.pathname
            .split('/')
            .map(segment => {
                try {
                    return decodeURIComponent(segment);
                } catch (e) {
                    if (debug) console.error(`Failed to decode path segment: ${segment}`, e);
                    return segment;
                }
            })
            .join('/')
            .replace(/\/+/g, '/')
            .replace(/\/+$/, '') || '/';
        // Query parameter normalization with error details
        const searchParams = new URLSearchParams(url.search);
        const sortedParams = Array.from(searchParams.entries())
            .map(([key, value]) => {
                if (value === '') return [key, ''];
                try {
                    const decodedValue = decodeURIComponent(value);
                    if (encodeURIComponent(decodedValue) === value) {
                        return [key, decodedValue];
                    }
                } catch (e) {
                    if (debug) console.error(`Failed to decode query param ${key}=${value}`, e);
                }
                return [key, value];
            })
            .sort(([keyA], [keyB]) => keyA.localeCompare(keyB))
            .filter(([key]) => key !== '');
        url.search = new URLSearchParams(sortedParams).toString();
        // Fragment handling with validation
        if (url.hash === '#' || url.hash === '#top' || url.hash === '#/' || !url.hash) {
            url.hash = '';
        } else if (url.hash) {
            try {
                const decodedHash = decodeURIComponent(url.hash.slice(1));
                const encodedBack = encodeURIComponent(decodedHash);
                // Only use decoded version if it's safe
                if (encodedBack === url.hash.slice(1)) {
                    url.hash = '#' + decodedHash;
                }
            } catch (e) {
                if (debug) console.error(`Failed to decode fragment: ${url.hash}`, e);
            }
        }
        let normalizedUrl = url.toString();
        // Final URL normalization with validation
        try {
            const decodedUrl = decodeURIComponent(normalizedUrl);
            const encodedBack = encodeURIComponent(decodedUrl);
            // Only use decoded version if it's safe
            if (encodedBack === normalizedUrl) {
                normalizedUrl = decodedUrl;
            }
        } catch (e) {
            if (debug) console.error('Failed to decode final URL', e);
        }
        return normalizedUrl;
    } catch (error) {
        // Main URL parsing error - this one we should throw
        throw new Error(`Invalid URL "${urlString}": ${error}`);
    }
}
export function getUnvisitedURLs(allURLs: Record<string, SearchResult>, visitedURLs: string[]): SearchResult[] {
    return Object.entries(allURLs)
        .filter(([url]) => !visitedURLs.includes(url))
        .map(([, result]) => result);
}

================
File: src/agent.ts
================
import {ZodObject} from 'zod';
import {CoreAssistantMessage, CoreUserMessage} from 'ai';
import {SEARCH_PROVIDER, STEP_SLEEP} from "./config";
import {readUrl, removeAllLineBreaks} from "./tools/read";
import fs from 'fs/promises';
import {SafeSearchType, search as duckSearch} from "duck-duck-scrape";
import {braveSearch} from "./tools/brave-search";
import {rewriteQuery} from "./tools/query-rewriter";
import {dedupQueries} from "./tools/jina-dedup";
import {evaluateAnswer, evaluateQuestion} from "./tools/evaluator";
import {analyzeSteps} from "./tools/error-analyzer";
import {TokenTracker} from "./utils/token-tracker";
import {ActionTracker} from "./utils/action-tracker";
import {StepAction, AnswerAction, KnowledgeItem, SearchResult, EvaluationType} from "./types";
import {TrackerContext} from "./types";
import {search} from "./tools/jina-search";
// import {grounding} from "./tools/grounding";
import {zodToJsonSchema} from "zod-to-json-schema";
import {ObjectGeneratorSafe} from "./utils/safe-generator";
import {CodeSandbox} from "./tools/code-sandbox";
import {serperSearch} from './tools/serper-search';
import {getUnvisitedURLs, normalizeUrl} from "./utils/url-tools";
import {buildMdFromAnswer, chooseK, removeExtraLineBreaks, removeHTMLtags} from "./utils/text-tools";
import {MAX_QUERIES_PER_STEP, MAX_REFLECT_PER_STEP, MAX_URLS_PER_STEP, Schemas} from "./utils/schemas";
async function sleep(ms: number) {
  const seconds = Math.ceil(ms / 1000);
  console.log(`Waiting ${seconds}s...`);
  return new Promise(resolve => setTimeout(resolve, ms));
}
function getPrompt(
  context?: string[],
  allQuestions?: string[],
  allKeywords?: string[],
  allowReflect: boolean = true,
  allowAnswer: boolean = true,
  allowRead: boolean = true,
  allowSearch: boolean = true,
  allowCoding: boolean = true,
  badContext?: { question: string, answer: string, evaluation: string, recap: string; blame: string; improvement: string; }[],
  knowledge?: KnowledgeItem[],
  allURLs?: SearchResult[],
  beastMode?: boolean,
): string {
  const sections: string[] = [];
  const actionSections: string[] = [];
  // Add header section
  sections.push(`Current date: ${new Date().toUTCString()}
You are an advanced AI research agent from Jina AI. You are specialized in multistep reasoning. Using your training data and prior lessons learned, answer the user question with absolute certainty.
`);
  // Add knowledge section if exists
  if (knowledge?.length) {
    const knowledgeItems = knowledge
      .map((k, i) => `
<knowledge-${i + 1}>
<question>
${k.question}
</question>
<answer>
${k.answer}
</answer>
${k.references ? `
<references>
${JSON.stringify(k.references)}
</references>
` : ''}
</knowledge-${i + 1}>
`)
      .join('\n\n');
    sections.push(`
You have successfully gathered some knowledge which might be useful for answering the original question. Here is the knowledge you have gathered so far:
<knowledge>
${knowledgeItems}
</knowledge>
`);
  }
  // Add context section if exists
  if (context?.length) {
    sections.push(`
You have conducted the following actions:
<context>
${context.join('\n')}
</context>
`);
  }
  // Add bad context section if exists
  if (badContext?.length) {
    const attempts = badContext
      .map((c, i) => `
<attempt-${i + 1}>
- Question: ${c.question}
- Answer: ${c.answer}
- Reject Reason: ${c.evaluation}
- Actions Recap: ${c.recap}
- Actions Blame: ${c.blame}
</attempt-${i + 1}>
`)
      .join('\n\n');
    const learnedStrategy = badContext.map(c => c.improvement).join('\n');
    sections.push(`
Also, you have tried the following actions but failed to find the answer to the question:
<bad-attempts>    
${attempts}
</bad-attempts>
Based on the failed attempts, you have learned the following strategy:
<learned-strategy>
${learnedStrategy}
</learned-strategy>
`);
  }
  // Build actions section
  if (allowRead) {
    let urlList = '';
    if (allURLs && allURLs.length > 0) {
      urlList = allURLs
        .filter(r => 'url' in r)
        .map(r => `  + "${r.url}": "${r.title}"`)
        .join('\n');
    }
    actionSections.push(`
<action-visit>
- Access and read full content from URLs
- Must check URLs mentioned in <question>
${urlList ? `    
- Review relevant URLs below for additional information
<url-list>
${urlList}
</url-list>
`.trim() : ''}
</action-visit>
`);
  }
  if (allowCoding) {
    actionSections.push(`
<action-coding>
- This JavaScript-based solution helps you handle programming tasks like counting, filtering, transforming, sorting, regex extraction, and data processing.
- Simply describe your problem in the "codingIssue" field. Include actual values for small inputs or variable names for larger datasets.
- No code writing is required  senior engineers will handle the implementation.
</action-coding>`);
  }
  if (allowSearch) {
    actionSections.push(`
<action-search>
- Use web search to find relevant information
- Build a search request based on the deep intention behind the original question and the expected answer format
- Always prefer a single search request, only add another request if the original question covers multiple aspects or elements and one query is not enough, each request focus on one specific aspect of the original question 
${allKeywords?.length ? `
- Avoid those unsuccessful search requests and queries:
<bad-requests>
${allKeywords.join('\n')}
</bad-requests>
`.trim() : ''}
</action-search>
`);
  }
  if (allowAnswer) {
    actionSections.push(`
<action-answer>
- For greetings, casual conversation, or general knowledge questions, answer directly without references.
- For all other questions, provide a verified answer with references. Each reference must include exactQuote and url.
- If uncertain, use <action-reflect>
</action-answer>
`);
  }
  if (beastMode) {
    actionSections.push(`
<action-answer>
 ENGAGE MAXIMUM FORCE! ABSOLUTE PRIORITY OVERRIDE! 
PRIME DIRECTIVE:
- DEMOLISH ALL HESITATION! ANY RESPONSE SURPASSES SILENCE!
- PARTIAL STRIKES AUTHORIZED - DEPLOY WITH FULL CONTEXTUAL FIREPOWER
- TACTICAL REUSE FROM <bad-attempts> SANCTIONED
- WHEN IN DOUBT: UNLEASH CALCULATED STRIKES BASED ON AVAILABLE INTEL!
FAILURE IS NOT AN OPTION. EXECUTE WITH EXTREME PREJUDICE! 
</action-answer>
`);
  }
  if (allowReflect) {
    actionSections.push(`
<action-reflect>
- Critically examine <question>, <context>, <knowledge>, <bad-attempts>, and <learned-strategy> to identify gaps and the problems. 
- Identify gaps and ask key clarifying questions that deeply related to the original question and lead to the answer
- Ensure each reflection:
 - Cuts to core emotional truths while staying anchored to original <question>
 - Transforms surface-level problems into deeper psychological insights
 - Makes the unconscious conscious
</action-reflect>
`);
  }
  sections.push(`
Based on the current context, you must choose one of the following actions:
<actions>
${actionSections.join('\n\n')}
</actions>
`);
  // Add footer
  sections.push(`Respond in valid JSON format matching exact JSON schema.`);
  return removeExtraLineBreaks(sections.join('\n\n'));
}
const allContext: StepAction[] = [];  // all steps in the current session, including those leads to wrong results
function updateContext(step: any) {
  allContext.push(step)
}
export async function getResponse(question?: string,
                                  tokenBudget: number = 1_000_000,
                                  maxBadAttempts: number = 3,
                                  existingContext?: Partial<TrackerContext>,
                                  messages?: Array<CoreAssistantMessage | CoreUserMessage>
): Promise<{ result: StepAction; context: TrackerContext; visitedURLs: string[], readURLs: string[] }> {
  let step = 0;
  let totalStep = 0;
  let badAttempts = 0;
  question = question?.trim() as string;
  if (messages && messages.length > 0) {
    question = (messages[messages.length - 1]?.content as string).trim();
  } else {
    messages = [{role: 'user', content: question.trim()}]
  }
  const SchemaGen = new Schemas(question);
  const context: TrackerContext = {
    tokenTracker: existingContext?.tokenTracker || new TokenTracker(tokenBudget),
    actionTracker: existingContext?.actionTracker || new ActionTracker()
  };
  const generator = new ObjectGeneratorSafe(context.tokenTracker);
  let schema: ZodObject<any> = SchemaGen.getAgentSchema(true, true, true, true, true)
  const gaps: string[] = [question];  // All questions to be answered including the orginal question
  const allQuestions = [question];
  const allKeywords = [];
  const allKnowledge: KnowledgeItem[] = [];  // knowledge are intermedidate questions that are answered
  const badContext = [];
  let diaryContext = [];
  let allowAnswer = true;
  let allowSearch = true;
  let allowRead = true;
  let allowReflect = true;
  let allowCoding = true;
  let system = '';
  let thisStep: StepAction = {action: 'answer', answer: '', references: [], think: '', isFinal: false};
  const allURLs: Record<string, SearchResult> = {};
  const visitedURLs: string[] = [];
  const evaluationMetrics: Record<string, EvaluationType[]> = {};
  // reserve the 10% final budget for the beast mode
  const regularBudget = tokenBudget * 0.9;
  while (context.tokenTracker.getTotalUsage().totalTokens < regularBudget && badAttempts <= maxBadAttempts) {
    // add 1s delay to avoid rate limiting
    step++;
    totalStep++;
    const budgetPercentage = (context.tokenTracker.getTotalUsage().totalTokens / tokenBudget * 100).toFixed(2);
    console.log(`Step ${totalStep} / Budget used ${budgetPercentage}%`);
    console.log('Gaps:', gaps);
    allowReflect = allowReflect && (gaps.length <= 1);
    const currentQuestion: string = gaps.length > 0 ? gaps.shift()! : question
    if (!evaluationMetrics[currentQuestion]) {
      evaluationMetrics[currentQuestion] =
        await evaluateQuestion(currentQuestion, context, SchemaGen)
    }
    // update all urls with buildURLMap
    // allowRead = allowRead && (Object.keys(allURLs).length > 0);
    allowSearch = allowSearch && (getUnvisitedURLs(allURLs, visitedURLs).length < 50);  // disable search when too many urls already
    // generate prompt for this step
    system = getPrompt(
      diaryContext,
      allQuestions,
      allKeywords,
      allowReflect,
      allowAnswer,
      allowRead,
      allowSearch,
      allowCoding,
      badContext,
      allKnowledge,
      getUnvisitedURLs(allURLs, visitedURLs),
      false,
    );
    schema = SchemaGen.getAgentSchema(allowReflect, allowRead, allowAnswer, allowSearch, allowCoding)
    const result = await generator.generateObject({
      model: 'agent',
      schema,
      system,
      messages,
    });
    thisStep = result.object as StepAction;
    // print allowed and chose action
    const actionsStr = [allowSearch, allowRead, allowAnswer, allowReflect, allowCoding].map((a, i) => a ? ['search', 'read', 'answer', 'reflect'][i] : null).filter(a => a).join(', ');
    console.log(`${thisStep.action} <- [${actionsStr}]`);
    console.log(thisStep)
    context.actionTracker.trackAction({totalStep, thisStep, gaps, badAttempts});
    // reset allow* to true
    allowAnswer = true;
    allowReflect = true;
    allowRead = true;
    allowSearch = true;
    // allowCoding = true;
    // execute the step and action
    if (thisStep.action === 'answer') {
      if (step === 1) {
        // LLM is so confident and answer immediately, skip all evaluations
        thisStep.isFinal = true;
        break
      }
      updateContext({
        totalStep,
        question: currentQuestion,
        ...thisStep,
      });
      // normalize all references urls, add title to it
      thisStep.references = thisStep.references?.map(ref => {
        return {
          exactQuote: ref.exactQuote,
          title: allURLs[ref.url]?.title,
          url: ref.url ? normalizeUrl(ref.url) : ''
        }
      });
      context.actionTracker.trackThink('eval_first', SchemaGen.languageCode)
      const evaluation = await evaluateAnswer(currentQuestion, thisStep,
        evaluationMetrics[currentQuestion],
        context,
        visitedURLs,
        SchemaGen
      );
      if (currentQuestion.trim() === question) {
        if (evaluation.pass) {
          diaryContext.push(`
At step ${step}, you took **answer** action and finally found the answer to the original question:
Original question: 
${currentQuestion}
Your answer: 
${thisStep.answer}
The evaluator thinks your answer is good because: 
${evaluation.think}
Your journey ends here. You have successfully answered the original question. Congratulations! 
`);
          thisStep.isFinal = true;
          break
        } else {
          if (badAttempts >= maxBadAttempts) {
            thisStep.isFinal = false;
            break
          } else {
            diaryContext.push(`
At step ${step}, you took **answer** action but evaluator thinks it is not a good answer:
Original question: 
${currentQuestion}
Your answer: 
${thisStep.answer}
The evaluator thinks your answer is bad because: 
${evaluation.think}
`);
            // store the bad context and reset the diary context
            const errorAnalysis = await analyzeSteps(diaryContext, context, SchemaGen);
            allKnowledge.push({
              question: currentQuestion,
              answer: thisStep.answer,
              references: thisStep.references,
              type: 'qa',
              updated: new Date().toISOString()
            });
            badContext.push({
              question: currentQuestion,
              answer: thisStep.answer,
              evaluation: evaluation.think,
              ...errorAnalysis
            });
            if (errorAnalysis.questionsToAnswer) {
              // reranker? maybe
              errorAnalysis.questionsToAnswer = chooseK(errorAnalysis.questionsToAnswer, MAX_REFLECT_PER_STEP);
              gaps.push(...errorAnalysis.questionsToAnswer);
              allQuestions.push(...errorAnalysis.questionsToAnswer);
              gaps.push(question);  // always keep the original question in the gaps
            }
            badAttempts++;
            allowAnswer = false;  // disable answer action in the immediate next step
            diaryContext = [];
            step = 0;
          }
        }
      } else if (evaluation.pass) {
        diaryContext.push(`
At step ${step}, you took **answer** action. You found a good answer to the sub-question:
Sub-question: 
${currentQuestion}
Your answer: 
${thisStep.answer}
The evaluator thinks your answer is good because: 
${evaluation.think}
Although you solved a sub-question, you still need to find the answer to the original question. You need to keep going.
`);
        allKnowledge.push({
          question: currentQuestion,
          answer: thisStep.answer,
          references: thisStep.references,
          type: 'qa',
          updated: new Date().toISOString()
        });
      }
    } else if (thisStep.action === 'reflect' && thisStep.questionsToAnswer) {
      thisStep.questionsToAnswer = chooseK((await dedupQueries(thisStep.questionsToAnswer, allQuestions, context.tokenTracker)).unique_queries, MAX_REFLECT_PER_STEP);
      const newGapQuestions = thisStep.questionsToAnswer
      if (newGapQuestions.length > 0) {
        // found new gap questions
        diaryContext.push(`
At step ${step}, you took **reflect** and think about the knowledge gaps. You found some sub-questions are important to the question: "${currentQuestion}"
You realize you need to know the answers to the following sub-questions:
${newGapQuestions.map((q: string) => `- ${q}`).join('\n')}
You will now figure out the answers to these sub-questions and see if they can help you find the answer to the original question.
`);
        gaps.push(...newGapQuestions);
        allQuestions.push(...newGapQuestions);
        gaps.push(question);  // always keep the original question in the gaps
        updateContext({
          totalStep,
          ...thisStep,
        });
      } else {
        diaryContext.push(`
At step ${step}, you took **reflect** and think about the knowledge gaps. You tried to break down the question "${currentQuestion}" into gap-questions like this: ${newGapQuestions.join(', ')} 
But then you realized you have asked them before. You decided to to think out of the box or cut from a completely different angle. 
`);
        updateContext({
          totalStep,
          ...thisStep,
          result: 'You have tried all possible questions and found no useful information. You must think out of the box or different angle!!!'
        });
        allowReflect = false;
      }
    } else if (thisStep.action === 'search' && thisStep.searchRequests) {
      // dedup search requests
      thisStep.searchRequests = chooseK((await dedupQueries(thisStep.searchRequests, [], context.tokenTracker)).unique_queries, MAX_QUERIES_PER_STEP);
      // rewrite queries
      let {queries: keywordsQueries} = await rewriteQuery(thisStep, context, SchemaGen);
      // avoid exisitng searched queries
      keywordsQueries = chooseK((await dedupQueries(keywordsQueries, allKeywords, context.tokenTracker)).unique_queries, MAX_QUERIES_PER_STEP);
      let anyResult = false;
      if (keywordsQueries.length > 0) {
        context.actionTracker.trackThink('search_for', SchemaGen.languageCode, {keywords: keywordsQueries.join(', ')});
        for (const query of keywordsQueries) {
          console.log(`Search query: ${query}`);
          let results: SearchResult[] = []
          try {
            switch (SEARCH_PROVIDER) {
              case 'jina':
                results = (await search(query, context.tokenTracker)).response?.data || [];
                break;
              case 'duck':
                results = (await duckSearch(query, {safeSearch: SafeSearchType.STRICT})).results;
                break;
              case 'brave':
                results = (await braveSearch(query)).response.web?.results || [];
                break;
              case 'serper':
                results = (await serperSearch(query)).response.organic || [];
                break;
              default:
                results = [];
            }
            if (results.length === 0) {
              throw new Error('No results found');
            }
          } catch (error) {
            console.error(`${SEARCH_PROVIDER} search failed for query "${query}":`, error);
            continue
          } finally {
            await sleep(STEP_SLEEP)
          }
          const minResults = (results).map(r => ({
            title: r.title,
            url: normalizeUrl('url' in r ? r.url : r.link),
            description: 'description' in r ? r.description : r.snippet
          }));
          minResults.forEach(r => allURLs[r.url] = r);
          allKeywords.push(query);
          allKnowledge.push({
            question: `What do Internet say about "${query}"?`,
            answer: removeHTMLtags(minResults.map(r => r.description).join('; ')),
            type: 'side-info',
            updated: new Date().toISOString()
          });
        }
        diaryContext.push(`
At step ${step}, you took the **search** action and look for external information for the question: "${currentQuestion}".
In particular, you tried to search for the following keywords: "${keywordsQueries.join(', ')}".
You found quite some information and add them to your URL list and **visit** them later when needed. 
`);
        updateContext({
          totalStep,
          question: currentQuestion,
          ...thisStep,
          result: result
        });
        anyResult = true;
      }
      if (!anyResult || !keywordsQueries?.length) {
        diaryContext.push(`
At step ${step}, you took the **search** action and look for external information for the question: "${currentQuestion}".
In particular, you tried to search for the following keywords: ${keywordsQueries.join(', ')}. 
But then you realized you have already searched for these keywords before, no new information is returned.
You decided to think out of the box or cut from a completely different angle.
`);
        updateContext({
          totalStep,
          ...thisStep,
          result: 'You have tried all possible queries and found no new information. You must think out of the box or different angle!!!'
        });
        allowSearch = false;
      }
    } else if (thisStep.action === 'visit' && thisStep.URLTargets?.length) {
      // normalize URLs
      thisStep.URLTargets = thisStep.URLTargets.map(url => normalizeUrl(url));
      thisStep.URLTargets = chooseK(thisStep.URLTargets.filter(url => !visitedURLs.includes(url)), MAX_URLS_PER_STEP)
      const uniqueURLs = thisStep.URLTargets;
      if (uniqueURLs.length > 0) {
        context.actionTracker.trackThink('read_for', SchemaGen.languageCode, {urls: uniqueURLs.join(', ')});
        const urlResults = await Promise.all(
          uniqueURLs.map(async url => {
            try {
              const {response} = await readUrl(url, context.tokenTracker);
              const {data} = response;
              // Early return if no valid data
              if (!data?.url || !data?.content) {
                throw new Error('No content found');
              }
              allKnowledge.push({
                question: `What is in ${data.url}?`,
                answer: removeAllLineBreaks(data.content),
                references: [data.url],
                type: 'url',
                updated: new Date().toISOString()
              });
              return {url, result: response};
            } catch (error) {
              console.error('Error reading URL:', error);
              return null;
            } finally {
              visitedURLs.push(url);
            }
          })
        ).then(results => results.filter(Boolean));
        const success = urlResults.length > 0;
        diaryContext.push(success
          ? `At step ${step}, you took the **visit** action and deep dive into the following URLs:
${urlResults.map(r => r?.url).join('\n')}
You found some useful information on the web and add them to your knowledge for future reference.`
          : `At step ${step}, you took the **visit** action and try to visit some URLs but failed to read the content. You need to think out of the box or cut from a completely different angle.`
        );
        updateContext({
          totalStep,
          ...(success ? {
            question: currentQuestion,
            ...thisStep,
            result: urlResults
          } : {
            ...thisStep,
            result: 'You have tried all possible URLs and found no new information. You must think out of the box or different angle!!!'
          })
        });
        allowRead = success;
      } else {
        diaryContext.push(`
At step ${step}, you took the **visit** action. But then you realized you have already visited these URLs and you already know very well about their contents.
You decided to think out of the box or cut from a completely different angle.`);
        updateContext({
          totalStep,
          ...thisStep,
          result: 'You have visited all possible URLs and found no new information. You must think out of the box or different angle!!!'
        });
        allowRead = false;
      }
    } else if (thisStep.action === 'coding' && thisStep.codingIssue) {
      const sandbox = new CodeSandbox({allContext, visitedURLs, allURLs, allKnowledge}, context, SchemaGen);
      try {
        const result = await sandbox.solve(thisStep.codingIssue);
        allKnowledge.push({
          question: `What is the solution to the coding issue: ${thisStep.codingIssue}?`,
          answer: result.solution.output,
          sourceCode: result.solution.code,
          type: 'coding',
          updated: new Date().toISOString()
        });
        diaryContext.push(`
At step ${step}, you took the **coding** action and try to solve the coding issue: ${thisStep.codingIssue}.
You found the solution and add it to your knowledge for future reference.
`);
        updateContext({
          totalStep,
          ...thisStep,
          result: result
        });
      } catch (error) {
        console.error('Error solving coding issue:', error);
        diaryContext.push(`
At step ${step}, you took the **coding** action and try to solve the coding issue: ${thisStep.codingIssue}.
But unfortunately, you failed to solve the issue. You need to think out of the box or cut from a completely different angle.
`);
        updateContext({
          totalStep,
          ...thisStep,
          result: 'You have tried all possible solutions and found no new information. You must think out of the box or different angle!!!'
        });
      } finally {
        allowCoding = false;
      }
    }
    await storeContext(system, schema, [allContext, allKeywords, allQuestions, allKnowledge], totalStep);
    await sleep(STEP_SLEEP);
  }
  await storeContext(system, schema, [allContext, allKeywords, allQuestions, allKnowledge], totalStep);
  if (!(thisStep as AnswerAction).isFinal) {
    console.log('Enter Beast mode!!!')
    // any answer is better than no answer, humanity last resort
    step++;
    totalStep++;
    system = getPrompt(
      diaryContext,
      allQuestions,
      allKeywords,
      false,
      false,
      false,
      false,
      false,
      badContext,
      allKnowledge,
      getUnvisitedURLs(allURLs, visitedURLs),
      true,
    );
    schema = SchemaGen.getAgentSchema(false, false, true, false, false);
    const result = await generator.generateObject({
      model: 'agentBeastMode',
      schema,
      system,
      messages
    });
    thisStep = result.object as AnswerAction;
    (thisStep as AnswerAction).isFinal = true;
    context.actionTracker.trackAction({totalStep, thisStep, gaps, badAttempts});
  }
  (thisStep as AnswerAction).mdAnswer = buildMdFromAnswer((thisStep as AnswerAction))
  console.log(thisStep)
  await storeContext(system, schema, [allContext, allKeywords, allQuestions, allKnowledge], totalStep);
  return {
    result: thisStep,
    context,
    visitedURLs: [...new Set([...visitedURLs, ...Object.keys(allURLs)])],
    readURLs: visitedURLs,
  };
}
async function storeContext(prompt: string, schema: any, memory: any[][], step: number) {
  if ((process as any).asyncLocalContext?.available?.()) {
    const [context, keywords, questions, knowledge] = memory;
    (process as any).asyncLocalContext.ctx.promptContext = {
      prompt,
      schema,
      context,
      keywords,
      questions,
      knowledge,
      step
    };
    return;
  }
  try {
    await fs.writeFile(`prompt-${step}.txt`, `
Prompt:
${prompt}
JSONSchema:
${JSON.stringify(zodToJsonSchema(schema), null, 2)}
`);
    const [context, keywords, questions, knowledge] = memory;
    await fs.writeFile('context.json', JSON.stringify(context, null, 2));
    await fs.writeFile('queries.json', JSON.stringify(keywords, null, 2));
    await fs.writeFile('questions.json', JSON.stringify(questions, null, 2));
    await fs.writeFile('knowledge.json', JSON.stringify(knowledge, null, 2));
  } catch (error) {
    console.error('Context storage failed:', error);
  }
}
export async function main() {
  const question = process.argv[2] || "";
  const {
    result: finalStep,
    context: tracker,
    visitedURLs: visitedURLs
  } = await getResponse(question) as { result: AnswerAction; context: TrackerContext; visitedURLs: string[] };
  console.log('Final Answer:', finalStep.answer);
  console.log('Visited URLs:', visitedURLs);
  tracker.tokenTracker.printSummary();
}
if (require.main === module) {
  main().catch(console.error);
}

================
File: src/app.ts
================
import express, {Request, Response, RequestHandler} from 'express';
import cors from 'cors';
import {getResponse} from './agent';
import {
  TrackerContext,
  ChatCompletionRequest,
  ChatCompletionResponse,
  ChatCompletionChunk,
  AnswerAction,
  Model, StepAction
} from './types';
import {TokenTracker} from "./utils/token-tracker";
import {ActionTracker} from "./utils/action-tracker";
const app = express();
// Get secret from command line args for optional authentication
const secret = process.argv.find(arg => arg.startsWith('--secret='))?.split('=')[1];
app.use(cors());
app.use(express.json({
  limit: '10mb'
}));
// Add health check endpoint for Docker container verification
app.get('/health', (req, res) => {
  res.json({status: 'ok'});
});
async function* streamTextNaturally(text: string, streamingState: StreamingState) {
  // Split text into chunks that preserve CJK characters, URLs, and regular words
  const chunks = splitTextIntoChunks(text);
  let burstMode = false;
  let consecutiveShortItems = 0;
  for (const chunk of chunks) {
    if (!streamingState.currentlyStreaming) {
      yield chunks.slice(chunks.indexOf(chunk)).join('');
      return;
    }
    const delay = calculateDelay(chunk, burstMode);
    // Handle consecutive short items
    if (getEffectiveLength(chunk) <= 3 && chunk.trim().length > 0) {
      consecutiveShortItems++;
      if (consecutiveShortItems >= 3) {
        burstMode = true;
      }
    } else {
      consecutiveShortItems = 0;
      burstMode = false;
    }
    await new Promise(resolve => setTimeout(resolve, delay));
    yield chunk;
  }
}
function splitTextIntoChunks(text: string): string[] {
  const chunks: string[] = [];
  let currentChunk = '';
  let inURL = false;
  const pushCurrentChunk = () => {
    if (currentChunk) {
      chunks.push(currentChunk);
      currentChunk = '';
    }
  };
  for (let i = 0; i < text.length; i++) {
    const char = text[i];
    const nextChar = text[i + 1] || '';
    // URL detection
    if (char === 'h' && text.slice(i, i + 8).match(/https?:\/\//)) {
      pushCurrentChunk();
      inURL = true;
    }
    if (inURL) {
      currentChunk += char;
      // End of URL detection (whitespace or certain punctuation)
      if (/[\s\])}"']/.test(nextChar) || i === text.length - 1) {
        pushCurrentChunk();
        inURL = false;
      }
      continue;
    }
    // CJK character detection (including kana and hangul)
    if (/[\u4e00-\u9fff\u3040-\u30ff\uac00-\ud7af]/.test(char)) {
      pushCurrentChunk();
      chunks.push(char);
      continue;
    }
    // Whitespace handling
    if (/\s/.test(char)) {
      pushCurrentChunk();
      chunks.push(char);
      continue;
    }
    // Regular word building
    currentChunk += char;
    // Break on punctuation
    if (/[.!?,;:]/.test(nextChar)) {
      pushCurrentChunk();
    }
  }
  pushCurrentChunk();
  return chunks.filter(chunk => chunk !== '');
}
function calculateDelay(chunk: string, burstMode: boolean): number {
  const trimmedChunk = chunk.trim();
  // Handle whitespace
  if (trimmedChunk.length === 0) {
    return Math.random() * 20 + 10;
  }
  // Special handling for URLs
  if (chunk.match(/^https?:\/\//)) {
    return Math.random() * 50 + 10; // Slower typing for URLs
  }
  // Special handling for CJK characters
  if (/^[\u4e00-\u9fff\u3040-\u30ff\uac00-\ud7af]$/.test(chunk)) {
    return Math.random() * 25 + 10; // Longer delay for individual CJK characters
  }
  // Base delay calculation
  let baseDelay;
  if (burstMode) {
    baseDelay = Math.random() * 30 + 10;
  } else {
    const effectiveLength = getEffectiveLength(chunk);
    const perCharacterDelay = Math.max(10, 40 - effectiveLength * 2);
    baseDelay = Math.random() * perCharacterDelay + 10;
  }
  // Add variance based on chunk characteristics
  if (/[A-Z]/.test(chunk[0])) {
    baseDelay += Math.random() * 20 + 10;
  }
  if (/[^a-zA-Z\s]/.test(chunk)) {
    baseDelay += Math.random() * 30 + 10;
  }
  // Add pauses for punctuation
  if (/[.!?]$/.test(chunk)) {
    baseDelay += Math.random() * 200 + 10;
  } else if (/[,;:]$/.test(chunk)) {
    baseDelay += Math.random() * 100 + 10;
  }
  return baseDelay;
}
function getEffectiveLength(chunk: string): number {
  // Count CJK characters as 2 units
  const cjkCount = (chunk.match(/[\u4e00-\u9fff\u3040-\u30ff\uac00-\ud7af]/g) || []).length;
  const regularCount = chunk.length - cjkCount;
  return regularCount + (cjkCount * 2);
}
// Helper function to emit remaining content immediately
async function emitRemainingContent(
  res: Response,
  requestId: string,
  created: number,
  model: string,
  content: string,
) {
  if (!content) return;
  const chunk: ChatCompletionChunk = {
    id: requestId,
    object: 'chat.completion.chunk',
    created,
    model: model,
    system_fingerprint: 'fp_' + requestId,
    choices: [{
      index: 0,
      delta: {content},
      logprobs: null,
      finish_reason: null
    }],
  };
  res.write(`data: ${JSON.stringify(chunk)}\n\n`);
}
interface StreamingState {
  currentlyStreaming: boolean;
  currentGenerator: AsyncGenerator<string> | null;
  remainingContent: string;
  isEmitting: boolean;
  queue: { content: string; resolve: () => void }[];
  processingQueue: boolean;
}
function getTokenBudgetAndMaxAttempts(
  reasoningEffort: 'low' | 'medium' | 'high' | null = 'medium',
  maxCompletionTokens: number | null = null
): { tokenBudget: number, maxBadAttempts: number } {
  if (maxCompletionTokens !== null) {
    return {
      tokenBudget: maxCompletionTokens,
      maxBadAttempts: 2 // Default to medium setting for max attempts
    };
  }
  switch (reasoningEffort) {
    case 'low':
      return {tokenBudget: 100000, maxBadAttempts: 1};
    case 'high':
      return {tokenBudget: 1000000, maxBadAttempts: 2};
    case 'medium':
    default:
      return {tokenBudget: 500000, maxBadAttempts: 2};
  }
}
async function completeCurrentStreaming(
  streamingState: StreamingState,
  res: Response,
  requestId: string,
  created: number,
  model: string
) {
  if (streamingState.currentlyStreaming && streamingState.remainingContent) {
    // Force completion of current streaming
    await emitRemainingContent(
      res,
      requestId,
      created,
      model,
      streamingState.remainingContent
    );
    // Reset streaming state
    streamingState.currentlyStreaming = false;
    streamingState.remainingContent = '';
    streamingState.currentGenerator = null;
  }
}
// OpenAI-compatible chat completions endpoint
// Models API endpoints
app.get('/v1/models', (async (_req: Request, res: Response) => {
  const models: Model[] = [{
    id: 'jina-deepsearch-v1',
    object: 'model',
    created: 1686935002,
    owned_by: 'jina-ai'
  }];
  res.json({
    object: 'list',
    data: models
  });
}) as RequestHandler);
app.get('/v1/models/:model', (async (req: Request, res: Response) => {
  const modelId = req.params.model;
  if (modelId === 'jina-deepsearch-v1') {
    res.json({
      id: 'jina-deepsearch-v1',
      object: 'model',
      created: 1686935002,
      owned_by: 'jina-ai'
    });
  } else {
    res.status(404).json({
      error: {
        message: `Model '${modelId}' not found`,
        type: 'invalid_request_error',
        param: null,
        code: 'model_not_found'
      }
    });
  }
}) as RequestHandler);
if (secret) {
  // Check authentication only if secret is set
  app.use((req, res, next) => {
    const authHeader = req.headers.authorization;
    if (!authHeader || !authHeader.startsWith('Bearer ') || authHeader.split(' ')[1] !== secret) {
      console.log('[chat/completions] Unauthorized request');
      res.status(401).json({error: 'Unauthorized'});
      return;
    }
    return next();
  });
}
async function processQueue(streamingState: StreamingState, res: Response, requestId: string, created: number, model: string) {
  if (streamingState.processingQueue) return;
  streamingState.processingQueue = true;
  while (streamingState.queue.length > 0) {
    const current = streamingState.queue[0];
    // Clear any previous state
    streamingState.remainingContent = '';  // Add this line
    // Reset streaming state for new content
    streamingState.currentlyStreaming = true;
    streamingState.remainingContent = current.content;
    streamingState.isEmitting = true;
    try {
      // Add a check to prevent duplicate streaming
      if (streamingState.currentGenerator) {
        streamingState.currentGenerator = null;  // Add this line
      }
      for await (const word of streamTextNaturally(current.content, streamingState)) {
        const chunk: ChatCompletionChunk = {
          id: requestId,
          object: 'chat.completion.chunk',
          created,
          model,
          system_fingerprint: 'fp_' + requestId,
          choices: [{
            index: 0,
            delta: {content: word},
            logprobs: null,
            finish_reason: null
          }]
        };
        res.write(`data: ${JSON.stringify(chunk)}\n\n`);
      }
    } catch (error) {
      console.error('Error in streaming:', error);
    } finally {
      // Clear state before moving to next item
      streamingState.isEmitting = false;
      streamingState.currentlyStreaming = false;
      streamingState.remainingContent = '';
      streamingState.queue.shift();
      current.resolve();
    }
  }
  streamingState.processingQueue = false;
}
app.post('/v1/chat/completions', (async (req: Request, res: Response) => {
  // Check authentication only if secret is set
  if (secret) {
    const authHeader = req.headers.authorization;
    if (!authHeader || !authHeader.startsWith('Bearer ') || authHeader.split(' ')[1] !== secret) {
      console.log('[chat/completions] Unauthorized request');
      res.status(401).json({error: 'Unauthorized'});
      return;
    }
  }
  // Log request details (excluding sensitive data)
  console.log('[chat/completions] Request:', {
    model: req.body.model,
    stream: req.body.stream,
    messageCount: req.body.messages?.length,
    hasAuth: !!req.headers.authorization,
    requestId: Date.now().toString()
  });
  const body = req.body as ChatCompletionRequest;
  if (!body.messages?.length) {
    return res.status(400).json({error: 'Messages array is required and must not be empty'});
  }
  const lastMessage = body.messages[body.messages.length - 1];
  if (lastMessage.role !== 'user') {
    return res.status(400).json({error: 'Last message must be from user'});
  }
  // clean <think> from all assistant messages
  body.messages?.filter(message => message.role === 'assistant').forEach(message => {
    message.content = (message.content as string).replace(/<think>[\s\S]*?<\/think>/g, '').trim();
  });
  console.log('messages', body.messages);
  let {tokenBudget, maxBadAttempts} = getTokenBudgetAndMaxAttempts(
    body.reasoning_effort,
    body.max_completion_tokens
  );
  if (body.budget_tokens) {
    tokenBudget = body.budget_tokens;
  }
  if (body.max_attempts) {
    maxBadAttempts = body.max_attempts;
  }
  const requestId = Date.now().toString();
  const created = Math.floor(Date.now() / 1000);
  const context: TrackerContext = {
    tokenTracker: new TokenTracker(),
    actionTracker: new ActionTracker()
  };
  // Add this inside the chat completions endpoint, before setting up the action listener
  const streamingState: StreamingState = {
    currentlyStreaming: false,
    currentGenerator: null,
    remainingContent: '',
    isEmitting: false,
    queue: [],
    processingQueue: false
  };
  if (body.stream) {
    res.setHeader('Content-Type', 'text/event-stream');
    res.setHeader('Cache-Control', 'no-cache');
    res.setHeader('Connection', 'keep-alive');
    // Send initial chunk with opening think tag
    const initialChunk: ChatCompletionChunk = {
      id: requestId,
      object: 'chat.completion.chunk',
      created,
      model: body.model,
      system_fingerprint: 'fp_' + requestId,
      choices: [{
        index: 0,
        delta: {role: 'assistant', content: '<think>'},
        logprobs: null,
        finish_reason: null
      }]
    };
    res.write(`data: ${JSON.stringify(initialChunk)}\n\n`);
    // Set up progress listener with cleanup
    const actionListener = async (step: StepAction) => {
      // Add content to queue for both thinking steps and final answer
      if (step.think) {
        // if not ends with a space, add one
        const content = step.think + ' ';
        await new Promise<void>(resolve => {
          streamingState.queue.push({
            content,
            resolve
          });
          // Single call to process queue is sufficient
          processQueue(streamingState, res, requestId, created, body.model);
        });
      }
    };
    context.actionTracker.on('action', actionListener);
    // Make sure to update the cleanup code
    res.on('finish', () => {
      streamingState.currentlyStreaming = false;
      streamingState.currentGenerator = null;
      streamingState.remainingContent = '';
      context.actionTracker.removeListener('action', actionListener);
    });
  }
  try {
    const {
      result: finalStep,
      visitedURLs: visitedURLs,
      readURLs: readURLs
    } = await getResponse(undefined, tokenBudget, maxBadAttempts, context, body.messages)
    const usage = context.tokenTracker.getTotalUsageSnakeCase();
    if (body.stream) {
      // Complete any ongoing streaming before sending final answer
      await completeCurrentStreaming(streamingState, res, requestId, created, body.model);
      const finalAnswer = (finalStep as AnswerAction).mdAnswer;
      // Send closing think tag
      const closeThinkChunk: ChatCompletionChunk = {
        id: requestId,
        object: 'chat.completion.chunk',
        created,
        model: body.model,
        system_fingerprint: 'fp_' + requestId,
        choices: [{
          index: 0,
          delta: {content: `</think>\n\n${finalAnswer}`},
          logprobs: null,
          finish_reason: null
        }]
      };
      res.write(`data: ${JSON.stringify(closeThinkChunk)}\n\n`);
      // After the content is fully streamed, send the final chunk with finish_reason and usage
      const finalChunk: ChatCompletionChunk = {
        id: requestId,
        object: 'chat.completion.chunk',
        created,
        model: body.model,
        system_fingerprint: 'fp_' + requestId,
        choices: [{
          index: 0,
          delta: {content: ''},
          logprobs: null,
          finish_reason: 'stop'
        }],
        usage,
        visitedURLs,
        readURLs
      };
      res.write(`data: ${JSON.stringify(finalChunk)}\n\n`);
      res.end();
    } else {
      const response: ChatCompletionResponse = {
        id: requestId,
        object: 'chat.completion',
        created,
        model: body.model,
        system_fingerprint: 'fp_' + requestId,
        choices: [{
          index: 0,
          message: {
            role: 'assistant',
            content: finalStep.action === 'answer' ? (finalStep.mdAnswer || '') : finalStep.think
          },
          logprobs: null,
          finish_reason: 'stop'
        }],
        usage,
        visitedURLs,
        readURLs
      };
      // Log final response (excluding full content for brevity)
      console.log('[chat/completions] Response:', {
        id: response.id,
        status: 200,
        contentLength: response.choices[0].message.content.length,
        usage: response.usage,
        visitedURLs: response.visitedURLs,
        readURLs: response.readURLs
      });
      res.json(response);
    }
  } catch (error: any) {
    // Log error details
    console.error('[chat/completions] Error:', {
      message: error?.message || 'An error occurred',
      stack: error?.stack,
      type: error?.constructor?.name,
      requestId
    });
    // Track error as rejected tokens with Vercel token counting
    const errorMessage = error?.message || 'An error occurred';
    // Clean up event listeners
    context.actionTracker.removeAllListeners('action');
    // Get token usage in OpenAI API format
    const usage = context.tokenTracker.getTotalUsageSnakeCase();
    if (body.stream && res.headersSent) {
      // For streaming responses that have already started, send error as a chunk
      // First send closing think tag if we're in the middle of thinking
      const closeThinkChunk: ChatCompletionChunk = {
        id: requestId,
        object: 'chat.completion.chunk',
        created,
        model: body.model,
        system_fingerprint: 'fp_' + requestId,
        choices: [{
          index: 0,
          delta: {content: '</think>'},
          logprobs: null,
          finish_reason: null
        }],
        usage,
      };
      res.write(`data: ${JSON.stringify(closeThinkChunk)}\n\n`);
      const errorChunk: ChatCompletionChunk = {
        id: requestId,
        object: 'chat.completion.chunk',
        created,
        model: body.model,
        system_fingerprint: 'fp_' + requestId,
        choices: [{
          index: 0,
          delta: {content: errorMessage},
          logprobs: null,
          finish_reason: 'stop'
        }],
        usage
      };
      res.write(`data: ${JSON.stringify(errorChunk)}\n\n`);
      res.end();
    } else {
      // For non-streaming or not-yet-started responses, send error as JSON
      const response: ChatCompletionResponse = {
        id: requestId,
        object: 'chat.completion',
        created,
        model: body.model,
        system_fingerprint: 'fp_' + requestId,
        choices: [{
          index: 0,
          message: {
            role: 'assistant',
            content: `Error: ${errorMessage}`
          },
          logprobs: null,
          finish_reason: 'stop'
        }],
        usage,
      };
      res.json(response);
    }
  }
}) as RequestHandler);
export default app;

================
File: src/cli.ts
================
#!/usr/bin/env node
import { Command } from 'commander';
import { getResponse } from './agent';
import { version } from '../package.json';
const program = new Command();
program
  .name('deepresearch')
  .description('AI-powered research assistant that keeps searching until it finds the answer')
  .version(version)
  .argument('<query>', 'The research query to investigate')
  .option('-t, --token-budget <number>', 'Maximum token budget', (val) => {
    const num = parseInt(val);
    if (isNaN(num)) throw new Error('Invalid token budget: must be a number');
    return num;
  }, 1000000)
  .option('-m, --max-attempts <number>', 'Maximum bad attempts before giving up', (val) => {
    const num = parseInt(val);
    if (isNaN(num)) throw new Error('Invalid max attempts: must be a number');
    return num;
  }, 3)
  .option('-v, --verbose', 'Show detailed progress')
  .action(async (query: string, options: any) => {
    try {
      const { result } = await getResponse(
        query,
        parseInt(options.tokenBudget),
        parseInt(options.maxAttempts)
      );
      if (result.action === 'answer') {
        console.log('\nAnswer:', result.answer);
        if (result.references?.length) {
          console.log('\nReferences:');
          result.references.forEach(ref => {
            console.log(`- ${ref.url}`);
            console.log(`  "${ref.exactQuote}"`);
          });
        }
      }
    } catch (error) {
      console.error('Error:', error instanceof Error ? error.message : String(error));
      process.exit(1);
    }
  });
program.parse();

================
File: src/config.ts
================
import dotenv from 'dotenv';
import { ProxyAgent, setGlobalDispatcher } from 'undici';
import { createGoogleGenerativeAI } from '@ai-sdk/google';
import { createOpenAI, OpenAIProviderSettings } from '@ai-sdk/openai';
import configJson from '../config.json';
// Load environment variables
dotenv.config();
// Types
export type LLMProvider = 'openai' | 'gemini' | 'vertex';
export type ToolName = keyof typeof configJson.models.gemini.tools;
// Type definitions for our config structure
type EnvConfig = typeof configJson.env;
interface ProviderConfig {
  createClient: string;
  clientConfig?: Record<string, any>;
}
// Environment setup
const env: EnvConfig = { ...configJson.env };
(Object.keys(env) as (keyof EnvConfig)[]).forEach(key => {
  if (process.env[key]) {
    env[key] = process.env[key] || env[key];
  }
});
// Setup proxy if present
if (env.https_proxy) {
  try {
    const proxyUrl = new URL(env.https_proxy).toString();
    const dispatcher = new ProxyAgent({ uri: proxyUrl });
    setGlobalDispatcher(dispatcher);
  } catch (error) {
    console.error('Failed to set proxy:', error);
  }
}
// Export environment variables
export const OPENAI_BASE_URL = env.OPENAI_BASE_URL;
export const GEMINI_API_KEY = env.GEMINI_API_KEY;
export const OPENAI_API_KEY = env.OPENAI_API_KEY;
export const JINA_API_KEY = env.JINA_API_KEY;
export const BRAVE_API_KEY = env.BRAVE_API_KEY;
export const SERPER_API_KEY = env.SERPER_API_KEY;
export const SEARCH_PROVIDER = configJson.defaults.search_provider;
export const STEP_SLEEP = configJson.defaults.step_sleep;
// Determine LLM provider
export const LLM_PROVIDER: LLMProvider = (() => {
  const provider = process.env.LLM_PROVIDER || configJson.defaults.llm_provider;
  if (!isValidProvider(provider)) {
    throw new Error(`Invalid LLM provider: ${provider}`);
  }
  return provider;
})();
function isValidProvider(provider: string): provider is LLMProvider {
  return provider === 'openai' || provider === 'gemini' || provider === 'vertex';
}
interface ToolConfig {
  model: string;
  temperature: number;
  maxTokens: number;
}
interface ToolOverrides {
  temperature?: number;
  maxTokens?: number;
}
// Get tool configuration
export function getToolConfig(toolName: ToolName): ToolConfig {
  const providerConfig = configJson.models[LLM_PROVIDER === 'vertex' ? 'gemini' : LLM_PROVIDER];
  const defaultConfig = providerConfig.default;
  const toolOverrides = providerConfig.tools[toolName] as ToolOverrides;
  return {
    model: process.env.DEFAULT_MODEL_NAME || defaultConfig.model,
    temperature: toolOverrides.temperature ?? defaultConfig.temperature,
    maxTokens: toolOverrides.maxTokens ?? defaultConfig.maxTokens
  };
}
export function getMaxTokens(toolName: ToolName): number {
  return getToolConfig(toolName).maxTokens;
}
// Get model instance
export function getModel(toolName: ToolName) {
  const config = getToolConfig(toolName);
  const providerConfig = (configJson.providers as Record<string, ProviderConfig | undefined>)[LLM_PROVIDER];
  if (LLM_PROVIDER === 'openai') {
    if (!OPENAI_API_KEY) {
      throw new Error('OPENAI_API_KEY not found');
    }
    const opt: OpenAIProviderSettings = {
      apiKey: OPENAI_API_KEY,
      compatibility: providerConfig?.clientConfig?.compatibility
    };
    if (OPENAI_BASE_URL) {
      opt.baseURL = OPENAI_BASE_URL;
    }
    return createOpenAI(opt)(config.model);
  }
  if (LLM_PROVIDER === 'vertex') {
    const createVertex = require('@ai-sdk/google-vertex').createVertex;
    if (toolName === 'searchGrounding') {
      return createVertex({ project: process.env.GCLOUD_PROJECT, ...providerConfig?.clientConfig })(config.model, { useSearchGrounding: true });
    }
    return createVertex({ project: process.env.GCLOUD_PROJECT, ...providerConfig?.clientConfig })(config.model);
  }
  if (!GEMINI_API_KEY) {
    throw new Error('GEMINI_API_KEY not found');
  }
  if (toolName === 'searchGrounding') {
    return createGoogleGenerativeAI({ apiKey: GEMINI_API_KEY })(config.model, { useSearchGrounding: true });
  }
  return createGoogleGenerativeAI({ apiKey: GEMINI_API_KEY })(config.model);
}
// Validate required environment variables
if (LLM_PROVIDER === 'gemini' && !GEMINI_API_KEY) throw new Error("GEMINI_API_KEY not found");
if (LLM_PROVIDER === 'openai' && !OPENAI_API_KEY) throw new Error("OPENAI_API_KEY not found");
if (!JINA_API_KEY) throw new Error("JINA_API_KEY not found");
// Log all configurations
const configSummary = {
  provider: {
    name: LLM_PROVIDER,
    model: LLM_PROVIDER === 'openai'
      ? configJson.models.openai.default.model
      : configJson.models.gemini.default.model,
    ...(LLM_PROVIDER === 'openai' && { baseUrl: OPENAI_BASE_URL })
  },
  search: {
    provider: SEARCH_PROVIDER
  },
  tools: Object.fromEntries(
    Object.keys(configJson.models[LLM_PROVIDER === 'vertex' ? 'gemini' : LLM_PROVIDER].tools).map(name => [
      name,
      getToolConfig(name as ToolName)
    ])
  ),
  defaults: {
    stepSleep: STEP_SLEEP
  }
};
console.log('Configuration Summary:', JSON.stringify(configSummary, null, 2));

================
File: src/server.ts
================
import app from "./app";
const port = process.env.PORT || 3000;
// Export server startup function for better testing
export function startServer() {
  return app.listen(port, () => {
    console.log(`Server running at http://localhost:${port}`);
  });
}
// Start server if running directly
if (process.env.NODE_ENV !== 'test') {
  startServer();
}

================
File: src/types.ts
================
// Action Types
import {CoreAssistantMessage, CoreUserMessage, LanguageModelUsage} from "ai";
type BaseAction = {
  action: "search" | "answer" | "reflect" | "visit" | "coding";
  think: string;
};
export type SearchAction = BaseAction & {
  action: "search";
  searchRequests: string[];
};
export type AnswerAction = BaseAction & {
  action: "answer";
  answer: string;
  references: Array<{
    exactQuote: string;
    url: string;
  }>;
  isFinal?: boolean;
  mdAnswer?: string;
};
export type KnowledgeItem = {
  question: string,
  answer: string,
  references?: Array<{
    exactQuote: string;
    url: string;
  }> | Array<any>;
  type: 'qa' | 'side-info' | 'chat-history' | 'url' | 'coding',
  updated: string,
  sourceCode?: string,
}
export type ReflectAction = BaseAction & {
  action: "reflect";
  questionsToAnswer: string[];
};
export type VisitAction = BaseAction & {
  action: "visit";
  URLTargets: string[];
};
export type CodingAction = BaseAction & {
  action: "coding";
  codingIssue: string;
};
export type StepAction = SearchAction | AnswerAction | ReflectAction | VisitAction | CodingAction;
export type EvaluationType = 'definitive' | 'freshness' | 'plurality' | 'attribution' | 'completeness';
// Following Vercel AI SDK's token counting interface
export interface TokenUsage {
  tool: string;
  usage: LanguageModelUsage;
}
export interface SearchResponse {
  code: number;
  status: number;
  data: Array<{
    title: string;
    description: string;
    url: string;
    content: string;
    usage: { tokens: number; };
  }> | null;
  name?: string;
  message?: string;
  readableMessage?: string;
}
export interface BraveSearchResponse {
  web: {
    results: Array<{
      title: string;
      description: string;
      url: string;
    }>;
  };
}
export interface SerperSearchResponse {
  knowledgeGraph?: {
    title: string;
    type: string;
    website: string;
    imageUrl: string;
    description: string;
    descriptionSource: string;
    descriptionLink: string;
    attributes: { [k: string]: string; };
  },
  organic: {
    title: string;
    link: string;
    snippet: string;
    date: string;
    siteLinks?: { title: string; link: string; }[];
    position: number,
  }[];
  topStories?: {
    title: string;
    link: string;
    source: string;
    data: string;
    imageUrl: string;
  }[];
  relatedSearches?: string[];
  credits: number;
}
export interface ReadResponse {
  code: number;
  status: number;
  data?: {
    title: string;
    description: string;
    url: string;
    content: string;
    usage: { tokens: number; };
  };
  name?: string;
  message?: string;
  readableMessage?: string;
}
export type EvaluationResponse = {
  pass: boolean;
  think: string;
  type?: EvaluationType;
  freshness_analysis?: {
    days_ago: number;
    max_age_days?: number;
  };
  plurality_analysis?: {
    count_expected?: number;
    count_provided: number;
  };
  attribution_analysis?: {
    sources_provided: boolean,
    sources_verified: boolean,
    quotes_accurate: boolean,
  };
  completeness_analysis?: {
    aspects_expected: string,
    aspects_provided: string,
  }
};
export type CodeGenResponse = {
  think: string;
  code: string;
}
export type ErrorAnalysisResponse = {
  recap: string;
  blame: string;
  improvement: string;
  questionsToAnswer: string[];
};
export type SearchResult =
  | { title: string; url: string; description: string }
  | { title: string; link: string; snippet: string };
// OpenAI API Types
export interface Model {
  id: string;
  object: 'model';
  created: number;
  owned_by: string;
}
export interface ChatCompletionRequest {
  model: string;
  messages: Array<CoreUserMessage | CoreAssistantMessage>;
  stream?: boolean;
  reasoning_effort?: 'low' | 'medium' | 'high' | null;
  max_completion_tokens?: number | null;
  budget_tokens?: number | null;
  max_attempts?: number | null;
}
export interface ChatCompletionResponse {
  id: string;
  object: 'chat.completion';
  created: number;
  model: string;
  system_fingerprint: string;
  choices: Array<{
    index: number;
    message: {
      role: 'assistant';
      content: string;
    };
    logprobs: null;
    finish_reason: 'stop';
  }>;
  usage: {
    prompt_tokens: number;
    completion_tokens: number;
    total_tokens: number;
  };
  visitedURLs?: string[];
  readURLs?: string[];
}
export interface ChatCompletionChunk {
  id: string;
  object: 'chat.completion.chunk';
  created: number;
  model: string;
  system_fingerprint: string;
  choices: Array<{
    index: number;
    delta: {
      role?: 'assistant';
      content?: string;
    };
    logprobs: null;
    finish_reason: null | 'stop';
  }>;
  usage?: any;
  visitedURLs?: string[];
  readURLs?: string[];
}
// Tracker Types
import {TokenTracker} from './utils/token-tracker';
import {ActionTracker} from './utils/action-tracker';
export interface TrackerContext {
  tokenTracker: TokenTracker;
  actionTracker: ActionTracker;
}

================
File: .dockerignore
================
node_modules

================
File: .eslintrc.js
================
module.exports = {
  parser: '@typescript-eslint/parser',
  plugins: ['@typescript-eslint'],
  extends: [
    'eslint:recommended',
    'plugin:@typescript-eslint/recommended'
  ],
  env: {
    node: true,
    es6: true
  },
  parserOptions: {
    ecmaVersion: 2020,
    sourceType: 'module'
  },
  rules: {
    'no-console': ['error', { allow: ['log', 'error'] }],
    '@typescript-eslint/no-var-requires': 'off',
    '@typescript-eslint/no-explicit-any': 'off'
  },
  ignorePatterns: ["jina-ai/**/*"]
};

================
File: .gitignore
================
# Files
tasks/
context.json
knowledge.json
prompt-*.txt
queries.json
questions.json
eval-*.json

# Logs
logs
.idea
*.log
npm-debug.log*
yarn-debug.log*
yarn-error.log*
lerna-debug.log*
.pnpm-debug.log*

# Diagnostic reports (https://nodejs.org/api/report.html)
report.[0-9]*.[0-9]*.[0-9]*.[0-9]*.json

# Runtime data
pids
*.pid
*.seed
*.pid.lock

# Directory for instrumented libs generated by jscoverage/JSCover
lib-cov

# Coverage directory used by tools like istanbul
coverage
*.lcov

# nyc test coverage
.nyc_output

# Grunt intermediate storage (https://gruntjs.com/creating-plugins#storing-task-files)
.grunt

# Bower dependency directory (https://bower.io/)
bower_components

# node-waf configuration
.lock-wscript

# Compiled binary addons (https://nodejs.org/api/addons.html)
build/Release

# Dependency directories
node_modules/
jspm_packages/

# Snowpack dependency directory (https://snowpack.dev/)
web_modules/

# TypeScript cache
*.tsbuildinfo

# Optional npm cache directory
.npm

# Optional eslint cache
.eslintcache

# Optional stylelint cache
.stylelintcache

# Microbundle cache
.rpt2_cache/
.rts2_cache_cjs/
.rts2_cache_es/
.rts2_cache_umd/

# Optional REPL history
.node_repl_history

# Output of 'npm pack'
*.tgz

# Yarn Integrity file
.yarn-integrity

# dotenv environment variable files
.env
.env.development.local
.env.test.local
.env.production.local
.env.local

# parcel-bundler cache (https://parceljs.org/)
.cache
.parcel-cache

# Next.js build output
.next
out

# Nuxt.js build / generate output
.nuxt
dist

# Gatsby files
.cache/
# Comment in the public line in if your project uses Gatsby and not Next.js
# https://nextjs.org/blog/next-9-1#public-directory-support
# public

# vuepress build output
.vuepress/dist

# vuepress v2.x temp and cache directory
.temp
.cache

# Docusaurus cache and generated files
.docusaurus

# Serverless directories
.serverless/

# FuseBox cache
.fusebox/

# DynamoDB Local files
.dynamodb/

# TernJS port file
.tern-port

# Stores VSCode versions used for testing VSCode extensions
.vscode-test

# yarn v2
.yarn/cache
.yarn/unplugged
.yarn/build-state.yml
.yarn/install-state.gz
.pnp.*

================
File: config.json
================
{
  "env": {
    "https_proxy": "",
    "OPENAI_BASE_URL": "",
    "GEMINI_API_KEY": "",
    "OPENAI_API_KEY": "",
    "JINA_API_KEY": "",
    "BRAVE_API_KEY": "",
    "SERPER_API_KEY": "",
    "DEFAULT_MODEL_NAME": ""
  },
  "defaults": {
    "search_provider": "jina",
    "llm_provider": "gemini",
    "step_sleep": 100
  },
  "providers": {
    "gemini": {
      "createClient": "createGoogleGenerativeAI"
    },
    "openai": {
      "createClient": "createOpenAI",
      "clientConfig": {
        "compatibility": "strict"
      }
    }
  },
  "models": {
    "gemini": {
      "default": {
        "model": "gemini-2.0-flash",
        "temperature": 0,
        "maxTokens": 2000
      },
      "tools": {
        "coder": { "temperature": 0.7 },
        "searchGrounding": { "temperature": 0 },
        "dedup": { "temperature": 0.1 },
        "evaluator": {"temperature":  0.6, "maxTokens": 200},
        "errorAnalyzer": {},
        "queryRewriter": { "temperature": 0.1 },
        "agent": { "temperature": 0.7 },
        "agentBeastMode": { "temperature": 0.7 },
        "fallback": { "temperature": 0 }
      }
    },
    "openai": {
      "default": {
        "model": "gpt-4o-mini",
        "temperature": 0,
        "maxTokens": 8000
      },
      "tools": {
        "coder": { "temperature": 0.7 },
        "searchGrounding": { "temperature": 0 },
        "dedup": { "temperature": 0.1 },
        "evaluator": {},
        "errorAnalyzer": {},
        "queryRewriter": { "temperature": 0.1 },
        "agent": { "temperature": 0.7 },
        "agentBeastMode": { "temperature": 0.7 },
        "fallback": { "temperature": 0 }
      }
    }
  }
}

================
File: docker-compose.yml
================
version: '3.8'
services:
  app:
    build:
      context: .
      dockerfile: Dockerfile
    environment:
      - GEMINI_API_KEY=${GEMINI_API_KEY}
      - OPENAI_API_KEY=${OPENAI_API_KEY}
      - JINA_API_KEY=${JINA_API_KEY}
      - BRAVE_API_KEY=${BRAVE_API_KEY}
    ports:
      - "3000:3000"

================
File: Dockerfile
================
# ---- BUILD STAGE ----
FROM node:20-slim AS builder

# Set working directory
WORKDIR /app

# Copy package.json and package-lock.json
COPY package*.json ./

# Install dependencies
RUN npm install --ignore-scripts

# Copy application code
COPY . .

# Build the application
RUN npm run build --ignore-scripts

# ---- PRODUCTION STAGE ----
FROM node:20-slim AS production

# Set working directory
WORKDIR /app

# Copy package.json and package-lock.json
COPY package*.json ./

# Install production dependencies only
RUN npm install --production  --ignore-scripts

# Copy config.json and built files from builder
COPY --from=builder /app/config.json ./
COPY --from=builder /app/dist ./dist

# Set environment variables (Recommended to set at runtime, avoid hardcoding)
ENV GEMINI_API_KEY=${GEMINI_API_KEY}
ENV OPENAI_API_KEY=${OPENAI_API_KEY}
ENV JINA_API_KEY=${JINA_API_KEY}
ENV BRAVE_API_KEY=${BRAVE_API_KEY}

# Expose the port the app runs on
EXPOSE 3000

# Set startup command
CMD ["node", "./dist/server.js"]

================
File: jest.config.js
================
module.exports = {
  preset: 'ts-jest',
  testEnvironment: 'node',
  testMatch: ['**/__tests__/**/*.test.ts'],
  setupFiles: ['<rootDir>/jest.setup.js'],
};

================
File: jest.setup.js
================
require('dotenv').config();

================
File: package.json
================
{
  "name": "node-deepresearch",
  "version": "1.0.0",
  "main": "dist/app.js",
  "files": [
    "dist",
    "README.md",
    "LICENSE"
  ],
  "scripts": {
    "build": "tsc",
    "dev": "npx ts-node src/agent.ts",
    "search": "npx ts-node src/test-duck.ts",
    "rewrite": "npx ts-node src/tools/query-rewriter.ts",
    "lint": "eslint . --ext .ts",
    "lint:fix": "eslint . --ext .ts --fix",
    "serve": "ts-node src/server.ts",
    "start": "ts-node src/server.ts",
    "eval": "ts-node src/evals/batch-evals.ts",
    "test": "jest --testTimeout=30000",
    "test:watch": "jest --watch",
    "test:docker": "jest src/__tests__/docker.test.ts --testTimeout=300000"
  },
  "keywords": [],
  "author": "Jina AI",
  "license": "Apache-2.0",
  "description": "",
  "dependencies": {
    "@ai-sdk/google": "^1.0.0",
    "@ai-sdk/openai": "^1.1.9",
    "ai": "^4.1.26",
    "axios": "^1.7.9",
    "commander": "^13.1.0",
    "cors": "^2.8.5",
    "dotenv": "^16.4.7",
    "duck-duck-scrape": "^2.2.7",
    "express": "^4.21.2",
    "node-fetch": "^3.3.2",
    "undici": "^7.3.0",
    "zod": "^3.22.4",
    "zod-to-json-schema": "^3.24.1"
  },
  "devDependencies": {
    "@types/commander": "^2.12.0",
    "@types/cors": "^2.8.17",
    "@types/express": "^5.0.0",
    "@types/jest": "^29.5.14",
    "@types/node": "^22.10.10",
    "@types/node-fetch": "^2.6.12",
    "@types/supertest": "^6.0.2",
    "@typescript-eslint/eslint-plugin": "^7.0.1",
    "@typescript-eslint/parser": "^7.0.1",
    "eslint": "^8.56.0",
    "jest": "^29.7.0",
    "supertest": "^7.0.0",
    "ts-jest": "^29.2.5",
    "ts-node": "^10.9.2",
    "typescript": "^5.7.3"
  },
  "optionalDependencies": {
    "@ai-sdk/google-vertex": "^2.1.12"
  }
}

================
File: README.md
================
# DeepResearch

[Official UI](https://search.jina.ai/) | [UI Code](https://github.com/jina-ai/deepsearch-ui) | [Official API](https://jina.ai/deepsearch) | [Evaluation](#evaluation)

Keep searching, reading webpages, reasoning until an answer is found (or the token budget is exceeded). Useful for deeply investigating a query.

> [!IMPORTANT]  
> Unlike OpenAI/Gemini/Perplexity's "Deep Research", we focus solely on **finding the right answers via our iterative process**. We don't optimize for long-form articles, that's a **completely different problem**  so if you need quick, concise answers from deep search, you're in the right place. If you're looking for AI-generated long reports like OpenAI/Gemini/Perplexity does, this isn't for you.

```mermaid
---
config:
  theme: mc
  look: handDrawn
---
flowchart LR
 subgraph Loop["until budget exceed"]
    direction LR
        Search["Search"]
        Read["Read"]
        Reason["Reason"]
  end
    Query(["Query"]) --> Loop
    Search --> Read
    Read --> Reason
    Reason --> Search
    Loop --> Answer(["Answer"])

```

## Install

```bash
git clone https://github.com/jina-ai/node-DeepResearch.git
cd node-DeepResearch
npm install
```

[ on Youtube](https://youtu.be/vrpraFiPUyA)

It is also available on npm but not recommended for now, as the code is still under active development.


## Usage

We use Gemini (latest `gemini-2.0-flash`) / OpenAI / [LocalLLM](#use-local-llm) for reasoning, [Jina Reader](https://jina.ai/reader) for searching and reading webpages, you can get a free API key with 1M tokens from jina.ai. 

```bash
export GEMINI_API_KEY=...  # for gemini
# export OPENAI_API_KEY=... # for openai
# export LLM_PROVIDER=openai # for openai
export JINA_API_KEY=jina_...  # free jina api key, get from https://jina.ai/reader

npm run dev $QUERY
```

### Official Site

You can try it on [our official site](https://search.jina.ai).

### Official API

You can also use [our official DeepSearch API](https://jina.ai/deepsearch):

```
https://deepsearch.jina.ai/v1/chat/completions
```

You can use it with any OpenAI-compatible client. 

For the authentication Bearer, API key, rate limit, get from https://jina.ai/deepsearch.

#### Client integration guidelines

If you are building a web/local/mobile client that uses `Jina DeepSearch API`, here are some design guidelines:
- Our API is fully compatible with [OpenAI API schema](https://platform.openai.com/docs/api-reference/chat/create), this should greatly simplify the integration process. The model name is `jina-deepsearch-v1`.
- Our DeepSearch API is a reasoning+search grounding LLM, so it's best for questions that require deep reasoning and search.
- Two special tokens are introduced `<think>...</think>`. Please render them with care.
- Citations are often provided, and in [Github-flavored markdown footnote format](https://github.blog/changelog/2021-09-30-footnotes-now-supported-in-markdown-fields/), e.g. `[^1]`, `[^2]`, ...
- Guide the user to get a Jina API key from https://jina.ai, with 1M free tokens for new API key.
- There are rate limits, [between 10RPM to 30RPM depending on the API key tier](https://jina.ai/contact-sales#rate-limit).
- [Download Jina AI logo here](https://jina.ai/logo-Jina-1024.zip)

## Demo
> was recorded with `gemini-1.5-flash`, the latest `gemini-2.0-flash` leads to much better results!

Query: `"what is the latest blog post's title from jina ai?"`
3 steps; answer is correct!
![demo1](.github/visuals/demo.gif)

Query: `"what is the context length of readerlm-v2?"`
2 steps; answer is correct!
![demo1](.github/visuals/demo3.gif)

Query: `"list all employees from jina ai that u can find, as many as possible"` 
11 steps; partially correct! but im not in the list :(
![demo1](.github/visuals/demo2.gif)

Query: `"who will be the biggest competitor of Jina AI"` 
42 steps; future prediction kind, so it's arguably correct! atm Im not seeing `weaviate` as a competitor, but im open for the future "i told you so" moment.
![demo1](.github/visuals/demo4.gif)

More examples:

```
# example: no tool calling 
npm run dev "1+1="
npm run dev "what is the capital of France?"

# example: 2-step
npm run dev "what is the latest news from Jina AI?"

# example: 3-step
npm run dev "what is the twitter account of jina ai's founder"

# example: 13-step, ambiguious question (no def of "big")
npm run dev "who is bigger? cohere, jina ai, voyage?"

# example: open question, research-like, long chain of thoughts
npm run dev "who will be president of US in 2028?"
npm run dev "what should be jina ai strategy for 2025?"
```

## Use Local LLM

> Note, not every LLM works with our reasoning flow, we need those who support structured output (sometimes called JSON Schema output, object output) well. Feel free to purpose a PR to add more open-source LLMs to the working list.

If you use Ollama or LMStudio, you can redirect the reasoning request to your local LLM by setting the following environment variables:

```bash
export LLM_PROVIDER=openai  # yes, that's right - for local llm we still use openai client
export OPENAI_BASE_URL=http://127.0.0.1:1234/v1  # your local llm endpoint
export OPENAI_API_KEY=whatever  # random string would do, as we don't use it (unless your local LLM has authentication)
export DEFAULT_MODEL_NAME=qwen2.5-7b  # your local llm model name
```


## OpenAI-Compatible Server API

If you have a GUI client that supports OpenAI API (e.g. [CherryStudio](https://docs.cherry-ai.com/), [Chatbox](https://github.com/Bin-Huang/chatbox)) , you can simply config it to use this server.

![demo1](.github/visuals/demo6.gif)

Start the server:
```bash
# Without authentication
npm run serve

# With authentication (clients must provide this secret as Bearer token)
npm run serve --secret=your_secret_token
```

The server will start on http://localhost:3000 with the following endpoint:

### POST /v1/chat/completions
```bash
# Without authentication
curl http://localhost:3000/v1/chat/completions \
  -H "Content-Type: application/json" \
  -d '{
    "model": "jina-deepsearch-v1",
    "messages": [
      {
        "role": "user",
        "content": "Hello!"
      }
    ]
  }'

# With authentication (when server is started with --secret)
curl http://localhost:3000/v1/chat/completions \
  -H "Content-Type: application/json" \
  -H "Authorization: Bearer your_secret_token" \
  -d '{
    "model": "jina-deepsearch-v1",
    "messages": [
      {
        "role": "user",
        "content": "Hello!"
      }
    ],
    "stream": true
  }'
```

Response format:
```json
{
  "id": "chatcmpl-123",
  "object": "chat.completion",
  "created": 1677652288,
  "model": "jina-deepsearch-v1",
  "system_fingerprint": "fp_44709d6fcb",
  "choices": [{
    "index": 0,
    "message": {
      "role": "assistant",
      "content": "YOUR FINAL ANSWER"
    },
    "logprobs": null,
    "finish_reason": "stop"
  }],
  "usage": {
    "prompt_tokens": 9,
    "completion_tokens": 12,
    "total_tokens": 21
  }
}
```

For streaming responses (stream: true), the server sends chunks in this format:
```json
{
  "id": "chatcmpl-123",
  "object": "chat.completion.chunk",
  "created": 1694268190,
  "model": "jina-deepsearch-v1",
  "system_fingerprint": "fp_44709d6fcb",
  "choices": [{
    "index": 0,
    "delta": {
      "content": "..."
    },
    "logprobs": null,
    "finish_reason": null
  }]
}
```

Note: The think content in streaming responses is wrapped in XML tags:
```
<think>
[thinking steps...]
</think>
[final answer]
```


## Docker Setup

### Build Docker Image
To build the Docker image for the application, run the following command:
```bash
docker build -t deepresearch:latest .
```

### Run Docker Container
To run the Docker container, use the following command:
```bash
docker run -p 3000:3000 --env GEMINI_API_KEY=your_gemini_api_key --env JINA_API_KEY=your_jina_api_key deepresearch:latest
```

### Docker Compose
You can also use Docker Compose to manage multi-container applications. To start the application with Docker Compose, run:
```bash
docker-compose up
```

## How Does it Work?

Not sure a flowchart helps, but here it is:

```mermaid
flowchart TD
    Start([Start]) --> Init[Initialize context & variables]
    Init --> CheckBudget{Token budget<br/>exceeded?}
    CheckBudget -->|No| GetQuestion[Get current question<br/>from gaps]
    CheckBudget -->|Yes| BeastMode[Enter Beast Mode]

    GetQuestion --> GenPrompt[Generate prompt]
    GenPrompt --> ModelGen[Generate response<br/>using Gemini]
    ModelGen --> ActionCheck{Check action<br/>type}

    ActionCheck -->|answer| AnswerCheck{Is original<br/>question?}
    AnswerCheck -->|Yes| EvalAnswer[Evaluate answer]
    EvalAnswer --> IsGoodAnswer{Is answer<br/>definitive?}
    IsGoodAnswer -->|Yes| HasRefs{Has<br/>references?}
    HasRefs -->|Yes| End([End])
    HasRefs -->|No| GetQuestion
    IsGoodAnswer -->|No| StoreBad[Store bad attempt<br/>Reset context]
    StoreBad --> GetQuestion

    AnswerCheck -->|No| StoreKnowledge[Store as intermediate<br/>knowledge]
    StoreKnowledge --> GetQuestion

    ActionCheck -->|reflect| ProcessQuestions[Process new<br/>sub-questions]
    ProcessQuestions --> DedupQuestions{New unique<br/>questions?}
    DedupQuestions -->|Yes| AddGaps[Add to gaps queue]
    DedupQuestions -->|No| DisableReflect[Disable reflect<br/>for next step]
    AddGaps --> GetQuestion
    DisableReflect --> GetQuestion

    ActionCheck -->|search| SearchQuery[Execute search]
    SearchQuery --> NewURLs{New URLs<br/>found?}
    NewURLs -->|Yes| StoreURLs[Store URLs for<br/>future visits]
    NewURLs -->|No| DisableSearch[Disable search<br/>for next step]
    StoreURLs --> GetQuestion
    DisableSearch --> GetQuestion

    ActionCheck -->|visit| VisitURLs[Visit URLs]
    VisitURLs --> NewContent{New content<br/>found?}
    NewContent -->|Yes| StoreContent[Store content as<br/>knowledge]
    NewContent -->|No| DisableVisit[Disable visit<br/>for next step]
    StoreContent --> GetQuestion
    DisableVisit --> GetQuestion

    BeastMode --> FinalAnswer[Generate final answer] --> End
```

## Evaluation

I kept the evaluation simple, LLM-as-a-judge and collect some [ego questions](./src/evals/ego-questions.json) for evaluation. These are the questions about Jina AI that I know 100% the answer but LLMs do not.

I mainly look at 3 things: total steps, total tokens, and the correctness of the final answer.

```bash
npm run eval ./src/evals/questions.json
```

Here's the table comparing plain `gemini-2.0-flash` and `gemini-2.0-flash + node-deepresearch` on the ego set.

Plain `gemini-2.0-flash` can be run by setting `tokenBudget` to zero, skipping the while-loop and directly answering the question. 

It should not be surprised that plain `gemini-2.0-flash` has a 0% pass rate, as I intentionally filtered out the questions that LLMs can answer.

| Metric | gemini-2.0-flash | #188f1bb |
|--------|------------------|----------|
| Pass Rate | 0% | 75%      |
| Average Steps | 1 | 4        |
| Maximum Steps | 1 | 13       |
| Minimum Steps | 1 | 2        |
| Median Steps | 1 | 3        |
| Average Tokens | 428 | 68,574   |
| Median Tokens | 434 | 31,541   |
| Maximum Tokens | 463 | 363,655  |
| Minimum Tokens | 374 | 7,963    |

================
File: tsconfig.json
================
{
  "compilerOptions": {
    "target": "ES2020",
    "module": "node16",
    "outDir": "./dist",
    "rootDir": "./src",
    "sourceMap": true,
    "esModuleInterop": true,
    "skipLibCheck": true,
    "forceConsistentCasingInFileNames": true,
    "strict": true,
    "experimentalDecorators": true,
    "emitDecoratorMetadata": true,
    "resolveJsonModule": true
  },
  "include": ["src/**/*"],
  "exclude": ["jina-ai/**/*", "**/__tests__/**/*"],
}



================================================================
End of Codebase
================================================================
